#!/usr/bin/env python3
"""
é‡å­æ™ºèƒ½åŒ–åŠŸèƒ½ç‚¹ä¼°ç®—ç³»ç»Ÿ - çŸ¥è¯†åº“åˆå§‹åŒ–è„šæœ¬

æ•´åˆæ–‡æ¡£åŠ è½½ã€å‘é‡åŒ–ã€å­˜å‚¨çš„å®Œæ•´çŸ¥è¯†åº“è®¾ç½®æµç¨‹
"""

import asyncio
import sys
from pathlib import Path
from typing import Dict, List
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from knowledge_base.loaders.pdf_loader import load_knowledge_base_pdfs
from knowledge_base.vector_stores.mongodb_atlas import setup_mongodb_vector_stores
from knowledge_base.embeddings.embedding_models import get_default_embedding_model, test_embedding_model
from config.settings import get_settings

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def check_prerequisites():
    """æ£€æŸ¥å‰ç½®æ¡ä»¶"""
    print("ğŸ” æ£€æŸ¥å‰ç½®æ¡ä»¶...")
    
    settings = get_settings()
    
    # æ£€æŸ¥å¿…è¦çš„é…ç½®
    checks = {
        "MongoDBè¿æ¥": bool(settings.database.mongodb_url),
        "åµŒå…¥æ¨¡å‹API": bool(settings.llm.bge_m3_api_key or settings.llm.openai_api_key),
        "NESMAæ–‡æ¡£ç›®å½•": settings.knowledge_base.nesma_docs_path.exists(),
        "COSMICæ–‡æ¡£ç›®å½•": settings.knowledge_base.cosmic_docs_path.exists(),
        "é€šç”¨æ–‡æ¡£ç›®å½•": settings.knowledge_base.common_docs_path.exists()
    }
    
    all_passed = True
    for check_name, passed in checks.items():
        status = "âœ…" if passed else "âŒ"
        print(f"  {status} {check_name}")
        if not passed:
            all_passed = False
    
    if not all_passed:
        print("\nâš ï¸ éƒ¨åˆ†å‰ç½®æ¡ä»¶ä¸æ»¡è¶³ï¼Œä½†ä»å¯ä»¥ç»§ç»­...")
        
    # æµ‹è¯•åµŒå…¥æ¨¡å‹
    print("\nğŸ§ª æµ‹è¯•åµŒå…¥æ¨¡å‹...")
    model_working = await test_embedding_model()
    if not model_working:
        print("âŒ åµŒå…¥æ¨¡å‹æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIé…ç½®")
        return False
    
    return True


async def create_document_directories():
    """åˆ›å»ºæ–‡æ¡£ç›®å½•"""
    print("ğŸ“ ç¡®ä¿æ–‡æ¡£ç›®å½•å­˜åœ¨...")
    
    settings = get_settings()
    directories = [
        settings.knowledge_base.nesma_docs_path,
        settings.knowledge_base.cosmic_docs_path,
        settings.knowledge_base.common_docs_path
    ]
    
    for directory in directories:
        directory.mkdir(parents=True, exist_ok=True)
        print(f"  âœ… {directory}")


async def load_and_process_documents():
    """åŠ è½½å’Œå¤„ç†æ–‡æ¡£"""
    print("ğŸ“š åŠ è½½çŸ¥è¯†åº“æ–‡æ¡£...")
    
    try:
        documents_by_type = await load_knowledge_base_pdfs()
        
        total_docs = sum(len(docs) for docs in documents_by_type.values())
        print(f"\nğŸ“Š æ–‡æ¡£åŠ è½½å®Œæˆï¼Œæ€»è®¡ {total_docs} ä¸ªæ–‡æ¡£å—:")
        
        for source_type, docs in documents_by_type.items():
            print(f"  {source_type.upper()}: {len(docs)} ä¸ªæ–‡æ¡£å—")
            
            # æ˜¾ç¤ºç¤ºä¾‹æ–‡æ¡£
            if docs:
                sample_doc = docs[0]
                print(f"    ç¤ºä¾‹: {sample_doc.metadata.get('file_name', 'unknown')}")
                print(f"    å†…å®¹é¢„è§ˆ: {sample_doc.page_content[:100]}...")
        
        return documents_by_type
        
    except Exception as e:
        logger.error(f"âŒ æ–‡æ¡£åŠ è½½å¤±è´¥: {str(e)}")
        return {}


async def setup_vector_storage(documents_by_type: Dict[str, List]):
    """è®¾ç½®å‘é‡å­˜å‚¨"""
    print("\nğŸ”— è®¾ç½®å‘é‡å­˜å‚¨...")
    
    if not documents_by_type:
        print("âš ï¸ æ²¡æœ‰æ–‡æ¡£å¯ä¾›å‘é‡åŒ–ï¼Œè·³è¿‡å‘é‡å­˜å‚¨è®¾ç½®")
        return None
    
    try:
        # è·å–åµŒå…¥æ¨¡å‹
        embeddings = get_default_embedding_model()
        
        # è®¾ç½®MongoDB Atlaså‘é‡å­˜å‚¨
        vector_manager = await setup_mongodb_vector_stores(
            documents_by_type, 
            embeddings
        )
        
        print("âœ… å‘é‡å­˜å‚¨è®¾ç½®å®Œæˆ")
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š å‘é‡å­˜å‚¨ç»Ÿè®¡:")
        for source_type in documents_by_type.keys():
            try:
                stats = await vector_manager.get_collection_stats(source_type)
                print(f"  {source_type.upper()}:")
                print(f"    æ–‡æ¡£æ•°é‡: {stats['total_documents']}")
                print(f"    é›†åˆåç§°: {stats['collection_name']}")
                if stats['standards']:
                    for standard, info in stats['standards'].items():
                        print(f"    {standard}: {info['count']} ä¸ªæ–‡æ¡£")
            except Exception as e:
                print(f"    âŒ è·å–ç»Ÿè®¡å¤±è´¥: {str(e)}")
        
        return vector_manager
        
    except Exception as e:
        logger.error(f"âŒ å‘é‡å­˜å‚¨è®¾ç½®å¤±è´¥: {str(e)}")
        return None


async def test_retrieval_system(vector_manager):
    """æµ‹è¯•æ£€ç´¢ç³»ç»Ÿ"""
    print("\nğŸ” æµ‹è¯•æ£€ç´¢ç³»ç»Ÿ...")
    
    if not vector_manager:
        print("âš ï¸ å‘é‡ç®¡ç†å™¨ä¸å¯ç”¨ï¼Œè·³è¿‡æ£€ç´¢æµ‹è¯•")
        return
    
    try:
        from knowledge_base.retrievers.semantic_retriever import create_knowledge_retrievers
        
        # åˆ›å»ºæ£€ç´¢å™¨
        retrievers = await create_knowledge_retrievers(vector_manager)
        multi_retriever = retrievers["multi_source"]
        
        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "åŠŸèƒ½ç‚¹åˆ†ç±»è§„åˆ™",
            "å¤æ‚åº¦è®¡ç®—æ–¹æ³•",
            "æ•°æ®ç§»åŠ¨ç±»å‹"
        ]
        
        for i, query in enumerate(test_queries, 1):
            print(f"\n  æµ‹è¯•æŸ¥è¯¢ {i}: {query}")
            
            try:
                result = await multi_retriever.adaptive_retrieve(query, min_chunks=1)
                
                print(f"    ğŸ“Š æ£€ç´¢åˆ° {len(result.retrieved_chunks)} ä¸ªç»“æœ")
                print(f"    â±ï¸ è€—æ—¶: {result.retrieval_time_ms}ms")
                
                if result.retrieved_chunks:
                    best_chunk = result.retrieved_chunks[0]
                    print(f"    ğŸ¯ æœ€ä½³åŒ¹é… (åˆ†æ•°: {best_chunk.relevance_score:.3f})")
                    print(f"       æ¥æº: {best_chunk.source_type.value}")
                
            except Exception as e:
                print(f"    âŒ æŸ¥è¯¢å¤±è´¥: {str(e)}")
        
        print("\nâœ… æ£€ç´¢ç³»ç»Ÿæµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        logger.error(f"âŒ æ£€ç´¢ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {str(e)}")


async def generate_setup_report(vector_manager, documents_by_type):
    """ç”Ÿæˆè®¾ç½®æŠ¥å‘Š"""
    print("\nğŸ“‹ ç”Ÿæˆè®¾ç½®æŠ¥å‘Š...")
    
    report = {
        "setup_time": asyncio.get_event_loop().time(),
        "document_stats": {
            source_type: len(docs) 
            for source_type, docs in documents_by_type.items()
        },
        "total_documents": sum(len(docs) for docs in documents_by_type.values()),
        "vector_storage": "MongoDB Atlas" if vector_manager else "æœªè®¾ç½®",
        "embedding_model": "BGE-M3 (é»˜è®¤)",
        "status": "å®Œæˆ"
    }
    
    print("ğŸ“Š è®¾ç½®æŠ¥å‘Š:")
    for key, value in report.items():
        print(f"  {key}: {value}")
    
    # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
    import json
    report_file = Path("knowledge_base_setup_report.json")
    with open(report_file, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    return report


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹çŸ¥è¯†åº“åˆå§‹åŒ–...")
    print("=" * 60)
    
    try:
        # 1. æ£€æŸ¥å‰ç½®æ¡ä»¶
        if not await check_prerequisites():
            print("âŒ å‰ç½®æ¡ä»¶æ£€æŸ¥å¤±è´¥ï¼Œç»ˆæ­¢åˆå§‹åŒ–")
            return
        
        # 2. åˆ›å»ºç›®å½•
        await create_document_directories()
        
        # 3. åŠ è½½æ–‡æ¡£
        documents_by_type = await load_and_process_documents()
        
        # 4. è®¾ç½®å‘é‡å­˜å‚¨
        vector_manager = await setup_vector_storage(documents_by_type)
        
        # 5. æµ‹è¯•æ£€ç´¢ç³»ç»Ÿ
        await test_retrieval_system(vector_manager)
        
        # 6. ç”ŸæˆæŠ¥å‘Š
        report = await generate_setup_report(vector_manager, documents_by_type)
        
        # 7. æ¸…ç†
        if vector_manager:
            await vector_manager.close()
        
        print("\n" + "=" * 60)
        print("âœ… çŸ¥è¯†åº“åˆå§‹åŒ–å®Œæˆï¼")
        
        # ä½¿ç”¨å»ºè®®
        print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
        print("1. å°†PDFæ–‡æ¡£æ”¾å…¥å¯¹åº”çš„æ–‡æ¡£ç›®å½•:")
        print(f"   - NESMA: knowledge_base/documents/nesma/")
        print(f"   - COSMIC: knowledge_base/documents/cosmic/")
        print(f"   - é€šç”¨: knowledge_base/documents/common/")
        print("2. é‡æ–°è¿è¡Œæ­¤è„šæœ¬æ¥æ›´æ–°çŸ¥è¯†åº“")
        print("3. ä½¿ç”¨ main.py estimate å‘½ä»¤å¼€å§‹åŠŸèƒ½ç‚¹ä¼°ç®—")
        
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­ï¼ŒçŸ¥è¯†åº“åˆå§‹åŒ–å·²å–æ¶ˆ")
    except Exception as e:
        logger.error(f"âŒ çŸ¥è¯†åº“åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        print(f"\nâŒ åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    # è®¾ç½®äº‹ä»¶å¾ªç¯ç­–ç•¥ (Windowså…¼å®¹æ€§)
    if sys.platform.startswith('win'):
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    
    asyncio.run(main()) 