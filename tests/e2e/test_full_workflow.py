"""
ç«¯åˆ°ç«¯å®Œæ•´å·¥ä½œæµæµ‹è¯•

æµ‹è¯•å®Œæ•´çš„åŠŸèƒ½ç‚¹ä¼°ç®—å·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬NESMAã€COSMICå’ŒåŒæ ‡å‡†å¯¹æ¯”
"""

import pytest
import asyncio
from unittest.mock import Mock, AsyncMock, patch
from typing import Dict, Any, List
import time

from graph.workflow_graph import FPEstimationWorkflow, create_compiled_workflow
from models.project_models import ProjectInfo, TechnologyStack, BusinessDomain
from models.common_models import EstimationStrategy, WorkflowState
from config.settings import get_settings


class TestFullWorkflow:
    """å®Œæ•´å·¥ä½œæµç«¯åˆ°ç«¯æµ‹è¯•"""
    
    @pytest.fixture
    def sample_projects(self):
        """ä¸åŒè§„æ¨¡çš„æ ·æœ¬é¡¹ç›®"""
        return {
            "small": ProjectInfo(
                name="ä¸ªäººåšå®¢ç³»ç»Ÿ",
                description="""
                ç®€å•çš„ä¸ªäººåšå®¢ç³»ç»Ÿï¼ŒåŒ…å«ï¼š
                1. ç”¨æˆ·æ³¨å†Œç™»å½•
                2. æ–‡ç« å‘å¸ƒå’Œç¼–è¾‘
                3. æ–‡ç« æµè§ˆå’Œæœç´¢
                4. è¯„è®ºåŠŸèƒ½
                """,
                technology_stack=[TechnologyStack.PYTHON, TechnologyStack.MYSQL],
                business_domain=BusinessDomain.OTHER
            ),
            "medium": ProjectInfo(
                name="ä¼ä¸šå®¢æˆ·ç®¡ç†ç³»ç»Ÿ",
                description="""
                ä¸­ç­‰è§„æ¨¡çš„CRMç³»ç»Ÿï¼ŒåŒ…å«ï¼š
                1. å®¢æˆ·ä¿¡æ¯ç®¡ç†ï¼šå½•å…¥ã€æŸ¥è¯¢ã€ä¿®æ”¹å®¢æˆ·èµ„æ–™
                2. é”€å”®æœºä¼šç®¡ç†ï¼šè·Ÿè¿›é”€å”®çº¿ç´¢ï¼Œè®°å½•æ²Ÿé€šå†å²
                3. åˆåŒç®¡ç†ï¼šåˆåŒç”Ÿæˆã€å®¡æ‰¹ã€å½’æ¡£
                4. æŠ¥è¡¨åˆ†æï¼šé”€å”®ç»Ÿè®¡ã€å®¢æˆ·åˆ†ææŠ¥è¡¨
                5. æƒé™ç®¡ç†ï¼šç”¨æˆ·è§’è‰²å’Œæƒé™æ§åˆ¶
                6. ç³»ç»Ÿé›†æˆï¼šä¸é‚®ä»¶ç³»ç»Ÿã€çŸ­ä¿¡å¹³å°é›†æˆ
                """,
                technology_stack=[TechnologyStack.JAVA, TechnologyStack.MYSQL, TechnologyStack.REDIS],
                business_domain=BusinessDomain.RETAIL
            ),
            "large": ProjectInfo(
                name="é“¶è¡Œæ ¸å¿ƒä¸šåŠ¡ç³»ç»Ÿ",
                description="""
                å¤§å‹é“¶è¡Œæ ¸å¿ƒç³»ç»Ÿï¼ŒåŒ…å«ï¼š
                1. è´¦æˆ·ç®¡ç†ï¼šå¼€æˆ·ã€é”€æˆ·ã€è´¦æˆ·ä¿¡æ¯ç»´æŠ¤
                2. å­˜å–æ¬¾ä¸šåŠ¡ï¼šç°é‡‘å­˜å–ã€è½¬è´¦ã€æ±‡æ¬¾
                3. è´·æ¬¾ä¸šåŠ¡ï¼šè´·æ¬¾ç”³è¯·ã€å®¡æ‰¹ã€æ”¾æ¬¾ã€è¿˜æ¬¾
                4. ç†è´¢äº§å“ï¼šäº§å“ç®¡ç†ã€è´­ä¹°ã€èµå›
                5. é£é™©æ§åˆ¶ï¼šåæ´—é’±ã€é£é™©è¯„ä¼°ã€é¢„è­¦
                6. å®¢æˆ·æœåŠ¡ï¼šå®¢æˆ·æŠ•è¯‰ã€å’¨è¯¢ã€æœåŠ¡è®°å½•
                7. æŠ¥è¡¨ç®¡ç†ï¼šç›‘ç®¡æŠ¥è¡¨ã€å†…éƒ¨æŠ¥è¡¨ã€ç»Ÿè®¡åˆ†æ
                8. ç³»ç»Ÿé›†æˆï¼šä¸å¤®è¡Œã€å¾ä¿¡ã€æ”¯ä»˜ç³»ç»Ÿé›†æˆ
                9. æ•°æ®ç®¡ç†ï¼šæ•°æ®å¤‡ä»½ã€æ¢å¤ã€å½’æ¡£
                10. å®‰å…¨ç®¡ç†ï¼šè®¿é—®æ§åˆ¶ã€å®¡è®¡æ—¥å¿—ã€åŠ å¯†
                """,
                technology_stack=[
                    TechnologyStack.JAVA, TechnologyStack.ORACLE, 
                    TechnologyStack.REDIS, TechnologyStack.AWS
                ],
                business_domain=BusinessDomain.FINANCE
            )
        }
    
    @pytest.fixture
    def workflow_instance(self):
        """åˆ›å»ºå·¥ä½œæµå®ä¾‹"""
        return FPEstimationWorkflow()
    
    @pytest.mark.asyncio
    async def test_nesma_only_workflow(self, workflow_instance, sample_projects):
        """æµ‹è¯•çº¯NESMAä¼°ç®—å·¥ä½œæµ"""
        project = sample_projects["medium"]
        
        # Mockå„ä¸ªæ™ºèƒ½ä½“çš„è¿”å›ç»“æœ
        mock_responses = self._create_nesma_mock_responses()
        
        with patch.multiple(
            'agents.standards.nesma.function_classifier.NESMAFunctionClassifierAgent',
            execute_task=AsyncMock(side_effect=mock_responses["classifier"]),
        ), patch.multiple(
            'agents.standards.nesma.complexity_calculator.NESMAComplexityCalculatorAgent',
            execute_task=AsyncMock(side_effect=mock_responses["complexity"]),
        ), patch.multiple(
            'agents.standards.nesma.ufp_calculator.NESMAUFPCalculatorAgent',
            execute_task=AsyncMock(side_effect=mock_responses["ufp"]),
        ):
            # åˆå§‹åŒ–å·¥ä½œæµ
            session_id = await workflow_instance.initialize(
                project_info=project,
                strategy=EstimationStrategy.NESMA_ONLY,
                requirements=project.description
            )
            
            assert session_id is not None
            
            # æ‰§è¡Œå·¥ä½œæµ
            start_time = time.time()
            final_state = await workflow_instance.execute()
            execution_time = time.time() - start_time
            
            # éªŒè¯æ‰§è¡Œç»“æœ
            assert final_state.current_state == WorkflowState.COMPLETED
            assert final_state.nesma_ufp_total > 0
            assert final_state.cosmic_cfp_total is None  # NESMA_ONLYæ¨¡å¼ä¸åº”æœ‰COSMICç»“æœ
            assert final_state.final_report is not None
            assert execution_time < 30  # ä¸­ç­‰é¡¹ç›®åº”åœ¨30ç§’å†…å®Œæˆ
            
            print(f"âœ… NESMAå·¥ä½œæµæµ‹è¯•å®Œæˆ: {final_state.nesma_ufp_total} UFP, è€—æ—¶: {execution_time:.2f}s")
    
    @pytest.mark.asyncio
    async def test_cosmic_only_workflow(self, workflow_instance, sample_projects):
        """æµ‹è¯•çº¯COSMICä¼°ç®—å·¥ä½œæµ"""
        project = sample_projects["medium"]
        
        # Mockå„ä¸ªæ™ºèƒ½ä½“çš„è¿”å›ç»“æœ
        mock_responses = self._create_cosmic_mock_responses()
        
        with patch.multiple(
            'agents.standards.cosmic.functional_user_agent.COSMICFunctionalUserAgent',
            execute_task=AsyncMock(side_effect=mock_responses["functional_user"]),
        ), patch.multiple(
            'agents.standards.cosmic.boundary_analyzer.COSMICBoundaryAnalyzerAgent',
            execute_task=AsyncMock(side_effect=mock_responses["boundary"]),
        ), patch.multiple(
            'agents.standards.cosmic.data_movement_classifier.COSMICDataMovementClassifierAgent',
            execute_task=AsyncMock(side_effect=mock_responses["data_movement"]),
        ), patch.multiple(
            'agents.standards.cosmic.cfp_calculator.COSMICCFPCalculatorAgent',
            execute_task=AsyncMock(side_effect=mock_responses["cfp"]),
        ):
            # åˆå§‹åŒ–å·¥ä½œæµ
            session_id = await workflow_instance.initialize(
                project_info=project,
                strategy=EstimationStrategy.COSMIC_ONLY,
                requirements=project.description
            )
            
            # æ‰§è¡Œå·¥ä½œæµ
            start_time = time.time()
            final_state = await workflow_instance.execute()
            execution_time = time.time() - start_time
            
            # éªŒè¯æ‰§è¡Œç»“æœ
            assert final_state.current_state == WorkflowState.COMPLETED
            assert final_state.cosmic_cfp_total > 0
            assert final_state.nesma_ufp_total is None  # COSMIC_ONLYæ¨¡å¼ä¸åº”æœ‰NESMAç»“æœ
            assert final_state.final_report is not None
            assert execution_time < 30  # ä¸­ç­‰é¡¹ç›®åº”åœ¨30ç§’å†…å®Œæˆ
            
            print(f"âœ… COSMICå·¥ä½œæµæµ‹è¯•å®Œæˆ: {final_state.cosmic_cfp_total} CFP, è€—æ—¶: {execution_time:.2f}s")
    
    @pytest.mark.asyncio
    async def test_dual_standard_workflow(self, workflow_instance, sample_projects):
        """æµ‹è¯•åŒæ ‡å‡†å¯¹æ¯”ä¼°ç®—å·¥ä½œæµ"""
        project = sample_projects["large"]
        
        # Mockä¸¤å¥—æ ‡å‡†çš„è¿”å›ç»“æœ
        nesma_mock = self._create_nesma_mock_responses()
        cosmic_mock = self._create_cosmic_mock_responses()
        
        with patch.multiple(
            'agents.standards.nesma.function_classifier.NESMAFunctionClassifierAgent',
            execute_task=AsyncMock(side_effect=nesma_mock["classifier"]),
        ), patch.multiple(
            'agents.standards.nesma.complexity_calculator.NESMAComplexityCalculatorAgent',
            execute_task=AsyncMock(side_effect=nesma_mock["complexity"]),
        ), patch.multiple(
            'agents.standards.nesma.ufp_calculator.NESMAUFPCalculatorAgent',
            execute_task=AsyncMock(side_effect=nesma_mock["ufp"]),
        ), patch.multiple(
            'agents.standards.cosmic.functional_user_agent.COSMICFunctionalUserAgent',
            execute_task=AsyncMock(side_effect=cosmic_mock["functional_user"]),
        ), patch.multiple(
            'agents.standards.cosmic.boundary_analyzer.COSMICBoundaryAnalyzerAgent',
            execute_task=AsyncMock(side_effect=cosmic_mock["boundary"]),
        ), patch.multiple(
            'agents.standards.cosmic.data_movement_classifier.COSMICDataMovementClassifierAgent',
            execute_task=AsyncMock(side_effect=cosmic_mock["data_movement"]),
        ), patch.multiple(
            'agents.standards.cosmic.cfp_calculator.COSMICCFPCalculatorAgent',
            execute_task=AsyncMock(side_effect=cosmic_mock["cfp"]),
        ):
            # åˆå§‹åŒ–å·¥ä½œæµ
            session_id = await workflow_instance.initialize(
                project_info=project,
                strategy=EstimationStrategy.DUAL_PARALLEL,
                requirements=project.description
            )
            
            # æ‰§è¡Œå·¥ä½œæµ
            start_time = time.time()
            final_state = await workflow_instance.execute()
            execution_time = time.time() - start_time
            
            # éªŒè¯æ‰§è¡Œç»“æœ
            assert final_state.current_state == WorkflowState.COMPLETED
            assert final_state.nesma_ufp_total > 0
            assert final_state.cosmic_cfp_total > 0
            assert final_state.final_report is not None
            assert execution_time < 60  # å¤§å‹é¡¹ç›®åŒæ ‡å‡†åº”åœ¨60ç§’å†…å®Œæˆ
            
            # éªŒè¯å¯¹æ¯”åˆ†æ
            assert "comparison_analysis" in final_state.final_report
            comparison = final_state.final_report["comparison_analysis"]
            assert "variance_percentage" in comparison
            assert "recommendations" in comparison
            
            print(f"âœ… åŒæ ‡å‡†å·¥ä½œæµæµ‹è¯•å®Œæˆ: NESMA {final_state.nesma_ufp_total} UFP, "
                  f"COSMIC {final_state.cosmic_cfp_total} CFP, è€—æ—¶: {execution_time:.2f}s")
    
    @pytest.mark.asyncio
    async def test_error_handling_and_retry(self, workflow_instance, sample_projects):
        """æµ‹è¯•é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶"""
        project = sample_projects["small"]
        
        # æ¨¡æ‹Ÿç¬¬ä¸€æ¬¡å¤±è´¥ï¼Œç¬¬äºŒæ¬¡æˆåŠŸçš„åœºæ™¯
        call_count = 0
        
        def failing_then_success(*args, **kwargs):
            nonlocal call_count
            call_count += 1
            if call_count == 1:
                raise Exception("æ¨¡æ‹ŸLLMè°ƒç”¨å¤±è´¥")
            return {
                "function_type": "EI",
                "confidence": 0.9,
                "reasoning": "é‡è¯•åæˆåŠŸ"
            }
        
        with patch.object(
            workflow_instance, '_call_llm_with_retry',
            side_effect=failing_then_success
        ):
            # åˆå§‹åŒ–å·¥ä½œæµ
            session_id = await workflow_instance.initialize(
                project_info=project,
                strategy=EstimationStrategy.NESMA_ONLY,
                requirements=project.description
            )
            
            # æ‰§è¡Œå·¥ä½œæµï¼Œåº”è¯¥èƒ½å¤Ÿä»é”™è¯¯ä¸­æ¢å¤
            final_state = await workflow_instance.execute()
            
            # éªŒè¯é‡è¯•æœºåˆ¶ç”Ÿæ•ˆ
            assert call_count > 1  # ç¡®å®è¿›è¡Œäº†é‡è¯•
            assert final_state.retry_count > 0
            
            # æœ€ç»ˆåº”è¯¥æˆåŠŸæˆ–ä¼˜é›…å¤±è´¥
            assert final_state.current_state in [WorkflowState.COMPLETED, WorkflowState.FAILED]
            
            if final_state.current_state == WorkflowState.FAILED:
                assert final_state.error_message is not None
                print(f"âš ï¸ å·¥ä½œæµå¤±è´¥ä½†é”™è¯¯å¤„ç†æ­£ç¡®: {final_state.error_message}")
            else:
                print(f"âœ… é‡è¯•æœºåˆ¶æµ‹è¯•å®Œæˆ: é‡è¯•{final_state.retry_count}æ¬¡åæˆåŠŸ")
    
    @pytest.mark.asyncio
    async def test_performance_benchmark(self, workflow_instance, sample_projects):
        """æµ‹è¯•æ€§èƒ½åŸºå‡†"""
        performance_results = {}
        
        for project_size, project in sample_projects.items():
            # æ‰§è¡Œå¤šæ¬¡å–å¹³å‡å€¼
            execution_times = []
            memory_usages = []
            
            for run in range(3):  # è¿è¡Œ3æ¬¡
                # Mockç®€åŒ–çš„å“åº”ä»¥ç¡®ä¿ç¨³å®šæ€§èƒ½
                with patch.multiple(
                    'agents.standards.nesma.function_classifier.NESMAFunctionClassifierAgent',
                    execute_task=AsyncMock(return_value={"function_type": "EI", "confidence": 0.9}),
                ), patch.multiple(
                    'agents.standards.nesma.ufp_calculator.NESMAUFPCalculatorAgent',
                    execute_task=AsyncMock(return_value={"total_ufp": 25, "function_breakdown": []}),
                ):
                    # åˆå§‹åŒ–å’Œæ‰§è¡Œ
                    session_id = await workflow_instance.initialize(
                        project_info=project,
                        strategy=EstimationStrategy.NESMA_ONLY,
                        requirements=project.description
                    )
                    
                    start_time = time.time()
                    final_state = await workflow_instance.execute()
                    execution_time = time.time() - start_time
                    
                    execution_times.append(execution_time)
                    
                    # ç®€å•çš„å†…å­˜ä½¿ç”¨ä¼°ç®— (å®é™…åº”ä½¿ç”¨psutilç­‰å·¥å…·)
                    estimated_memory = len(str(final_state)) * 0.001  # KB
                    memory_usages.append(estimated_memory)
            
            # è®¡ç®—å¹³å‡æ€§èƒ½æŒ‡æ ‡
            avg_time = sum(execution_times) / len(execution_times)
            avg_memory = sum(memory_usages) / len(memory_usages)
            
            performance_results[project_size] = {
                "avg_execution_time": avg_time,
                "avg_memory_usage": avg_memory,
                "max_execution_time": max(execution_times),
                "min_execution_time": min(execution_times)
            }
            
            # æ€§èƒ½åŸºå‡†éªŒè¯
            if project_size == "small":
                assert avg_time < 15, f"å°å‹é¡¹ç›®æ‰§è¡Œæ—¶é—´è¿‡é•¿: {avg_time}s"
            elif project_size == "medium":
                assert avg_time < 30, f"ä¸­å‹é¡¹ç›®æ‰§è¡Œæ—¶é—´è¿‡é•¿: {avg_time}s"
            elif project_size == "large":
                assert avg_time < 60, f"å¤§å‹é¡¹ç›®æ‰§è¡Œæ—¶é—´è¿‡é•¿: {avg_time}s"
        
        # æ‰“å°æ€§èƒ½æŠ¥å‘Š
        print("\nğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æœ:")
        for project_size, metrics in performance_results.items():
            print(f"  {project_size.upper()}é¡¹ç›®:")
            print(f"    å¹³å‡æ‰§è¡Œæ—¶é—´: {metrics['avg_execution_time']:.2f}s")
            print(f"    æœ€å¤§æ‰§è¡Œæ—¶é—´: {metrics['max_execution_time']:.2f}s")
            print(f"    å¹³å‡å†…å­˜ä½¿ç”¨: {metrics['avg_memory_usage']:.2f}KB")
    
    def _create_nesma_mock_responses(self) -> Dict[str, List[Any]]:
        """åˆ›å»ºNESMAæ¨¡æ‹Ÿå“åº”"""
        return {
            "classifier": [
                {"function_type": "EI", "confidence": 0.9, "reasoning": "ç”¨æˆ·è¾“å…¥åŠŸèƒ½"},
                {"function_type": "EO", "confidence": 0.85, "reasoning": "æŠ¥å‘Šè¾“å‡ºåŠŸèƒ½"},
                {"function_type": "EQ", "confidence": 0.88, "reasoning": "ä¿¡æ¯æŸ¥è¯¢åŠŸèƒ½"},
                {"function_type": "ILF", "confidence": 0.92, "reasoning": "å†…éƒ¨æ•°æ®æ–‡ä»¶"},
                {"function_type": "EIF", "confidence": 0.87, "reasoning": "å¤–éƒ¨æ¥å£æ–‡ä»¶"}
            ],
            "complexity": [
                {"complexity": "AVERAGE", "det_count": 10, "ftr_count": 2},
                {"complexity": "LOW", "det_count": 5, "ftr_count": 1},
                {"complexity": "HIGH", "det_count": 20, "ftr_count": 3},
                {"complexity": "AVERAGE", "det_count": 25, "ret_count": 2},
                {"complexity": "LOW", "det_count": 8, "ret_count": 1}
            ],
            "ufp": [
                {
                    "total_ufp": 35,
                    "function_breakdown": [
                        {"type": "EI", "complexity": "AVERAGE", "weight": 4, "ufp": 4},
                        {"type": "EO", "complexity": "LOW", "weight": 4, "ufp": 4},
                        {"type": "EQ", "complexity": "HIGH", "weight": 6, "ufp": 6},
                        {"type": "ILF", "complexity": "AVERAGE", "weight": 10, "ufp": 10},
                        {"type": "EIF", "complexity": "LOW", "weight": 5, "ufp": 5}
                    ],
                    "type_summary": {"total_functions": 5}
                }
            ]
        }
    
    def _create_cosmic_mock_responses(self) -> Dict[str, List[Any]]:
        """åˆ›å»ºCOSMICæ¨¡æ‹Ÿå“åº”"""
        return {
            "functional_user": [
                {
                    "functional_users": [
                        {"name": "ä¸šåŠ¡ç”¨æˆ·", "user_type": "primary"},
                        {"name": "ç³»ç»Ÿç®¡ç†å‘˜", "user_type": "primary"},
                        {"name": "å¤–éƒ¨ç³»ç»Ÿ", "user_type": "secondary"}
                    ]
                }
            ],
            "boundary": [
                {
                    "software_boundary": {
                        "included_components": ["ä¸šåŠ¡é€»è¾‘", "æ•°æ®å¤„ç†", "ç”¨æˆ·ç•Œé¢"],
                        "excluded_components": ["å¤–éƒ¨ç³»ç»Ÿ", "ç”¨æˆ·è®¾å¤‡"]
                    },
                    "persistent_storage_boundary": {
                        "internal_storage": ["ä¸šåŠ¡æ•°æ®åº“", "é…ç½®æ•°æ®"],
                        "external_storage": ["å¤–éƒ¨æ•°æ®æº"]
                    }
                }
            ],
            "data_movement": [
                {
                    "data_movements": [
                        {"type": "Entry", "description": "ç”¨æˆ·è¾“å…¥ä¸šåŠ¡æ•°æ®"},
                        {"type": "Read", "description": "è¯»å–ä¸šåŠ¡é…ç½®"},
                        {"type": "Write", "description": "ä¿å­˜ä¸šåŠ¡ç»“æœ"},
                        {"type": "Exit", "description": "è¿”å›å¤„ç†ç»“æœ"}
                    ]
                }
            ],
            "cfp": [
                {
                    "total_cfp": 28,
                    "functional_processes": [
                        {
                            "name": "ä¸šåŠ¡å¤„ç†æµç¨‹",
                            "cfp": 28,
                            "movement_count": {"Entry": 7, "Exit": 7, "Read": 7, "Write": 7}
                        }
                    ],
                    "cfp_breakdown": {"Entry": 7, "Exit": 7, "Read": 7, "Write": 7, "total": 28}
                }
            ]
        }


class TestWorkflowRecovery:
    """å·¥ä½œæµæ¢å¤å’ŒçŠ¶æ€ç®¡ç†æµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_workflow_state_persistence(self):
        """æµ‹è¯•å·¥ä½œæµçŠ¶æ€æŒä¹…åŒ–"""
        # è¿™ä¸ªæµ‹è¯•éœ€è¦çœŸå®çš„çŠ¶æ€å­˜å‚¨æœºåˆ¶
        # è¿™é‡Œæä¾›æµ‹è¯•æ¡†æ¶ï¼Œå®é™…å®ç°éœ€è¦æ ¹æ®å…·ä½“çš„æŒä¹…åŒ–æ–¹æ¡ˆ
        pass
    
    @pytest.mark.asyncio
    async def test_workflow_checkpoint_recovery(self):
        """æµ‹è¯•å·¥ä½œæµæ£€æŸ¥ç‚¹æ¢å¤"""
        # æµ‹è¯•ä»ä¸­é—´æ£€æŸ¥ç‚¹æ¢å¤æ‰§è¡Œ
        pass


class TestConcurrentWorkflows:
    """å¹¶å‘å·¥ä½œæµæµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_multiple_concurrent_estimations(self):
        """æµ‹è¯•å¤šä¸ªå¹¶å‘ä¼°ç®—"""
        # åˆ›å»ºå¤šä¸ªå·¥ä½œæµå®ä¾‹å¹¶å‘æ‰§è¡Œ
        workflows = [FPEstimationWorkflow() for _ in range(3)]
        sample_project = ProjectInfo(
            name="æµ‹è¯•é¡¹ç›®",
            description="å¹¶å‘æµ‹è¯•é¡¹ç›®",
            technology_stack=[TechnologyStack.PYTHON],
            business_domain=BusinessDomain.OTHER
        )
        
        # å¹¶å‘æ‰§è¡Œå¤šä¸ªä¼°ç®—
        tasks = []
        for i, workflow in enumerate(workflows):
            task = asyncio.create_task(self._run_single_estimation(workflow, sample_project, i))
            tasks.append(task)
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # éªŒè¯ç»“æœ
        successful_results = [r for r in results if not isinstance(r, Exception)]
        failed_results = [r for r in results if isinstance(r, Exception)]
        
        print(f"å¹¶å‘æµ‹è¯•ç»“æœ: {len(successful_results)}æˆåŠŸ, {len(failed_results)}å¤±è´¥")
        
        # è‡³å°‘åº”æœ‰ä¸€åŠæˆåŠŸ
        assert len(successful_results) >= len(workflows) // 2
    
    async def _run_single_estimation(self, workflow, project, task_id):
        """è¿è¡Œå•ä¸ªä¼°ç®—ä»»åŠ¡"""
        try:
            with patch.multiple(
                'agents.standards.nesma.ufp_calculator.NESMAUFPCalculatorAgent',
                execute_task=AsyncMock(return_value={"total_ufp": 20 + task_id}),
            ):
                session_id = await workflow.initialize(
                    project_info=project,
                    strategy=EstimationStrategy.NESMA_ONLY,
                    requirements=project.description
                )
                
                final_state = await workflow.execute()
                return {"task_id": task_id, "result": final_state.nesma_ufp_total}
        except Exception as e:
            return {"task_id": task_id, "error": str(e)}


@pytest.mark.asyncio
async def test_full_system_integration():
    """å®Œæ•´ç³»ç»Ÿé›†æˆæµ‹è¯•"""
    # è¿™æ˜¯ä¸€ä¸ªç»¼åˆæ€§æµ‹è¯•ï¼ŒéªŒè¯æ•´ä¸ªç³»ç»Ÿçš„ç«¯åˆ°ç«¯åŠŸèƒ½
    print("\nğŸš€ å¼€å§‹å®Œæ•´ç³»ç»Ÿé›†æˆæµ‹è¯•...")
    
    # æµ‹è¯•é¡¹ç›®
    test_project = ProjectInfo(
        name="ç»¼åˆæµ‹è¯•ç”µå•†å¹³å°",
        description="""
        å®Œæ•´çš„ç”µå•†å¹³å°åŠŸèƒ½ï¼š
        1. ç”¨æˆ·ç®¡ç†ï¼šæ³¨å†Œã€ç™»å½•ã€èµ„æ–™ç®¡ç†
        2. å•†å“ç®¡ç†ï¼šå•†å“å½•å…¥ã€åˆ†ç±»ã€åº“å­˜ç®¡ç†
        3. è®¢å•ç®¡ç†ï¼šä¸‹å•ã€æ”¯ä»˜ã€å‘è´§ã€é€€è´§
        4. å®¢æœç³»ç»Ÿï¼šåœ¨çº¿å’¨è¯¢ã€å·¥å•å¤„ç†
        5. æ•°æ®åˆ†æï¼šé”€å”®ç»Ÿè®¡ã€ç”¨æˆ·è¡Œä¸ºåˆ†æ
        """,
        technology_stack=[TechnologyStack.JAVA, TechnologyStack.MYSQL, TechnologyStack.REDIS],
        business_domain=BusinessDomain.ECOMMERCE
    )
    
    # åˆ›å»ºå·¥ä½œæµå®ä¾‹
    workflow = FPEstimationWorkflow()
    
    # ä½¿ç”¨å®é™…çš„æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œå®Œæ•´æµ‹è¯•
    with patch('agents.base.base_agent.BaseAgent._call_llm') as mock_llm:
        # é…ç½®æ¨¡æ‹Ÿè¿”å›
        mock_llm.side_effect = [
            {"recommended_standards": ["NESMA", "COSMIC"], "strategy": "DUAL_PARALLEL"},
            {"identified_processes": [{"name": "ç”¨æˆ·ç®¡ç†", "description": "ç”¨æˆ·æ³¨å†Œç™»å½•"}]},
            {"function_type": "EI", "confidence": 0.9},
            {"complexity": "AVERAGE", "det_count": 10},
            {"total_ufp": 45, "function_breakdown": []},
            {"functional_users": [{"name": "ç”¨æˆ·", "type": "primary"}]},
            {"software_boundary": {"included": ["ç”¨æˆ·æ¨¡å—"]}},
            {"data_movements": [{"type": "Entry", "description": "ç”¨æˆ·è¾“å…¥"}]},
            {"total_cfp": 38, "functional_processes": []},
            {"final_report": {"summary": "ä¼°ç®—å®Œæˆ"}}
        ]
        
        # æ‰§è¡Œå®Œæ•´å·¥ä½œæµ
        session_id = await workflow.initialize(
            project_info=test_project,
            strategy=EstimationStrategy.DUAL_PARALLEL,
            requirements=test_project.description
        )
        
        start_time = time.time()
        final_state = await workflow.execute()
        total_time = time.time() - start_time
        
        # éªŒè¯æœ€ç»ˆç»“æœ
        assert final_state.current_state == WorkflowState.COMPLETED
        assert final_state.nesma_ufp_total > 0
        assert final_state.cosmic_cfp_total > 0
        assert final_state.final_report is not None
        
        print(f"âœ… ç³»ç»Ÿé›†æˆæµ‹è¯•å®Œæˆ!")
        print(f"   NESMAç»“æœ: {final_state.nesma_ufp_total} UFP")
        print(f"   COSMICç»“æœ: {final_state.cosmic_cfp_total} CFP")
        print(f"   æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"   ä¼šè¯ID: {session_id}")


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"]) 