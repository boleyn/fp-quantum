"""
é‡å­æ™ºèƒ½åŒ–åŠŸèƒ½ç‚¹ä¼°ç®—ç³»ç»Ÿ - MongoDB Atlaså‘é‡å­˜å‚¨

MongoDB Atlas Vector Searché›†æˆï¼Œæ”¯æŒç”Ÿäº§ç¯å¢ƒçš„å‘é‡å­˜å‚¨å’Œæ£€ç´¢
"""

import asyncio
from typing import List, Dict, Any, Optional, Tuple
import logging

from langchain_core.documents import Document
from langchain_mongodb import MongoDBAtlasVectorSearch
from langchain_core.embeddings import Embeddings
from motor.motor_asyncio import AsyncIOMotorClient, AsyncIOMotorDatabase, AsyncIOMotorCollection
import pymongo

from config.settings import get_settings
from models.common_models import EstimationStandard

logger = logging.getLogger(__name__)


class MongoDBAtlasVectorManager:
    """MongoDB Atlaså‘é‡å­˜å‚¨ç®¡ç†å™¨"""
    
    def __init__(self):
        self.settings = get_settings()
        self.client: Optional[AsyncIOMotorClient] = None
        self.database: Optional[AsyncIOMotorDatabase] = None
        self.collections: Dict[str, AsyncIOMotorCollection] = {}
        
        # é›†åˆåç§°æ˜ å°„
        self.collection_names = {
            "nesma": "nesma_knowledge_vectors",
            "cosmic": "cosmic_knowledge_vectors", 
            "common": "common_knowledge_vectors",
            "mixed": "mixed_knowledge_vectors"
        }
    
    async def initialize(self):
        """åˆå§‹åŒ–MongoDB Atlasè¿æ¥"""
        try:
            # åˆ›å»ºå¼‚æ­¥å®¢æˆ·ç«¯
            mongodb_url = self.settings.database.mongodb_url
            self.client = AsyncIOMotorClient(
                mongodb_url,
                maxPoolSize=self.settings.database.mongodb_max_pool_size,
                minPoolSize=self.settings.database.mongodb_min_pool_size,
                maxIdleTimeMS=self.settings.database.mongodb_max_idle_time_ms,
            )
            
            # é€‰æ‹©æ•°æ®åº“
            if self.settings.database.mongodb_atlas_uri:
                db_name = self.settings.database.mongodb_atlas_db
            else:
                db_name = self.settings.database.mongodb_db
            
            self.database = self.client[db_name]
            
            # åˆå§‹åŒ–é›†åˆ
            for source_type, collection_name in self.collection_names.items():
                self.collections[source_type] = self.database[collection_name]
            
            # éªŒè¯è¿æ¥
            await self.client.admin.command('ismaster')
            logger.info(f"âœ… MongoDB Atlasè¿æ¥æˆåŠŸ: {db_name}")
            
            # åˆ›å»ºå‘é‡æœç´¢ç´¢å¼•
            await self._ensure_vector_indexes()
            
        except Exception as e:
            logger.error(f"âŒ MongoDB Atlasè¿æ¥å¤±è´¥: {str(e)}")
            raise
    
    async def _ensure_vector_indexes(self):
        """ç¡®ä¿å‘é‡æœç´¢ç´¢å¼•å­˜åœ¨"""
        index_definition = {
            "name": "vector_index",
            "type": "vectorSearch",
            "definition": {
                "fields": [
                    {
                        "type": "vector",
                        "path": "embedding",
                        "numDimensions": self.settings.llm.embedding_dimensions,
                        "similarity": "cosine"
                    },
                    {
                        "type": "filter",
                        "path": "source_type"
                    },
                    {
                        "type": "filter", 
                        "path": "standard"
                    },
                    {
                        "type": "filter",
                        "path": "document_type"
                    }
                ]
            }
        }
        
        for source_type, collection in self.collections.items():
            try:
                # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨
                existing_indexes = await collection.list_indexes().to_list(length=None)
                vector_index_exists = any(
                    idx.get("name") == "vector_index" for idx in existing_indexes
                )
                
                if not vector_index_exists:
                    # ä½¿ç”¨åŒæ­¥å®¢æˆ·ç«¯åˆ›å»ºç´¢å¼•ï¼ˆMongoDB Atlasè¦æ±‚ï¼‰
                    sync_client = pymongo.MongoClient(self.settings.database.mongodb_url)
                    sync_db = sync_client[self.database.name]
                    sync_collection = sync_db[collection.name]
                    
                    # åˆ›å»ºå‘é‡æœç´¢ç´¢å¼•
                    sync_collection.create_search_index(index_definition)
                    logger.info(f"âœ… ä¸ºé›†åˆ {collection.name} åˆ›å»ºå‘é‡ç´¢å¼•")
                    
                    sync_client.close()
                
            except Exception as e:
                logger.warning(f"âš ï¸ ä¸ºé›†åˆ {collection.name} åˆ›å»ºå‘é‡ç´¢å¼•å¤±è´¥: {str(e)}")
    
    async def add_documents(
        self,
        documents: List[Document],
        embeddings: Embeddings,
        source_type: str = "common"
    ) -> List[str]:
        """æ·»åŠ æ–‡æ¡£åˆ°å‘é‡å­˜å‚¨"""
        if source_type not in self.collections:
            raise ValueError(f"ä¸æ”¯æŒçš„æºç±»å‹: {source_type}")
        
        collection = self.collections[source_type]
        
        # ç”ŸæˆåµŒå…¥å‘é‡
        texts = [doc.page_content for doc in documents]
        embeddings_list = await embeddings.aembed_documents(texts)
        
        # å‡†å¤‡æ’å…¥æ•°æ®
        docs_to_insert = []
        for i, (doc, embedding) in enumerate(zip(documents, embeddings_list)):
            doc_dict = {
                "text": doc.page_content,
                "embedding": embedding,
                "metadata": doc.metadata,
                "source_type": source_type.upper(),
                "standard": doc.metadata.get("standard", source_type.upper()),
                "document_type": doc.metadata.get("document_type", "general"),
                "chunk_index": i,
                "source": doc.metadata.get("source", "unknown")
            }
            docs_to_insert.append(doc_dict)
        
        # æ‰¹é‡æ’å…¥
        result = await collection.insert_many(docs_to_insert)
        inserted_ids = [str(id) for id in result.inserted_ids]
        
        logger.info(f"âœ… æˆåŠŸæ·»åŠ  {len(inserted_ids)} ä¸ªæ–‡æ¡£åˆ° {source_type} é›†åˆ")
        return inserted_ids
    
    async def similarity_search(
        self,
        query: str,
        embeddings: Embeddings,
        source_type: Optional[str] = None,
        k: int = 5,
        filter_dict: Optional[Dict[str, Any]] = None
    ) -> List[Tuple[Document, float]]:
        """ç›¸ä¼¼åº¦æœç´¢"""
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = await embeddings.aembed_query(query)
        
        # å¦‚æœæŒ‡å®šäº†source_typeï¼Œåªåœ¨å¯¹åº”é›†åˆä¸­æœç´¢
        if source_type and source_type in self.collections:
            collections_to_search = [self.collections[source_type]]
        else:
            # åœ¨æ‰€æœ‰é›†åˆä¸­æœç´¢
            collections_to_search = list(self.collections.values())
        
        all_results = []
        
        for collection in collections_to_search:
            try:
                # æ„å»ºæœç´¢ç®¡é“
                pipeline = [
                    {
                        "$vectorSearch": {
                            "index": "vector_index",
                            "path": "embedding",
                            "queryVector": query_embedding,
                            "numCandidates": k * 2,  # è·å–æ›´å¤šå€™é€‰é¡¹
                            "limit": k,
                        }
                    },
                    {
                        "$project": {
                            "text": 1,
                            "metadata": 1,
                            "source_type": 1,
                            "standard": 1,
                            "document_type": 1,
                            "score": {"$meta": "vectorSearchScore"}
                        }
                    }
                ]
                
                # æ·»åŠ è¿‡æ»¤æ¡ä»¶
                if filter_dict:
                    match_stage = {"$match": filter_dict}
                    pipeline.insert(1, match_stage)
                
                # æ‰§è¡Œæœç´¢
                cursor = collection.aggregate(pipeline)
                results = await cursor.to_list(length=k)
                
                # è½¬æ¢ä¸ºDocumentå’Œåˆ†æ•°çš„å…ƒç»„
                for result in results:
                    doc = Document(
                        page_content=result["text"],
                        metadata=result["metadata"]
                    )
                    score = result["score"]
                    all_results.append((doc, score))
                    
            except Exception as e:
                logger.warning(f"âš ï¸ åœ¨é›†åˆ {collection.name} ä¸­æœç´¢å¤±è´¥: {str(e)}")
                continue
        
        # æŒ‰åˆ†æ•°æ’åºå¹¶è¿”å›top-kç»“æœ
        all_results.sort(key=lambda x: x[1], reverse=True)
        return all_results[:k]
    
    async def delete_documents(
        self,
        source_type: str,
        filter_dict: Optional[Dict[str, Any]] = None
    ) -> int:
        """åˆ é™¤æ–‡æ¡£"""
        if source_type not in self.collections:
            raise ValueError(f"ä¸æ”¯æŒçš„æºç±»å‹: {source_type}")
        
        collection = self.collections[source_type]
        
        if filter_dict:
            result = await collection.delete_many(filter_dict)
        else:
            result = await collection.delete_many({})
        
        logger.info(f"âœ… ä» {source_type} é›†åˆåˆ é™¤äº† {result.deleted_count} ä¸ªæ–‡æ¡£")
        return result.deleted_count
    
    async def get_collection_stats(self, source_type: str) -> Dict[str, Any]:
        """è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯"""
        if source_type not in self.collections:
            raise ValueError(f"ä¸æ”¯æŒçš„æºç±»å‹: {source_type}")
        
        collection = self.collections[source_type]
        
        # è·å–æ–‡æ¡£æ•°é‡
        total_docs = await collection.count_documents({})
        
        # è·å–æŒ‰æ ‡å‡†åˆ†ç»„çš„ç»Ÿè®¡
        pipeline = [
            {
                "$group": {
                    "_id": "$standard",
                    "count": {"$sum": 1},
                    "doc_types": {"$addToSet": "$document_type"}
                }
            }
        ]
        
        cursor = collection.aggregate(pipeline)
        standard_stats = await cursor.to_list(length=None)
        
        stats = {
            "total_documents": total_docs,
            "collection_name": collection.name,
            "standards": {
                stat["_id"]: {
                    "count": stat["count"],
                    "document_types": stat["doc_types"]
                }
                for stat in standard_stats
            }
        }
        
        return stats
    
    async def close(self):
        """å…³é—­è¿æ¥"""
        if self.client:
            self.client.close()
            logger.info("âœ… MongoDB Atlasè¿æ¥å·²å…³é—­")


def create_langchain_vector_store(
    source_type: str,
    embeddings: Embeddings,
    mongodb_manager: MongoDBAtlasVectorManager
) -> MongoDBAtlasVectorSearch:
    """åˆ›å»ºLangChain MongoDB Atlaså‘é‡å­˜å‚¨å®ä¾‹"""
    if source_type not in mongodb_manager.collection_names:
        raise ValueError(f"ä¸æ”¯æŒçš„æºç±»å‹: {source_type}")
    
    collection_name = mongodb_manager.collection_names[source_type]
    
    # ä½¿ç”¨åŒæ­¥å®¢æˆ·ç«¯åˆ›å»ºLangChainå‘é‡å­˜å‚¨
    sync_client = pymongo.MongoClient(mongodb_manager.settings.database.mongodb_url)
    
    if mongodb_manager.settings.database.mongodb_atlas_uri:
        db_name = mongodb_manager.settings.database.mongodb_atlas_db
    else:
        db_name = mongodb_manager.settings.database.mongodb_db
    
    vector_store = MongoDBAtlasVectorSearch(
        collection=sync_client[db_name][collection_name],
        embedding=embeddings,
        index_name="vector_index",
        text_key="text",
        embedding_key="embedding",
    )
    
    return vector_store


async def setup_mongodb_vector_stores(
    documents_by_type: Dict[str, List[Document]],
    embeddings: Embeddings
) -> MongoDBAtlasVectorManager:
    """è®¾ç½®MongoDB Atlaså‘é‡å­˜å‚¨"""
    manager = MongoDBAtlasVectorManager()
    await manager.initialize()
    
    for source_type, documents in documents_by_type.items():
        if documents:
            try:
                await manager.add_documents(documents, embeddings, source_type)
                logger.info(f"âœ… æˆåŠŸè®¾ç½® {source_type} å‘é‡å­˜å‚¨")
            except Exception as e:
                logger.error(f"âŒ è®¾ç½® {source_type} å‘é‡å­˜å‚¨å¤±è´¥: {str(e)}")
    
    return manager


if __name__ == "__main__":
    async def main():
        # æµ‹è¯•MongoDB Atlaså‘é‡å­˜å‚¨
        from knowledge_base.embeddings.embedding_models import get_default_embedding_model
        
        manager = MongoDBAtlasVectorManager()
        await manager.initialize()
        
        # è·å–æ‰€æœ‰é›†åˆçš„ç»Ÿè®¡ä¿¡æ¯
        for source_type in manager.collection_names.keys():
            try:
                stats = await manager.get_collection_stats(source_type)
                print(f"\nğŸ“Š {source_type.upper()} é›†åˆç»Ÿè®¡:")
                print(f"  æ€»æ–‡æ¡£æ•°: {stats['total_documents']}")
                print(f"  é›†åˆåç§°: {stats['collection_name']}")
                print(f"  æ ‡å‡†åˆ†å¸ƒ: {stats['standards']}")
            except Exception as e:
                print(f"âŒ è·å– {source_type} ç»Ÿè®¡å¤±è´¥: {str(e)}")
        
        await manager.close()
    
    asyncio.run(main()) 