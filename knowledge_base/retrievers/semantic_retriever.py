"""
é‡å­æ™ºèƒ½åŒ–åŠŸèƒ½ç‚¹ä¼°ç®—ç³»ç»Ÿ - è¯­ä¹‰æ£€ç´¢å™¨

å®ç°å¤šç§é«˜çº§æ£€ç´¢ç­–ç•¥ï¼ŒåŒ…æ‹¬å¤šæŸ¥è¯¢æ£€ç´¢ã€ä¸Šä¸‹æ–‡å‹ç¼©ã€æ··åˆæ£€ç´¢ç­‰
"""

import asyncio
from typing import List, Dict, Any, Optional, Tuple
import logging

from langchain_core.documents import Document
from langchain_core.embeddings import Embeddings
from langchain_core.language_models import BaseLanguageModel
from langchain.retrievers.multi_query import MultiQueryRetriever
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMChainExtractor
from langchain_core.retrievers import BaseRetriever
from langchain_core.callbacks import CallbackManagerForRetrieverRun
from langchain_community.retrievers import BM25Retriever

from knowledge_base.vector_stores.mongodb_atlas import MongoDBAtlasVectorManager, create_langchain_vector_store
from knowledge_base.embeddings.embedding_models import get_default_embedding_model
from models.common_models import EstimationStandard, RetrievalResult, KnowledgeChunk, ValidationResult
from config.settings import get_settings

logger = logging.getLogger(__name__)


class EnhancedSemanticRetriever(BaseRetriever):
    """å¢å¼ºçš„è¯­ä¹‰æ£€ç´¢å™¨"""
    
    def __init__(
        self,
        vector_manager: MongoDBAtlasVectorManager,
        embeddings: Embeddings,
        llm: Optional[BaseLanguageModel] = None,
        source_type: Optional[str] = None,
        use_multi_query: bool = True,
        use_compression: bool = True,
        k: int = 5
    ):
        super().__init__()
        self.vector_manager = vector_manager
        self.embeddings = embeddings
        self.llm = llm
        self.source_type = source_type
        self.use_multi_query = use_multi_query
        self.use_compression = use_compression
        self.k = k
        self.settings = get_settings()
        
        # åˆ›å»ºåŸºç¡€å‘é‡æ£€ç´¢å™¨
        if source_type:
            self.vector_store = create_langchain_vector_store(
                source_type, embeddings, vector_manager
            )
            self.base_retriever = self.vector_store.as_retriever(search_kwargs={"k": k})
        else:
            self.base_retriever = None
        
        # åˆ›å»ºå¢å¼ºæ£€ç´¢å™¨
        self._setup_enhanced_retrievers()
    
    def _setup_enhanced_retrievers(self):
        """è®¾ç½®å¢å¼ºæ£€ç´¢å™¨"""
        if not self.base_retriever:
            return
        
        # å¤šæŸ¥è¯¢æ£€ç´¢å™¨
        if self.use_multi_query and self.llm:
            try:
                self.multi_query_retriever = MultiQueryRetriever.from_llm(
                    retriever=self.base_retriever,
                    llm=self.llm,
                    include_original=True
                )
            except Exception as e:
                logger.warning(f"âš ï¸ å¤šæŸ¥è¯¢æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                self.multi_query_retriever = self.base_retriever
        else:
            self.multi_query_retriever = self.base_retriever
        
        # ä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨
        if self.use_compression and self.llm:
            try:
                compressor = LLMChainExtractor.from_llm(self.llm)
                self.compression_retriever = ContextualCompressionRetriever(
                    base_compressor=compressor,
                    base_retriever=self.multi_query_retriever
                )
            except Exception as e:
                logger.warning(f"âš ï¸ ä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                self.compression_retriever = self.multi_query_retriever
        else:
            self.compression_retriever = self.multi_query_retriever
    
    def _get_relevant_documents(
        self,
        query: str,
        *,
        run_manager: CallbackManagerForRetrieverRun
    ) -> List[Document]:
        """è·å–ç›¸å…³æ–‡æ¡£ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
        # ç”±äºåŸºç¡€æ¥å£æ˜¯åŒæ­¥çš„ï¼Œè¿™é‡Œéœ€è¦å¤„ç†å¼‚æ­¥é€»è¾‘
        import asyncio
        try:
            loop = asyncio.get_event_loop()
            return loop.run_until_complete(self.aget_relevant_documents(query))
        except RuntimeError:
            # å¦‚æœæ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„
            return asyncio.run(self.aget_relevant_documents(query))
    
    async def aget_relevant_documents(self, query: str) -> List[Document]:
        """å¼‚æ­¥è·å–ç›¸å…³æ–‡æ¡£"""
        if self.vector_manager and not self.base_retriever:
            # ç›´æ¥ä½¿ç”¨å‘é‡ç®¡ç†å™¨è¿›è¡Œæœç´¢
            results = await self.vector_manager.similarity_search(
                query=query,
                embeddings=self.embeddings,
                source_type=self.source_type,
                k=self.k
            )
            return [doc for doc, score in results]
        
        # ä½¿ç”¨å¢å¼ºæ£€ç´¢å™¨
        if self.compression_retriever:
            return await self.compression_retriever.aget_relevant_documents(query)
        elif self.multi_query_retriever:
            return await self.multi_query_retriever.aget_relevant_documents(query)
        else:
            return await self.base_retriever.aget_relevant_documents(query)
    
    async def similarity_search_with_score(
        self,
        query: str,
        k: Optional[int] = None
    ) -> List[Tuple[Document, float]]:
        """å¸¦åˆ†æ•°çš„ç›¸ä¼¼åº¦æœç´¢"""
        k = k or self.k
        
        if self.vector_manager:
            return await self.vector_manager.similarity_search(
                query=query,
                embeddings=self.embeddings,
                source_type=self.source_type,
                k=k
            )
        else:
            # ä½¿ç”¨åŸºç¡€æ£€ç´¢å™¨ï¼Œä½†æ— æ³•è·å–åˆ†æ•°
            docs = await self.aget_relevant_documents(query)
            return [(doc, 1.0) for doc in docs[:k]]


class MultiSourceRetriever:
    """å¤šæºæ£€ç´¢å™¨ - æ”¯æŒè·¨NESMAã€COSMICã€é€šç”¨çŸ¥è¯†åº“æ£€ç´¢"""
    
    def __init__(
        self,
        vector_manager: MongoDBAtlasVectorManager,
        embeddings: Embeddings,
        llm: Optional[BaseLanguageModel] = None
    ):
        self.vector_manager = vector_manager
        self.embeddings = embeddings
        self.llm = llm
        self.settings = get_settings()
        
        # ä¸ºæ¯ä¸ªçŸ¥è¯†æºåˆ›å»ºæ£€ç´¢å™¨
        self.retrievers = {}
        for source_type in ["nesma", "cosmic", "common"]:
            self.retrievers[source_type] = EnhancedSemanticRetriever(
                vector_manager=vector_manager,
                embeddings=embeddings,
                llm=llm,
                source_type=source_type,
                k=5
            )
    
    async def retrieve_by_source(
        self,
        query: str,
        source_type: str,
        k: int = 5
    ) -> RetrievalResult:
        """æŒ‰æŒ‡å®šçŸ¥è¯†æºæ£€ç´¢"""
        import time
        start_time = time.time()
        
        if source_type not in self.retrievers:
            raise ValueError(f"ä¸æ”¯æŒçš„çŸ¥è¯†æº: {source_type}")
        
        retriever = self.retrievers[source_type]
        
        # æ‰§è¡Œæ£€ç´¢
        try:
            docs_with_scores = await retriever.similarity_search_with_score(query, k)
            
            # è½¬æ¢ä¸ºKnowledgeChunk
            chunks = []
            for doc, score in docs_with_scores:
                chunk = KnowledgeChunk(
                    chunk_id=f"{source_type}_{hash(doc.page_content)%1000000}",
                    content=doc.page_content,
                    source_document=doc.metadata.get("source", "unknown"),
                    source_type=EstimationStandard(source_type.upper()),
                    chunk_index=doc.metadata.get("chunk_index", 0),
                    relevance_score=score,
                    metadata=doc.metadata
                )
                chunks.append(chunk)
            
            retrieval_time = int((time.time() - start_time) * 1000)
            
            return RetrievalResult(
                query=query,
                source_type=EstimationStandard(source_type.upper()),
                retrieved_chunks=chunks,
                total_chunks=len(chunks),
                retrieval_time_ms=retrieval_time
            )
            
        except Exception as e:
            logger.error(f"âŒ {source_type} æ£€ç´¢å¤±è´¥: {str(e)}")
            return RetrievalResult(
                query=query,
                source_type=EstimationStandard(source_type.upper()),
                retrieved_chunks=[],
                total_chunks=0,
                retrieval_time_ms=int((time.time() - start_time) * 1000)
            )
    
    async def retrieve_multi_source(
        self,
        query: str,
        sources: List[str] = ["nesma", "cosmic", "common"],
        k_per_source: int = 3
    ) -> Dict[str, RetrievalResult]:
        """å¤šæºå¹¶è¡Œæ£€ç´¢"""
        tasks = []
        for source in sources:
            if source in self.retrievers:
                task = self.retrieve_by_source(query, source, k_per_source)
                tasks.append((source, task))
        
        results = {}
        if tasks:
            completed_tasks = await asyncio.gather(
                *[task for _, task in tasks],
                return_exceptions=True
            )
            
            for (source, _), result in zip(tasks, completed_tasks):
                if isinstance(result, Exception):
                    logger.error(f"âŒ {source} æ£€ç´¢å¼‚å¸¸: {str(result)}")
                    results[source] = RetrievalResult(
                        query=query,
                        source_type=EstimationStandard(source.upper()),
                        retrieved_chunks=[],
                        total_chunks=0,
                        retrieval_time_ms=0
                    )
                else:
                    results[source] = result
        
        return results
    
    async def adaptive_retrieve(
        self,
        query: str,
        preferred_source: Optional[str] = None,
        fallback_sources: Optional[List[str]] = None,
        min_chunks: int = 3
    ) -> RetrievalResult:
        """è‡ªé€‚åº”æ£€ç´¢ - æ ¹æ®ç»“æœè´¨é‡åŠ¨æ€é€‰æ‹©çŸ¥è¯†æº"""
        
        # ç¡®å®šæ£€ç´¢é¡ºåº
        if preferred_source:
            sources_to_try = [preferred_source]
            if fallback_sources:
                sources_to_try.extend(fallback_sources)
            else:
                # é»˜è®¤å¤‡ç”¨æº
                all_sources = ["nesma", "cosmic", "common"]
                sources_to_try.extend([s for s in all_sources if s != preferred_source])
        else:
            sources_to_try = ["nesma", "cosmic", "common"]
        
        # é€ä¸ªå°è¯•æ£€ç´¢
        for source in sources_to_try:
            if source not in self.retrievers:
                continue
            
            result = await self.retrieve_by_source(query, source, 5)
            
            # æ£€æŸ¥ç»“æœè´¨é‡
            if self._is_result_sufficient(result, min_chunks):
                logger.info(f"âœ… ä½¿ç”¨ {source} çŸ¥è¯†æºæ£€ç´¢æˆåŠŸï¼Œè·å¾— {len(result.retrieved_chunks)} ä¸ªé«˜è´¨é‡ç»“æœ")
                return result
            else:
                logger.info(f"âš ï¸ {source} çŸ¥è¯†æºç»“æœä¸è¶³ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæº")
        
        # å¦‚æœæ‰€æœ‰å•ä¸€æºéƒ½ä¸è¶³ï¼Œå°è¯•åˆå¹¶æ£€ç´¢
        logger.info("ğŸ“Š æ‰§è¡Œå¤šæºåˆå¹¶æ£€ç´¢")
        multi_results = await self.retrieve_multi_source(query, sources_to_try, 2)
        
        # åˆå¹¶æ‰€æœ‰ç»“æœ
        all_chunks = []
        total_time = 0
        for result in multi_results.values():
            all_chunks.extend(result.retrieved_chunks)
            total_time += result.retrieval_time_ms
        
        # æŒ‰ç›¸å…³æ€§æ’åº
        all_chunks.sort(key=lambda x: x.relevance_score, reverse=True)
        
        return RetrievalResult(
            query=query,
            source_type=EstimationStandard.BOTH,
            retrieved_chunks=all_chunks[:10],  # æœ€å¤šè¿”å›10ä¸ªç»“æœ
            total_chunks=len(all_chunks),
            retrieval_time_ms=total_time
        )
    
    def _is_result_sufficient(self, result: RetrievalResult, min_chunks: int) -> bool:
        """åˆ¤æ–­æ£€ç´¢ç»“æœæ˜¯å¦å……è¶³"""
        if len(result.retrieved_chunks) < min_chunks:
            return False
        
        # æ£€æŸ¥ç›¸å…³æ€§é˜ˆå€¼
        high_quality_chunks = [
            chunk for chunk in result.retrieved_chunks 
            if chunk.relevance_score > 0.7
        ]
        
        return len(high_quality_chunks) >= min_chunks


class HybridRetriever:
    """æ··åˆæ£€ç´¢å™¨ - ç»“åˆå‘é‡æ£€ç´¢å’Œå…³é”®è¯æ£€ç´¢"""
    
    def __init__(
        self,
        semantic_retriever: EnhancedSemanticRetriever,
        documents: Optional[List[Document]] = None
    ):
        self.semantic_retriever = semantic_retriever
        
        # åˆ›å»ºBM25å…³é”®è¯æ£€ç´¢å™¨
        if documents:
            self.keyword_retriever = BM25Retriever.from_documents(documents)
        else:
            self.keyword_retriever = None
    
    async def hybrid_search(
        self,
        query: str,
        semantic_weight: float = 0.7,
        keyword_weight: float = 0.3,
        k: int = 5
    ) -> List[Tuple[Document, float]]:
        """æ··åˆæ£€ç´¢ï¼šç»“åˆè¯­ä¹‰å’Œå…³é”®è¯æœç´¢"""
        
        # è¯­ä¹‰æ£€ç´¢
        semantic_results = await self.semantic_retriever.similarity_search_with_score(
            query, k=k
        )
        
        # å…³é”®è¯æ£€ç´¢
        keyword_results = []
        if self.keyword_retriever:
            try:
                keyword_docs = await self.keyword_retriever.aget_relevant_documents(query)
                # BM25æ²¡æœ‰ç›´æ¥åˆ†æ•°ï¼Œä½¿ç”¨å›ºå®šåˆ†æ•°
                keyword_results = [(doc, 0.8) for doc in keyword_docs[:k]]
            except Exception as e:
                logger.warning(f"âš ï¸ å…³é”®è¯æ£€ç´¢å¤±è´¥: {str(e)}")
        
        # åˆå¹¶å’Œé‡æ–°æ’åº
        all_results = {}
        
        # æ·»åŠ è¯­ä¹‰æ£€ç´¢ç»“æœ
        for doc, score in semantic_results:
            doc_key = hash(doc.page_content)
            if doc_key not in all_results:
                all_results[doc_key] = (doc, 0.0)
            all_results[doc_key] = (
                all_results[doc_key][0],
                all_results[doc_key][1] + score * semantic_weight
            )
        
        # æ·»åŠ å…³é”®è¯æ£€ç´¢ç»“æœ
        for doc, score in keyword_results:
            doc_key = hash(doc.page_content)
            if doc_key not in all_results:
                all_results[doc_key] = (doc, 0.0)
            all_results[doc_key] = (
                all_results[doc_key][0],
                all_results[doc_key][1] + score * keyword_weight
            )
        
        # æŒ‰ç»¼åˆåˆ†æ•°æ’åº
        sorted_results = sorted(
            all_results.values(),
            key=lambda x: x[1],
            reverse=True
        )
        
        return sorted_results[:k]


async def create_knowledge_retrievers(
    vector_manager: MongoDBAtlasVectorManager,
    embeddings: Optional[Embeddings] = None,
    llm: Optional[BaseLanguageModel] = None
) -> Dict[str, Any]:
    """åˆ›å»ºçŸ¥è¯†æ£€ç´¢å™¨é›†åˆ"""
    
    if embeddings is None:
        embeddings = get_default_embedding_model()
    
    # åˆ›å»ºå¤šæºæ£€ç´¢å™¨
    multi_source_retriever = MultiSourceRetriever(
        vector_manager=vector_manager,
        embeddings=embeddings,
        llm=llm
    )
    
    # ä¸ºæ¯ä¸ªæ ‡å‡†åˆ›å»ºä¸“ç”¨æ£€ç´¢å™¨
    retrievers = {
        "multi_source": multi_source_retriever,
        "nesma": EnhancedSemanticRetriever(
            vector_manager=vector_manager,
            embeddings=embeddings,
            llm=llm,
            source_type="nesma",
            k=5
        ),
        "cosmic": EnhancedSemanticRetriever(
            vector_manager=vector_manager,
            embeddings=embeddings,
            llm=llm,
            source_type="cosmic",
            k=5
        ),
        "common": EnhancedSemanticRetriever(
            vector_manager=vector_manager,
            embeddings=embeddings,
            llm=llm,
            source_type="common",
            k=5
        )
    }
    
    return retrievers


if __name__ == "__main__":
    async def main():
        # æµ‹è¯•è¯­ä¹‰æ£€ç´¢å™¨
        from knowledge_base.vector_stores.mongodb_atlas import MongoDBAtlasVectorManager
        
        # åˆå§‹åŒ–å‘é‡ç®¡ç†å™¨
        vector_manager = MongoDBAtlasVectorManager()
        await vector_manager.initialize()
        
        # åˆ›å»ºæ£€ç´¢å™¨
        retrievers = await create_knowledge_retrievers(vector_manager)
        
        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "NESMAåŠŸèƒ½ç‚¹åˆ†ç±»è§„åˆ™",
            "COSMICæ•°æ®ç§»åŠ¨ç±»å‹",
            "åŠŸèƒ½å¤æ‚åº¦è®¡ç®—æ–¹æ³•"
        ]
        
        multi_retriever = retrievers["multi_source"]
        
        for query in test_queries:
            print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: {query}")
            
            # è‡ªé€‚åº”æ£€ç´¢
            result = await multi_retriever.adaptive_retrieve(query)
            print(f"ğŸ“Š æ£€ç´¢ç»“æœ: {len(result.retrieved_chunks)} ä¸ªæ–‡æ¡£å—")
            print(f"â±ï¸ æ£€ç´¢è€—æ—¶: {result.retrieval_time_ms}ms")
            
            if result.retrieved_chunks:
                best_chunk = result.retrieved_chunks[0]
                print(f"ğŸ¯ æœ€ä½³åŒ¹é… (åˆ†æ•°: {best_chunk.relevance_score:.3f})")
                print(f"   å†…å®¹é¢„è§ˆ: {best_chunk.content_preview}")
        
        await vector_manager.close()
    
    asyncio.run(main()) 