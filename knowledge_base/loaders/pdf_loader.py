"""
é‡å­æ™ºèƒ½åŒ–åŠŸèƒ½ç‚¹ä¼°ç®—ç³»ç»Ÿ - PDFæ–‡æ¡£åŠ è½½å™¨

æ”¯æŒå¤šç§PDFæ–‡æ¡£åŠ è½½ç­–ç•¥ï¼Œé’ˆå¯¹NESMA/COSMICæ ‡å‡†æ–‡æ¡£ä¼˜åŒ–
"""

import os
from pathlib import Path
from typing import List, Optional, Dict, Any

from langchain_community.document_loaders import (
    PyPDFLoader,
    UnstructuredPDFLoader,
    PDFMinerLoader
)
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter

from config.settings import get_settings


class PDFLoaderStrategy:
    """PDFåŠ è½½ç­–ç•¥æšä¸¾"""
    PYPDF = "pypdf"                    # åŸºç¡€PDFåŠ è½½
    UNSTRUCTURED = "unstructured"      # ç»“æ„åŒ–PDFåŠ è½½
    PDFMINER = "pdfminer"             # é«˜ç²¾åº¦æ–‡æœ¬æå–


class EnhancedPDFLoader:
    """å¢å¼ºçš„PDFæ–‡æ¡£åŠ è½½å™¨"""
    
    def __init__(self, strategy: str = PDFLoaderStrategy.UNSTRUCTURED):
        self.strategy = strategy
        self.settings = get_settings()
        
        # æ–‡æœ¬åˆ†å‰²å™¨é…ç½®
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.settings.knowledge_base.chunk_size,
            chunk_overlap=self.settings.knowledge_base.chunk_overlap,
            separators=[
                "\n\n",  # æ®µè½åˆ†éš”
                "\n",    # è¡Œåˆ†éš”
                "ã€‚",    # ä¸­æ–‡å¥å·
                ".",     # è‹±æ–‡å¥å·
                "!",     # æ„Ÿå¹å·
                "?",     # é—®å·
                "ï¼›",    # ä¸­æ–‡åˆ†å·
                ";",     # è‹±æ–‡åˆ†å·
                "ï¼Œ",    # ä¸­æ–‡é€—å·
                ",",     # è‹±æ–‡é€—å·
                " ",     # ç©ºæ ¼
                ""       # å­—ç¬¦
            ]
        )
    
    def load_pdf(self, file_path: str, metadata: Optional[Dict[str, Any]] = None) -> List[Document]:
        """åŠ è½½å•ä¸ªPDFæ–‡ä»¶"""
        file_path = Path(file_path)
        if not file_path.exists():
            raise FileNotFoundError(f"PDFæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        # æ ¹æ®ç­–ç•¥é€‰æ‹©åŠ è½½å™¨
        if self.strategy == PDFLoaderStrategy.PYPDF:
            loader = PyPDFLoader(str(file_path))
        elif self.strategy == PDFLoaderStrategy.UNSTRUCTURED:
            loader = UnstructuredPDFLoader(
                str(file_path),
                mode="elements",
                strategy="hi_res"
            )
        elif self.strategy == PDFLoaderStrategy.PDFMINER:
            loader = PDFMinerLoader(str(file_path))
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„PDFåŠ è½½ç­–ç•¥: {self.strategy}")
        
        # åŠ è½½æ–‡æ¡£
        documents = loader.load()
        
        # æ·»åŠ å…ƒæ•°æ®
        base_metadata = {
            "source": str(file_path),
            "file_name": file_path.name,
            "file_type": "pdf",
            "loader_strategy": self.strategy,
        }
        
        if metadata:
            base_metadata.update(metadata)
        
        # ä¸ºæ¯ä¸ªæ–‡æ¡£æ·»åŠ å…ƒæ•°æ®
        for doc in documents:
            doc.metadata.update(base_metadata)
        
        return documents
    
    def load_directory(
        self, 
        directory_path: str, 
        pattern: str = "*.pdf",
        metadata_extractor: Optional[callable] = None
    ) -> List[Document]:
        """åŠ è½½ç›®å½•ä¸­çš„æ‰€æœ‰PDFæ–‡ä»¶"""
        directory_path = Path(directory_path)
        if not directory_path.exists():
            raise FileNotFoundError(f"ç›®å½•ä¸å­˜åœ¨: {directory_path}")
        
        all_documents = []
        pdf_files = list(directory_path.glob(pattern))
        
        if not pdf_files:
            print(f"âš ï¸ åœ¨ç›®å½• {directory_path} ä¸­æœªæ‰¾åˆ°PDFæ–‡ä»¶")
            return all_documents
        
        for pdf_file in pdf_files:
            try:
                # æå–æ–‡ä»¶å…ƒæ•°æ®
                file_metadata = {}
                if metadata_extractor:
                    file_metadata = metadata_extractor(pdf_file)
                
                # åŠ è½½æ–‡æ¡£
                documents = self.load_pdf(str(pdf_file), file_metadata)
                all_documents.extend(documents)
                
                print(f"âœ… æˆåŠŸåŠ è½½: {pdf_file.name} ({len(documents)} ä¸ªæ–‡æ¡£å—)")
                
            except Exception as e:
                print(f"âŒ åŠ è½½å¤±è´¥: {pdf_file.name} - {str(e)}")
                continue
        
        return all_documents
    
    def split_documents(self, documents: List[Document]) -> List[Document]:
        """åˆ†å‰²æ–‡æ¡£ä¸ºè¾ƒå°çš„å—"""
        return self.text_splitter.split_documents(documents)
    
    def load_and_split(
        self, 
        file_path: str, 
        metadata: Optional[Dict[str, Any]] = None
    ) -> List[Document]:
        """åŠ è½½å¹¶åˆ†å‰²PDFæ–‡æ¡£"""
        documents = self.load_pdf(file_path, metadata)
        return self.split_documents(documents)


class NESMAPDFLoader(EnhancedPDFLoader):
    """NESMAæ ‡å‡†æ–‡æ¡£ä¸“ç”¨åŠ è½½å™¨"""
    
    def __init__(self):
        super().__init__(strategy=PDFLoaderStrategy.UNSTRUCTURED)
    
    def extract_nesma_metadata(self, file_path: Path) -> Dict[str, Any]:
        """æå–NESMAæ–‡æ¡£çš„å…ƒæ•°æ®"""
        metadata = {
            "source_type": "NESMA",
            "standard": "NESMA",
            "version": self._extract_version_from_filename(file_path.name),
            "document_type": self._classify_nesma_document(file_path.name)
        }
        return metadata
    
    def _extract_version_from_filename(self, filename: str) -> str:
        """ä»æ–‡ä»¶åæå–ç‰ˆæœ¬ä¿¡æ¯"""
        # å¯»æ‰¾ç‰ˆæœ¬æ¨¡å¼ï¼Œå¦‚ v2.3, version_2.3, 2.3ç­‰
        import re
        patterns = [
            r'v?(\d+\.\d+)',
            r'version[_\s]?(\d+\.\d+)',
            r'nesma[_\s]?(\d+\.\d+)'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, filename.lower())
            if match:
                return match.group(1)
        
        return "unknown"
    
    def _classify_nesma_document(self, filename: str) -> str:
        """åˆ†ç±»NESMAæ–‡æ¡£ç±»å‹"""
        filename_lower = filename.lower()
        
        if any(keyword in filename_lower for keyword in ['manual', 'æ‰‹å†Œ', 'guide', 'æŒ‡å—']):
            return "manual"
        elif any(keyword in filename_lower for keyword in ['specification', 'è§„èŒƒ', 'spec']):
            return "specification"
        elif any(keyword in filename_lower for keyword in ['example', 'ç¤ºä¾‹', 'case']):
            return "example"
        elif any(keyword in filename_lower for keyword in ['rule', 'è§„åˆ™', 'standard']):
            return "rules"
        else:
            return "general"


class COSMICPDFLoader(EnhancedPDFLoader):
    """COSMICæ ‡å‡†æ–‡æ¡£ä¸“ç”¨åŠ è½½å™¨"""
    
    def __init__(self):
        super().__init__(strategy=PDFLoaderStrategy.UNSTRUCTURED)
    
    def extract_cosmic_metadata(self, file_path: Path) -> Dict[str, Any]:
        """æå–COSMICæ–‡æ¡£çš„å…ƒæ•°æ®"""
        metadata = {
            "source_type": "COSMIC",
            "standard": "COSMIC",
            "version": self._extract_version_from_filename(file_path.name),
            "document_type": self._classify_cosmic_document(file_path.name)
        }
        return metadata
    
    def _extract_version_from_filename(self, filename: str) -> str:
        """ä»æ–‡ä»¶åæå–ç‰ˆæœ¬ä¿¡æ¯"""
        import re
        patterns = [
            r'v?(\d+\.\d+)',
            r'version[_\s]?(\d+\.\d+)',
            r'cosmic[_\s]?(\d+\.\d+)'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, filename.lower())
            if match:
                return match.group(1)
        
        return "unknown"
    
    def _classify_cosmic_document(self, filename: str) -> str:
        """åˆ†ç±»COSMICæ–‡æ¡£ç±»å‹"""
        filename_lower = filename.lower()
        
        if any(keyword in filename_lower for keyword in ['manual', 'æ‰‹å†Œ', 'handbook']):
            return "manual"
        elif any(keyword in filename_lower for keyword in ['method', 'æ–¹æ³•', 'methodology']):
            return "methodology"
        elif any(keyword in filename_lower for keyword in ['guideline', 'æŒ‡å—', 'guide']):
            return "guideline"
        elif any(keyword in filename_lower for keyword in ['example', 'ç¤ºä¾‹', 'case']):
            return "example"
        else:
            return "general"


def pdf_loader_factory(source_type: str = "general") -> EnhancedPDFLoader:
    """PDFåŠ è½½å™¨å·¥å‚å‡½æ•°"""
    if source_type.lower() == "nesma":
        return NESMAPDFLoader()
    elif source_type.lower() == "cosmic":
        return COSMICPDFLoader()
    else:
        return EnhancedPDFLoader()


async def load_knowledge_base_pdfs(
    nesma_path: Optional[str] = None,
    cosmic_path: Optional[str] = None,
    common_path: Optional[str] = None
) -> Dict[str, List[Document]]:
    """åŠ è½½çŸ¥è¯†åº“ä¸­çš„æ‰€æœ‰PDFæ–‡æ¡£"""
    settings = get_settings()
    results = {}
    
    # åŠ è½½NESMAæ–‡æ¡£
    if nesma_path or settings.knowledge_base.nesma_docs_path.exists():
        path = nesma_path or str(settings.knowledge_base.nesma_docs_path)
        loader = NESMAPDFLoader()
        documents = loader.load_directory(
            path, 
            metadata_extractor=loader.extract_nesma_metadata
        )
        if documents:
            # åˆ†å‰²æ–‡æ¡£
            split_docs = loader.split_documents(documents)
            results["nesma"] = split_docs
            print(f"ğŸ“š NESMAæ–‡æ¡£åŠ è½½å®Œæˆ: {len(documents)} åŸå§‹æ–‡æ¡£ -> {len(split_docs)} åˆ†å‰²å—")
    
    # åŠ è½½COSMICæ–‡æ¡£
    if cosmic_path or settings.knowledge_base.cosmic_docs_path.exists():
        path = cosmic_path or str(settings.knowledge_base.cosmic_docs_path)
        loader = COSMICPDFLoader()
        documents = loader.load_directory(
            path,
            metadata_extractor=loader.extract_cosmic_metadata
        )
        if documents:
            # åˆ†å‰²æ–‡æ¡£
            split_docs = loader.split_documents(documents)
            results["cosmic"] = split_docs
            print(f"ğŸŒŒ COSMICæ–‡æ¡£åŠ è½½å®Œæˆ: {len(documents)} åŸå§‹æ–‡æ¡£ -> {len(split_docs)} åˆ†å‰²å—")
    
    # åŠ è½½é€šç”¨æ–‡æ¡£
    if common_path or settings.knowledge_base.common_docs_path.exists():
        path = common_path or str(settings.knowledge_base.common_docs_path)
        loader = EnhancedPDFLoader()
        documents = loader.load_directory(path)
        if documents:
            # æ·»åŠ é€šç”¨æ ‡è¯†
            for doc in documents:
                doc.metadata["source_type"] = "COMMON"
                doc.metadata["standard"] = "COMMON"
            
            # åˆ†å‰²æ–‡æ¡£
            split_docs = loader.split_documents(documents)
            results["common"] = split_docs
            print(f"ğŸ“– é€šç”¨æ–‡æ¡£åŠ è½½å®Œæˆ: {len(documents)} åŸå§‹æ–‡æ¡£ -> {len(split_docs)} åˆ†å‰²å—")
    
    return results


class BatchPDFProcessor:
    """æ‰¹é‡PDFå¤„ç†å™¨"""
    
    def __init__(self, strategy: str = PDFLoaderStrategy.UNSTRUCTURED):
        self.loader = EnhancedPDFLoader(strategy)
        self.processed_files = []
        self.failed_files = []
    
    async def process_directory(
        self, 
        directory_path: str,
        pattern: str = "*.pdf",
        max_files: Optional[int] = None
    ) -> Dict[str, List[Document]]:
        """æ‰¹é‡å¤„ç†ç›®å½•ä¸­çš„PDFæ–‡ä»¶"""
        directory_path = Path(directory_path)
        if not directory_path.exists():
            raise FileNotFoundError(f"ç›®å½•ä¸å­˜åœ¨: {directory_path}")
        
        pdf_files = list(directory_path.glob(pattern))
        if max_files:
            pdf_files = pdf_files[:max_files]
        
        results = {
            "documents": [],
            "metadata": []
        }
        
        for pdf_file in pdf_files:
            try:
                documents = self.loader.load_and_split(str(pdf_file))
                results["documents"].extend(documents)
                self.processed_files.append(str(pdf_file))
                
                # æ·»åŠ å¤„ç†å…ƒæ•°æ®
                results["metadata"].append({
                    "file": str(pdf_file),
                    "status": "success",
                    "document_count": len(documents)
                })
                
            except Exception as e:
                self.failed_files.append({"file": str(pdf_file), "error": str(e)})
                results["metadata"].append({
                    "file": str(pdf_file),
                    "status": "failed", 
                    "error": str(e)
                })
        
        return results
    
    def get_processing_stats(self) -> Dict[str, Any]:
        """è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_processed": len(self.processed_files),
            "total_failed": len(self.failed_files),
            "success_rate": len(self.processed_files) / (len(self.processed_files) + len(self.failed_files)) if (len(self.processed_files) + len(self.failed_files)) > 0 else 0,
            "processed_files": self.processed_files,
            "failed_files": self.failed_files
        }


if __name__ == "__main__":
    import asyncio
    
    async def main():
        # æµ‹è¯•PDFåŠ è½½å™¨
        print("ğŸ§ª æµ‹è¯•PDFåŠ è½½å™¨...")
        
        # æµ‹è¯•åŸºç¡€åŠ è½½å™¨
        loader = EnhancedPDFLoader()
        print(f"âœ… PDFåŠ è½½å™¨åˆ›å»ºæˆåŠŸï¼Œç­–ç•¥: {loader.strategy}")
        
        # æµ‹è¯•NESMAåŠ è½½å™¨
        nesma_loader = NESMAPDFLoader()
        print(f"âœ… NESMAåŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•COSMICåŠ è½½å™¨
        cosmic_loader = COSMICPDFLoader()
        print(f"âœ… COSMICåŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•æ‰¹é‡å¤„ç†å™¨
        batch_processor = BatchPDFProcessor()
        print(f"âœ… æ‰¹é‡å¤„ç†å™¨åˆ›å»ºæˆåŠŸ")
        
        print("ğŸ“„ PDFåŠ è½½å™¨æµ‹è¯•å®Œæˆ!")
    
    asyncio.run(main()) 