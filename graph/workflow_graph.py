"""
é‡å­æ™ºèƒ½åŒ–åŠŸèƒ½ç‚¹ä¼°ç®—ç³»ç»Ÿ - ä¸»å·¥ä½œæµå›¾

åŸºäºLangGraphçš„çŠ¶æ€æœºé©±åŠ¨å·¥ä½œæµï¼Œå®ç°NESMAå’ŒCOSMICåŒæ ‡å‡†æ™ºèƒ½åŒ–ä¼°ç®—
"""

import asyncio
import logging
from datetime import datetime
from typing import Dict, Any, Literal, List, Optional

from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver

from .state_definitions import WorkflowGraphState, WorkflowState, ProcessingStage
from .node_functions import (
    # å¯åŠ¨å’Œè·¯ç”±èŠ‚ç‚¹
    start_workflow_node,
    recommend_standard_node,
    
    # éœ€æ±‚è§£æèŠ‚ç‚¹
    parse_requirements_node,
    identify_processes_node,
    
    # NESMAå·¥ä½œæµèŠ‚ç‚¹
    nesma_classify_functions_node,
    nesma_calculate_complexity_node,
    nesma_calculate_ufp_node,
    
    # COSMICå·¥ä½œæµèŠ‚ç‚¹
    cosmic_identify_users_node,
    cosmic_analyze_boundary_node,
    cosmic_classify_movements_node,
    cosmic_calculate_cfp_node,
    
    # éªŒè¯èŠ‚ç‚¹
    validate_results_node,
    
    # å¯¹æ¯”å’Œè¾“å‡ºèŠ‚ç‚¹
    compare_standards_node,
    generate_report_node,
    
    # é”™è¯¯å¤„ç†èŠ‚ç‚¹
    handle_error_node,
    complete_workflow_node
)

logger = logging.getLogger(__name__)


def create_workflow_graph() -> StateGraph:
    """åˆ›å»ºä¸»å·¥ä½œæµå›¾"""
    
    # åˆ›å»ºçŠ¶æ€å›¾
    workflow = StateGraph(WorkflowGraphState)
    
    # ==================== æ·»åŠ èŠ‚ç‚¹ ====================
    
    # å¯åŠ¨å’Œè·¯ç”±èŠ‚ç‚¹
    workflow.add_node("start_workflow", start_workflow_node)
    workflow.add_node("recommend_standard", recommend_standard_node)
    
    # éœ€æ±‚è§£æèŠ‚ç‚¹
    workflow.add_node("parse_requirements", parse_requirements_node)
    workflow.add_node("identify_processes", identify_processes_node)
    
    # NESMAå·¥ä½œæµèŠ‚ç‚¹
    workflow.add_node("nesma_classify_functions", nesma_classify_functions_node)
    workflow.add_node("nesma_calculate_complexity", nesma_calculate_complexity_node)
    workflow.add_node("nesma_calculate_ufp", nesma_calculate_ufp_node)
    
    # COSMICå·¥ä½œæµèŠ‚ç‚¹
    workflow.add_node("cosmic_identify_users", cosmic_identify_users_node)
    workflow.add_node("cosmic_analyze_boundary", cosmic_analyze_boundary_node)
    workflow.add_node("cosmic_classify_movements", cosmic_classify_movements_node)
    workflow.add_node("cosmic_calculate_cfp", cosmic_calculate_cfp_node)
    
    # éªŒè¯èŠ‚ç‚¹
    workflow.add_node("validate_results", validate_results_node)
    
    # å¯¹æ¯”å’Œè¾“å‡ºèŠ‚ç‚¹
    workflow.add_node("compare_standards", compare_standards_node)
    workflow.add_node("generate_report", generate_report_node)
    
    # é”™è¯¯å¤„ç†èŠ‚ç‚¹
    workflow.add_node("handle_error", handle_error_node)
    
    # ==================== è®¾ç½®å…¥å£ç‚¹ ====================
    workflow.set_entry_point("start_workflow")
    
    # ==================== æ·»åŠ è¾¹å’Œæ¡ä»¶è·¯ç”± ====================
    
    # å¯åŠ¨æµç¨‹
    workflow.add_edge("start_workflow", "recommend_standard")
    workflow.add_edge("recommend_standard", "parse_requirements")
    
    # éœ€æ±‚è§£ææµç¨‹
    workflow.add_edge("parse_requirements", "identify_processes")
    workflow.add_conditional_edges(
        "identify_processes",
        after_process_identification,
        {
            "nesma_only": "nesma_classify_functions",
            "cosmic_only": "cosmic_identify_users", 
            "dual_standard": "nesma_classify_functions",  # åŒæ ‡å‡†æ—¶å…ˆèµ°NESMAï¼Œç„¶åä¼šè·¯ç”±åˆ°COSMIC
            "handle_error": "handle_error"
        }
    )
    
    # NESMAå·¥ä½œæµ
    workflow.add_conditional_edges(
        "nesma_classify_functions",
        after_nesma_classification,
        {
            "nesma_calculate_complexity": "nesma_calculate_complexity",
            "validate_results": "validate_results",
            "handle_error": "handle_error"
        }
    )
    
    workflow.add_conditional_edges(
        "nesma_calculate_complexity",
        after_nesma_complexity,
        {
            "nesma_calculate_ufp": "nesma_calculate_ufp",
            "validate_results": "validate_results",
            "handle_error": "handle_error"
        }
    )
    
    workflow.add_conditional_edges(
        "nesma_calculate_ufp",
        after_nesma_ufp,
        {
            "cosmic_identify_users": "cosmic_identify_users",
            "compare_standards": "compare_standards",
            "generate_report": "generate_report",
            "validate_results": "validate_results",
            "handle_error": "handle_error"
        }
    )
    
    # COSMICå·¥ä½œæµ
    workflow.add_conditional_edges(
        "cosmic_identify_users",
        after_cosmic_functional_users,
        {
            "cosmic_analyze_boundary": "cosmic_analyze_boundary",
            "validate_results": "validate_results",
            "handle_error": "handle_error"
        }
    )
    
    workflow.add_conditional_edges(
        "cosmic_analyze_boundary",
        after_cosmic_boundaries,
        {
            "cosmic_classify_movements": "cosmic_classify_movements",
            "validate_results": "validate_results",
            "handle_error": "handle_error"
        }
    )
    
    workflow.add_conditional_edges(
        "cosmic_classify_movements",
        after_cosmic_data_movements,
        {
            "cosmic_calculate_cfp": "cosmic_calculate_cfp",
            "validate_results": "validate_results",
            "handle_error": "handle_error"
        }
    )
    
    workflow.add_conditional_edges(
        "cosmic_calculate_cfp",
        after_cosmic_cfp,
        {
            "nesma_classify_functions": "nesma_classify_functions",
            "compare_standards": "compare_standards",
            "generate_report": "generate_report",
            "validate_results": "validate_results",
            "handle_error": "handle_error"
        }
    )
    
    # éªŒè¯ç»“æœ
    workflow.add_conditional_edges(
        "validate_results",
        after_validation,
        {
            "compare_standards": "compare_standards",
            "generate_report": "generate_report",
            "handle_error": "handle_error"
        }
    )
    
    # å¯¹æ¯”å’Œè¾“å‡º
    workflow.add_edge("compare_standards", "generate_report")
    workflow.add_edge("generate_report", END)
    
    # é”™è¯¯å¤„ç†
    workflow.add_conditional_edges(
        "handle_error",
        after_error_handling,
        {
            "generate_report": "generate_report",
            END: END
        }
    )
    
    return workflow


# ==================== æ¡ä»¶è·¯ç”±å‡½æ•° ====================

def route_strategy_decision(state: WorkflowGraphState) -> Literal["parse_requirements", "handle_error"]:
    """æ ‡å‡†è·¯ç”±å†³ç­–"""
    try:
        if not state.standard_recommendation:
            logger.warning("ç¼ºå°‘æ ‡å‡†æ¨èç»“æœ")
            return "handle_error"
        
        if not state.selected_strategy:
            logger.warning("ç¼ºå°‘é€‰æ‹©çš„ç­–ç•¥")
            return "handle_error"
        
        return "parse_requirements"
        
    except Exception as e:
        logger.error(f"æ ‡å‡†è·¯ç”±å†³ç­–å¤±è´¥: {e}")
        return "handle_error"


def after_process_identification(state: WorkflowGraphState) -> Literal[
    "nesma_only", "cosmic_only", "dual_standard", "handle_error"
]:
    """æµç¨‹è¯†åˆ«åçš„è·¯ç”±å†³ç­–"""
    try:
        strategy = state.selected_strategy
        
        if not strategy:
            logger.error("ç¼ºå°‘ä¼°ç®—ç­–ç•¥ä¿¡æ¯")
            return "handle_error"
        
        from models.common_models import EstimationStrategy
        
        if strategy == EstimationStrategy.NESMA_ONLY:
            logger.info("ğŸ¯ é€‰æ‹©NESMAå•ä¸€æ ‡å‡†ä¼°ç®—")
            return "nesma_only"
        elif strategy == EstimationStrategy.COSMIC_ONLY:
            logger.info("ğŸ¯ é€‰æ‹©COSMICå•ä¸€æ ‡å‡†ä¼°ç®—")
            return "cosmic_only"
        elif strategy == EstimationStrategy.DUAL_PARALLEL:
            logger.info("ğŸ¯ é€‰æ‹©åŒæ ‡å‡†å¹¶è¡Œä¼°ç®—")
            return "dual_standard"
        else:
            logger.error(f"æœªçŸ¥çš„ä¼°ç®—ç­–ç•¥: {strategy}")
            return "handle_error"
            
    except Exception as e:
        logger.error(f"æµç¨‹è¯†åˆ«åè·¯ç”±å¤±è´¥: {str(e)}")
        return "handle_error"


# åˆ é™¤ä¸ä½¿ç”¨çš„after_knowledge_retrievalå‡½æ•°


def after_nesma_classification(state: WorkflowGraphState) -> Literal[
    "nesma_calculate_complexity", "validate_results", "handle_error"
]:
    """NESMAåˆ†ç±»åçš„è·¯ç”±å†³ç­–"""
    try:
        if not state.nesma_results:
            return "validate_results"
        
        classifications = state.nesma_classifications or []
        
        if not classifications:
            return "validate_results"
        
        return "nesma_calculate_complexity"
        
    except Exception as e:
        logger.error(f"NESMAåˆ†ç±»åè·¯ç”±å¤±è´¥: {str(e)}")
        return "handle_error"


def after_nesma_complexity(state: WorkflowGraphState) -> Literal[
    "nesma_calculate_ufp", "validate_results", "handle_error"
]:
    """NESMAå¤æ‚åº¦è®¡ç®—åçš„è·¯ç”±å†³ç­–"""
    try:
        if not state.nesma_results:
            return "validate_results"
        
        complexity_results = state.nesma_complexity_results or []
        
        if not complexity_results:
            return "validate_results"
        
        return "nesma_calculate_ufp"
        
    except Exception as e:
        logger.error(f"NESMAå¤æ‚åº¦è®¡ç®—åè·¯ç”±å¤±è´¥: {str(e)}")
        return "handle_error"


def after_nesma_ufp(state: WorkflowGraphState) -> Literal[
    "cosmic_identify_users", "compare_standards", 
    "generate_report", "validate_results", "handle_error"
]:
    """NESMA UFPè®¡ç®—åçš„è·¯ç”±å†³ç­–"""
    try:
        strategy = state.selected_strategy
        
        if not state.nesma_results or not state.nesma_results.total_ufp:
            return "validate_results"
        
        from models.common_models import EstimationStrategy
        
        if strategy == EstimationStrategy.NESMA_ONLY:
            return "generate_report"
        elif strategy == EstimationStrategy.DUAL_PARALLEL:
            if state.cosmic_results and state.cosmic_results.total_cfp:
                return "compare_standards"
            else:
                return "cosmic_identify_users"
        else:
            return "validate_results"
            
    except Exception as e:
        logger.error(f"NESMA UFPè®¡ç®—åè·¯ç”±å¤±è´¥: {str(e)}")
        return "handle_error"


def after_cosmic_functional_users(state: WorkflowGraphState) -> Literal[
    "cosmic_analyze_boundary", "validate_results", "handle_error"
]:
    """COSMICåŠŸèƒ½ç”¨æˆ·è¯†åˆ«åçš„è·¯ç”±å†³ç­–"""
    try:
        if not state.cosmic_results:
            return "validate_results"
        
        functional_users = state.cosmic_functional_users or []
        
        if not functional_users:
            return "validate_results"
        
        return "cosmic_analyze_boundary"
        
    except Exception as e:
        logger.error(f"COSMICåŠŸèƒ½ç”¨æˆ·è¯†åˆ«åè·¯ç”±å¤±è´¥: {str(e)}")
        return "handle_error"


def after_cosmic_boundaries(state: WorkflowGraphState) -> Literal[
    "cosmic_classify_movements", "validate_results", "handle_error"
]:
    """COSMICè¾¹ç•Œåˆ†æåçš„è·¯ç”±å†³ç­–"""
    try:
        if not state.cosmic_results or not state.cosmic_boundary_analysis:
            return "validate_results"
        
        return "cosmic_classify_movements"
        
    except Exception as e:
        logger.error(f"COSMICè¾¹ç•Œåˆ†æåè·¯ç”±å¤±è´¥: {str(e)}")
        return "handle_error"


def after_cosmic_data_movements(state: WorkflowGraphState) -> Literal[
    "cosmic_calculate_cfp", "validate_results", "handle_error"
]:
    """COSMICæ•°æ®ç§»åŠ¨åˆ†ç±»åçš„è·¯ç”±å†³ç­–"""
    try:
        if not state.cosmic_results:
            return "validate_results"
        
        data_movements = state.cosmic_data_movements or []
        
        if not data_movements:
            return "validate_results"
        
        return "cosmic_calculate_cfp"
        
    except Exception as e:
        logger.error(f"COSMICæ•°æ®ç§»åŠ¨åˆ†ç±»åè·¯ç”±å¤±è´¥: {str(e)}")
        return "handle_error"


def after_cosmic_cfp(state: WorkflowGraphState) -> Literal[
    "nesma_classify_functions", "compare_standards", 
    "generate_report", "validate_results", "handle_error"
]:
    """COSMIC CFPè®¡ç®—åçš„è·¯ç”±å†³ç­–"""
    try:
        strategy = state.selected_strategy
        
        if not state.cosmic_results or not state.cosmic_results.total_cfp:
            return "validate_results"
        
        from models.common_models import EstimationStrategy
        
        if strategy == EstimationStrategy.COSMIC_ONLY:
            return "generate_report"
        elif strategy == EstimationStrategy.DUAL_PARALLEL:
            if state.nesma_results and state.nesma_results.total_ufp:
                return "compare_standards"
            else:
                return "nesma_classify_functions"
        else:
            return "validate_results"
            
    except Exception as e:
        logger.error(f"COSMIC CFPè®¡ç®—åè·¯ç”±å¤±è´¥: {str(e)}")
        return "handle_error"


def after_validation(state: WorkflowGraphState) -> Literal[
    "compare_standards", "generate_report", "handle_error"
]:
    """éªŒè¯åçš„è·¯ç”±å†³ç­–"""
    try:
        validation_results = state.validation_results
        logger.info(f"ğŸ” éªŒè¯åè·¯ç”± - éªŒè¯ç»“æœ: {validation_results}")
        
        is_valid = True
        
        if validation_results:
            if hasattr(validation_results, 'validation_status'):
                is_valid = validation_results.validation_status != "failed"
            elif isinstance(validation_results, dict):
                overall_validation = validation_results.get("overall_validation")
                if overall_validation and hasattr(overall_validation, 'is_valid'):
                    is_valid = overall_validation.is_valid
                elif isinstance(overall_validation, dict):
                    is_valid = overall_validation.get("is_valid", True)
            elif isinstance(validation_results, list) and validation_results:
                first_result = validation_results[0]
                if hasattr(first_result, 'is_valid'):
                    is_valid = first_result.is_valid
                elif isinstance(first_result, dict):
                    is_valid = first_result.get("is_valid", True)
        
        logger.info(f"ğŸ” éªŒè¯çŠ¶æ€: is_valid={is_valid}")
        
        if not is_valid:
            logger.warning("éªŒè¯å¤±è´¥ï¼Œè·³è½¬åˆ°é”™è¯¯å¤„ç†")
            return "handle_error"
        
        strategy = state.selected_strategy
        
        has_nesma = bool(state.nesma_results and state.nesma_results.total_ufp)
        has_cosmic = bool(state.cosmic_results and state.cosmic_results.total_cfp)
        
        logger.info(f"ğŸ” ç»“æœæ£€æŸ¥: strategy={strategy}, NESMA={has_nesma}, COSMIC={has_cosmic}")
        
        from models.common_models import EstimationStrategy
        
        if (strategy == EstimationStrategy.DUAL_PARALLEL and 
            has_nesma and has_cosmic):
            return "compare_standards"
        else:
            return "generate_report"
            
    except Exception as e:
        logger.error(f"éªŒè¯åè·¯ç”±å¤±è´¥: {str(e)}")
        import traceback
        logger.error(f"éªŒè¯åè·¯ç”±å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
        return "handle_error"


def after_error_handling(state: WorkflowGraphState) -> Literal["generate_report", END]:
    """é”™è¯¯å¤„ç†åçš„è·¯ç”±å†³ç­–"""
    try:
        if not state:
            logger.error("çŠ¶æ€ä¸ºç©ºï¼Œç»ˆæ­¢å·¥ä½œæµ")
            return END
        
        current_state = state.current_state
        
        if current_state == WorkflowState.REPORT_GENERATION_PENDING:
            return "generate_report"
        
        try:
            has_nesma_results = bool(state.nesma_results and state.nesma_results.total_ufp)
            has_cosmic_results = bool(state.cosmic_results and state.cosmic_results.total_cfp)
            
            logger.info(f"ğŸ” é”™è¯¯å¤„ç†è·¯ç”±æ£€æŸ¥: NESMA={has_nesma_results}, COSMIC={has_cosmic_results}")
            
            if has_nesma_results or has_cosmic_results:
                return "generate_report"
            else:
                return END
                
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥ç»“æœçŠ¶æ€æ—¶å‡ºé”™: {e}")
            return END
            
    except Exception as e:
        logger.error(f"é”™è¯¯å¤„ç†åè·¯ç”±å¤±è´¥: {e}")
        return END


def after_retry(state: WorkflowGraphState) -> Literal[
    "recommend_standard", "parse_requirements", "identify_processes",
    "nesma_classify_functions", "cosmic_identify_users",
    "validate_results", "handle_error", END
]:
    """é‡è¯•åçš„è·¯ç”±å†³ç­–"""
    try:
        retry_info = state.retry_info or {}
        failed_step = retry_info.get("failed_step")
        retry_count = state.retry_count or 0
        max_retries = state.max_retries or 3
        
        if retry_count >= max_retries:
            return "handle_error"
        
        step_mapping = {
            "recommend_standard": "recommend_standard",
            "parse_requirements": "parse_requirements",
            "identify_processes": "identify_processes",
            "nesma_classify_functions": "nesma_classify_functions",
            "cosmic_identify_users": "cosmic_identify_users",
            "validate_results": "validate_results"
        }
        
        return step_mapping.get(failed_step, "handle_error")
        
    except Exception as e:
        logger.error(f"é‡è¯•åè·¯ç”±å¤±è´¥: {e}")
        return "handle_error"


# ==================== å·¥ä½œæµç¼–è¯‘å’Œåˆ›å»ºå‡½æ•° ====================

def create_compiled_workflow() -> StateGraph:
    """åˆ›å»ºç¼–è¯‘åçš„å·¥ä½œæµ"""
    try:
        workflow = create_workflow_graph()
        compiled_workflow = workflow.compile()
        logger.info("âœ… å·¥ä½œæµç¼–è¯‘å®Œæˆ")
        return compiled_workflow
    except Exception as e:
        logger.error(f"âŒ å·¥ä½œæµç¼–è¯‘å¤±è´¥: {str(e)}")
        raise


def get_workflow_config() -> Dict[str, Any]:
    """è·å–å·¥ä½œæµé…ç½®"""
    return {
        "version": "1.0.0",
        "max_retries": 3,
        "timeout_seconds": 300,
        "checkpointing_enabled": True
    }


def visualize_workflow(workflow: StateGraph, output_path: str = "workflow_graph.png"):
    """å¯è§†åŒ–å·¥ä½œæµå›¾"""
    try:
        import matplotlib.pyplot as plt
        from matplotlib.patches import Rectangle, FancyBboxPatch
        import networkx as nx
        
        G = nx.DiGraph()
        
        nodes = [
            "start_workflow", "recommend_standard", "route_by_standard",
            "parse_requirements", "identify_processes", "retrieve_knowledge",
            "nesma_classify_functions", "nesma_calculate_complexity", "nesma_calculate_ufp",
            "cosmic_identify_functional_users", "cosmic_analyze_boundaries", 
            "cosmic_classify_data_movements", "cosmic_calculate_cfp",
            "validate_results", "compare_standards", "generate_report",
            "handle_error", "retry_failed_step"
        ]
        
        G.add_nodes_from(nodes)
        
        edges = [
            ("start_workflow", "recommend_standard"),
            ("recommend_standard", "route_by_standard"),
            ("route_by_standard", "parse_requirements"),
            ("parse_requirements", "identify_processes"),
            ("identify_processes", "nesma_classify_functions"),
            ("identify_processes", "cosmic_identify_functional_users"),
            ("nesma_classify_functions", "nesma_calculate_complexity"),
            ("nesma_calculate_complexity", "nesma_calculate_ufp"),
            ("cosmic_identify_functional_users", "cosmic_analyze_boundaries"),
            ("cosmic_analyze_boundaries", "cosmic_classify_data_movements"),
            ("cosmic_classify_data_movements", "cosmic_calculate_cfp"),
            ("nesma_calculate_ufp", "compare_standards"),
            ("cosmic_calculate_cfp", "compare_standards"),
            ("compare_standards", "generate_report")
        ]
        
        G.add_edges_from(edges)
        
        plt.figure(figsize=(20, 15))
        pos = nx.spring_layout(G, k=3, iterations=50)
        
        nx.draw_networkx_nodes(G, pos, node_color='lightblue', 
                              node_size=3000, alpha=0.7)
        
        nx.draw_networkx_edges(G, pos, edge_color='gray', arrows=True, 
                              arrowsize=20, alpha=0.6)
        
        nx.draw_networkx_labels(G, pos, font_size=8, font_weight='bold')
        
        plt.title("é‡å­æ™ºèƒ½åŒ–åŠŸèƒ½ç‚¹ä¼°ç®—ç³»ç»Ÿ - å·¥ä½œæµå›¾", fontsize=16, fontweight='bold')
        plt.axis('off')
        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"å·¥ä½œæµå›¾å·²ä¿å­˜åˆ°: {output_path}")
        
    except ImportError:
        logger.warning("matplotlib å’Œ networkx æœªå®‰è£…ï¼Œæ— æ³•ç”Ÿæˆå¯è§†åŒ–å›¾å½¢")
    except Exception as e:
        logger.error(f"ç”Ÿæˆå·¥ä½œæµå¯è§†åŒ–å¤±è´¥: {e}")


# ==================== å·¥ä½œæµåŒ…è£…ç±» ====================

class FPEstimationWorkflow:
    """åŠŸèƒ½ç‚¹ä¼°ç®—å·¥ä½œæµåŒ…è£…ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–å·¥ä½œæµ"""
        self.compiled_workflow = None
        self.current_state = None
        self.session_id = None
        
    async def initialize(self, project_info, strategy, requirements, user_preferences=None):
        """åˆå§‹åŒ–å·¥ä½œæµçŠ¶æ€"""
        import uuid
        from datetime import datetime
        from models.common_models import EstimationStrategy
        
        self.session_id = str(uuid.uuid4())
        
        self.current_state = {
            "session_id": self.session_id,
            "project_info": project_info,
            "current_state": WorkflowState.STARTING,
            "execution_log": [],
            
            "user_requirements": requirements,
            "user_preferences": user_preferences or {},
            
            "standard_recommendation": None,
            "selected_strategy": strategy,
            
            "requirement_analysis": None,
            "identified_processes": None,
            "current_process_context": None,
            
            "nesma_results": None,
            "nesma_classifications": [],
            "nesma_complexity_results": [],
            "nesma_estimation_result": None,
            
            "cosmic_results": None,
            "cosmic_functional_users": [],
            "cosmic_data_movements": [],
            "cosmic_boundary_analysis": None,
            "cosmic_estimation_result": None,
            
            "validation_results": None,
            
            "comparison_analysis": None,
            "final_report": None,
            
            "error_message": None,
            "retry_count": 0,
            "max_retries": 3,
            
            "created_at": datetime.now(),
            "updated_at": datetime.now(),
            "processing_stats": {}
        }
        
        self.compiled_workflow = create_compiled_workflow()
        
        return self.session_id
    
    async def execute(self):
        """æ‰§è¡Œå·¥ä½œæµ"""
        if not self.compiled_workflow or not self.current_state:
            raise ValueError("å·¥ä½œæµæœªæ­£ç¡®åˆå§‹åŒ–")
        
        try:
            final_state = await self.compiled_workflow.ainvoke(
                self.current_state,
                config={"configurable": {"thread_id": self.session_id}}
            )
            
            self.current_state = final_state
            return final_state
            
        except Exception as e:
            logger.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}")
            if self.current_state:
                self.current_state["error_message"] = str(e)
                self.current_state["current_state"] = WorkflowState.ERROR_ENCOUNTERED
            raise
    
    async def get_current_state(self):
        """è·å–å½“å‰çŠ¶æ€"""
        return self.current_state
    
    def get_session_id(self):
        """è·å–ä¼šè¯ID"""
        return self.session_id


# ==================== å‘åå…¼å®¹å‡½æ•° ====================

async def create_function_point_workflow():
    """åˆ›å»ºåŠŸèƒ½ç‚¹ä¼°ç®—å·¥ä½œæµ - å‘åå…¼å®¹çš„å‡½æ•°"""
    return create_compiled_workflow()


def create_workflow():
    """åˆ›å»ºå·¥ä½œæµ - å¦ä¸€ä¸ªå‘åå…¼å®¹çš„å‡½æ•°"""
    return create_compiled_workflow()


# ==================== å¯¼å‡ºæ¥å£ ====================

__all__ = [
    "create_workflow_graph",
    "create_compiled_workflow", 
    "get_workflow_config",
    "visualize_workflow",
    "FPEstimationWorkflow"
]


if __name__ == "__main__":
    # æµ‹è¯•å·¥ä½œæµåˆ›å»º
    try:
        workflow = create_compiled_workflow()
        print("âœ… å·¥ä½œæµå›¾åˆ›å»ºæˆåŠŸ")
        
        # ç”Ÿæˆå¯è§†åŒ–å›¾
        try:
            visualize_workflow(workflow)
            print("âœ… å·¥ä½œæµå¯è§†åŒ–å›¾ç”ŸæˆæˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ å·¥ä½œæµå¯è§†åŒ–å¤±è´¥: {e}")
            
    except Exception as e:
        print(f"âŒ å·¥ä½œæµå›¾åˆ›å»ºå¤±è´¥: {e}") 