"""
é‡å­æ™ºèƒ½åŒ–åŠŸèƒ½ç‚¹ä¼°ç®—ç³»ç»Ÿ - LangGraphèŠ‚ç‚¹å‡½æ•°

å®ç°å·¥ä½œæµä¸­çš„å„ä¸ªèŠ‚ç‚¹é€»è¾‘
"""

import asyncio
import time
from typing import Dict, Any, Optional, List
import logging
from datetime import datetime

from graph.state_definitions import (
    WorkflowGraphState, WorkflowState, ProcessingStage,
    transition_state, update_execution_log, is_retry_needed,
    increment_retry_attempt
)
from agents.standards.standard_recommender import StandardRecommenderAgent
from agents.analysis.requirement_parser import RequirementParserAgent
from agents.analysis.process_identifier import ProcessIdentifierAgent
from agents.analysis.comparison_analyzer import ComparisonAnalyzerAgent
from agents.standards.nesma.function_classifier import NESMAFunctionClassifierAgent
from agents.standards.nesma.complexity_calculator import NESMAComplexityCalculatorAgent
from agents.standards.nesma.ufp_calculator import NESMAUFPCalculatorAgent
from agents.standards.cosmic.functional_user_agent import COSMICFunctionalUserAgent
from agents.standards.cosmic.boundary_analyzer import COSMICBoundaryAnalyzerAgent
from agents.standards.cosmic.data_movement_classifier import COSMICDataMovementClassifierAgent
from agents.standards.cosmic.cfp_calculator import COSMICCFPCalculatorAgent
from agents.knowledge.validator import ValidatorAgent
from agents.output.report_generator import ReportGeneratorAgent

logger = logging.getLogger(__name__)


# åˆå§‹åŒ–èŠ‚ç‚¹
async def start_workflow_node(state: WorkflowGraphState) -> WorkflowGraphState:
    """å·¥ä½œæµå¯åŠ¨èŠ‚ç‚¹"""
    
    logger.info(f"ğŸš€ å¯åŠ¨å·¥ä½œæµï¼Œä¼šè¯ID: {state['session_id']}")
    
    try:
        # è®°å½•å¯åŠ¨æ—¥å¿—
        state = update_execution_log(
            state,
            agent_id="workflow_manager",
            action="start_workflow",
            status="success",
            details={
                "project_name": state["project_info"].name,
                "user_requirements_length": len(state["user_requirements"])
            }
        )
        
        # è½¬æ¢çŠ¶æ€
        state = transition_state(
            state,
            WorkflowState.REQUIREMENT_INPUT_RECEIVED,
            "å·¥ä½œæµå¯åŠ¨å®Œæˆ"
        )
        
        logger.info("âœ… å·¥ä½œæµå¯åŠ¨æˆåŠŸ")
        return state
        
    except Exception as e:
        logger.error(f"âŒ å·¥ä½œæµå¯åŠ¨å¤±è´¥: {str(e)}")
        state["current_error"] = str(e)
        return transition_state(state, WorkflowState.ERROR_ENCOUNTERED, str(e))


# æ ‡å‡†æ¨èèŠ‚ç‚¹
async def recommend_standard_node(state: WorkflowGraphState) -> WorkflowGraphState:
    """æ ‡å‡†æ¨èèŠ‚ç‚¹"""
    
    logger.info("ğŸ¯ å¼€å§‹æ ‡å‡†æ¨èåˆ†æ...")
    
    start_time = time.time()
    
    try:
        # åˆ›å»ºæ ‡å‡†æ¨èæ™ºèƒ½ä½“
        recommender = StandardRecommenderAgent()
        
        # æ‰§è¡Œæ ‡å‡†æ¨è
        recommendation = await recommender.recommend_estimation_standard(
            project_info=state["project_info"],
            user_preferences=state["user_preferences"]
        )
        
        # æ›´æ–°çŠ¶æ€
        state["standard_recommendation"] = {
            "recommended_strategy": recommendation.strategy,
            "confidence_score": recommendation.confidence_score,
            "reasoning": recommendation.reasoning,
            "nesma_suitability": getattr(recommendation, "nesma_suitability", 0.5),
            "cosmic_suitability": getattr(recommendation, "cosmic_suitability", 0.5),
            "project_characteristics": getattr(recommendation, "project_characteristics", {}),
            "recommendation_details": getattr(recommendation, "recommendation_details", {})
        }
        
        state["selected_strategy"] = recommendation.strategy
        
        processing_time = time.time() - start_time
        
        # è®°å½•æ‰§è¡Œæ—¥å¿—
        state = update_execution_log(
            state,
            agent_id="standard_recommender",
            action="recommend_standard",
            status="success",
            duration_ms=int(processing_time * 1000),
            details={
                "recommended_strategy": recommendation.strategy,
                "confidence_score": recommendation.confidence_score
            }
        )
        
        # è½¬æ¢çŠ¶æ€
        state = transition_state(
            state,
            WorkflowState.STANDARD_RECOMMENDATION_READY,
            f"æ ‡å‡†æ¨èå®Œæˆ: {recommendation.strategy}"
        )
        
        logger.info(f"âœ… æ ‡å‡†æ¨èå®Œæˆ: {recommendation.strategy}")
        return state
        
    except Exception as e:
        logger.error(f"âŒ æ ‡å‡†æ¨èå¤±è´¥: {str(e)}")
        state["current_error"] = str(e)
        return transition_state(state, WorkflowState.ERROR_ENCOUNTERED, str(e))


# éœ€æ±‚è§£æèŠ‚ç‚¹
async def parse_requirements_node(state: WorkflowGraphState) -> WorkflowGraphState:
    """éœ€æ±‚è§£æèŠ‚ç‚¹"""
    
    logger.info("ğŸ“ å¼€å§‹éœ€æ±‚è§£æ...")
    
    start_time = time.time()
    
    try:
        # åˆ›å»ºéœ€æ±‚è§£ææ™ºèƒ½ä½“
        parser = RequirementParserAgent()
        
        # æ‰§è¡Œéœ€æ±‚è§£æ
        analysis_result = await parser.parse_requirements(
            requirement_text=state["user_requirements"],
            project_info=state["project_info"]
        )
        
        # æ›´æ–°çŠ¶æ€
        state["requirement_analysis"] = {
            "functional_modules": analysis_result.get("functional_modules", []),
            "business_entities": analysis_result.get("business_entities", {}),
            "business_processes": analysis_result.get("business_processes", []),
            "data_groups": analysis_result.get("data_groups", []),
            "analysis_confidence": analysis_result.get("confidence_score", 0.0),
            "parsing_issues": analysis_result.get("parsing_issues", []),
            "analysis_metadata": analysis_result.get("metadata", {})
        }
        
        processing_time = time.time() - start_time
        
        # è®°å½•æ‰§è¡Œæ—¥å¿—
        state = update_execution_log(
            state,
            agent_id="requirement_parser",
            action="parse_requirements",
            status="success",
            duration_ms=int(processing_time * 1000),
            details={
                "functional_modules_count": len(state["requirement_analysis"]["functional_modules"]),
                "analysis_confidence": state["requirement_analysis"]["analysis_confidence"]
            }
        )
        
        # è½¬æ¢çŠ¶æ€
        state = transition_state(
            state,
            WorkflowState.REQUIREMENT_PARSING_COMPLETED,
            "éœ€æ±‚è§£æå®Œæˆ"
        )
        
        logger.info("âœ… éœ€æ±‚è§£æå®Œæˆ")
        return state
        
    except Exception as e:
        logger.error(f"âŒ éœ€æ±‚è§£æå¤±è´¥: {str(e)}")
        state["current_error"] = str(e)
        return transition_state(state, WorkflowState.ERROR_ENCOUNTERED, str(e))


# æµç¨‹è¯†åˆ«èŠ‚ç‚¹
async def identify_processes_node(state: WorkflowGraphState) -> WorkflowGraphState:
    """æµç¨‹è¯†åˆ«èŠ‚ç‚¹"""
    
    logger.info("ğŸ” å¼€å§‹æµç¨‹è¯†åˆ«...")
    
    start_time = time.time()
    
    try:
        # åˆ›å»ºæµç¨‹è¯†åˆ«æ™ºèƒ½ä½“
        identifier = ProcessIdentifierAgent()
        
        # æ‰§è¡Œæµç¨‹è¯†åˆ«
        processes = await identifier.identify_processes(
            requirement_analysis=state["requirement_analysis"],
            project_info=state["project_info"]
        )
        
        # æ›´æ–°çŠ¶æ€
        state["identified_processes"] = processes
        
        processing_time = time.time() - start_time
        
        # è®°å½•æ‰§è¡Œæ—¥å¿—
        state = update_execution_log(
            state,
            agent_id="process_identifier",
            action="identify_processes",
            status="success",
            duration_ms=int(processing_time * 1000),
            details={
                "processes_count": len(processes),
                "process_names": [p.name for p in processes]
            }
        )
        
        # è½¬æ¢çŠ¶æ€
        state = transition_state(
            state,
            WorkflowState.PROCESSES_IDENTIFIED,
            f"è¯†åˆ«å‡º {len(processes)} ä¸ªåŠŸèƒ½æµç¨‹"
        )
        
        logger.info(f"âœ… æµç¨‹è¯†åˆ«å®Œæˆï¼Œè¯†åˆ«å‡º {len(processes)} ä¸ªæµç¨‹")
        return state
        
    except Exception as e:
        logger.error(f"âŒ æµç¨‹è¯†åˆ«å¤±è´¥: {str(e)}")
        state["current_error"] = str(e)
        return transition_state(state, WorkflowState.ERROR_ENCOUNTERED, str(e))


# NESMAåŠŸèƒ½åˆ†ç±»èŠ‚ç‚¹
async def nesma_classify_functions_node(state: WorkflowGraphState) -> WorkflowGraphState:
    """NESMAåŠŸèƒ½åˆ†ç±»èŠ‚ç‚¹"""
    
    logger.info("ğŸ¯ å¼€å§‹NESMAåŠŸèƒ½åˆ†ç±»...")
    
    start_time = time.time()
    
    try:
        # åˆ›å»ºNESMAåŠŸèƒ½åˆ†ç±»æ™ºèƒ½ä½“
        classifier = NESMAFunctionClassifierAgent()
        
        classifications = []
        processes = state["identified_processes"] or []
        
        for process in processes:
            # ä¸ºæ¯ä¸ªæµç¨‹è¿›è¡ŒåŠŸèƒ½åˆ†ç±»
            classification = await classifier.classify_function_type(
                process_detail=process,
                project_context=state["project_info"]
            )
            classifications.append(classification)
        
        # åˆå§‹åŒ–NESMAç»“æœ
        if not state["nesma_results"]:
            state["nesma_results"] = {
                "function_classifications": [],
                "complexity_results": [],
                "total_ufp": 0,
                "ufp_breakdown": {},
                "estimation_confidence": 0.0,
                "classification_issues": [],
                "calculation_metadata": {}
            }
        
        state["nesma_results"]["function_classifications"] = classifications
        
        processing_time = time.time() - start_time
        
        # è®°å½•æ‰§è¡Œæ—¥å¿—
        state = update_execution_log(
            state,
            agent_id="nesma_classifier",
            action="classify_functions",
            status="success",
            duration_ms=int(processing_time * 1000),
            details={
                "classifications_count": len(classifications),
                "function_types": [c.function_type for c in classifications]
            }
        )
        
        # è½¬æ¢çŠ¶æ€
        state = transition_state(
            state,
            WorkflowState.NESMA_CLASSIFICATION_COMPLETED,
            f"NESMAåŠŸèƒ½åˆ†ç±»å®Œæˆï¼Œåˆ†ç±» {len(classifications)} ä¸ªåŠŸèƒ½"
        )
        
        logger.info(f"âœ… NESMAåŠŸèƒ½åˆ†ç±»å®Œæˆ")
        return state
        
    except Exception as e:
        logger.error(f"âŒ NESMAåŠŸèƒ½åˆ†ç±»å¤±è´¥: {str(e)}")
        state["current_error"] = str(e)
        return transition_state(state, WorkflowState.ERROR_ENCOUNTERED, str(e))


# NESMAå¤æ‚åº¦è®¡ç®—èŠ‚ç‚¹
async def nesma_calculate_complexity_node(state: WorkflowGraphState) -> WorkflowGraphState:
    """NESMAå¤æ‚åº¦è®¡ç®—èŠ‚ç‚¹"""
    
    logger.info("âš™ï¸ å¼€å§‹NESMAå¤æ‚åº¦è®¡ç®—...")
    
    start_time = time.time()
    
    try:
        # åˆ›å»ºNESMAå¤æ‚åº¦è®¡ç®—æ™ºèƒ½ä½“
        calculator = NESMAComplexityCalculatorAgent()
        
        complexity_results = []
        classifications = state["nesma_results"]["function_classifications"]
        
        for classification in classifications:
            # ä¸ºæ¯ä¸ªåˆ†ç±»è®¡ç®—å¤æ‚åº¦
            complexity = await calculator.calculate_complexity(
                classification=classification,
                detailed_requirements=state["requirement_analysis"]
            )
            complexity_results.append(complexity)
        
        state["nesma_results"]["complexity_results"] = complexity_results
        
        processing_time = time.time() - start_time
        
        # è®°å½•æ‰§è¡Œæ—¥å¿—
        state = update_execution_log(
            state,
            agent_id="nesma_complexity_calculator",
            action="calculate_complexity",
            status="success",
            duration_ms=int(processing_time * 1000),
            details={
                "complexity_results_count": len(complexity_results)
            }
        )
        
        # è½¬æ¢çŠ¶æ€
        state = transition_state(
            state,
            WorkflowState.NESMA_COMPLEXITY_COMPLETED,
            "NESMAå¤æ‚åº¦è®¡ç®—å®Œæˆ"
        )
        
        logger.info("âœ… NESMAå¤æ‚åº¦è®¡ç®—å®Œæˆ")
        return state
        
    except Exception as e:
        logger.error(f"âŒ NESMAå¤æ‚åº¦è®¡ç®—å¤±è´¥: {str(e)}")
        state["current_error"] = str(e)
        return transition_state(state, WorkflowState.ERROR_ENCOUNTERED, str(e))


# NESMA UFPè®¡ç®—èŠ‚ç‚¹
async def nesma_calculate_ufp_node(state: WorkflowGraphState) -> WorkflowGraphState:
    """NESMA UFPè®¡ç®—èŠ‚ç‚¹"""
    
    logger.info("ğŸ§® å¼€å§‹NESMA UFPè®¡ç®—...")
    
    start_time = time.time()
    
    try:
        # åˆ›å»ºNESMA UFPè®¡ç®—æ™ºèƒ½ä½“
        calculator = NESMAUFPCalculatorAgent()
        
        # æ‰§è¡ŒUFPè®¡ç®—
        ufp_result = await calculator.calculate_unadjusted_function_points(
            classifications=state["nesma_results"]["function_classifications"],
            complexity_results=state["nesma_results"]["complexity_results"]
        )
        
        # æ›´æ–°NESMAç»“æœ
        state["nesma_results"]["total_ufp"] = ufp_result.total_ufp
        state["nesma_results"]["ufp_breakdown"] = ufp_result.ufp_breakdown
        state["nesma_results"]["estimation_confidence"] = ufp_result.confidence_score
        state["nesma_results"]["calculation_metadata"] = ufp_result.calculation_details
        
        processing_time = time.time() - start_time
        
        # è®°å½•æ‰§è¡Œæ—¥å¿—
        state = update_execution_log(
            state,
            agent_id="nesma_ufp_calculator",
            action="calculate_ufp",
            status="success",
            duration_ms=int(processing_time * 1000),
            details={
                "total_ufp": ufp_result.total_ufp,
                "confidence_score": ufp_result.confidence_score
            }
        )
        
        # è½¬æ¢çŠ¶æ€
        state = transition_state(
            state,
            WorkflowState.NESMA_CALCULATION_COMPLETED,
            f"NESMA UFPè®¡ç®—å®Œæˆ: {ufp_result.total_ufp} UFP"
        )
        
        logger.info(f"âœ… NESMA UFPè®¡ç®—å®Œæˆ: {ufp_result.total_ufp} UFP")
        return state
        
    except Exception as e:
        logger.error(f"âŒ NESMA UFPè®¡ç®—å¤±è´¥: {str(e)}")
        state["current_error"] = str(e)
        return transition_state(state, WorkflowState.ERROR_ENCOUNTERED, str(e))


# COSMICåŠŸèƒ½ç”¨æˆ·è¯†åˆ«èŠ‚ç‚¹
async def cosmic_identify_users_node(state: WorkflowGraphState) -> WorkflowGraphState:
    """COSMICåŠŸèƒ½ç”¨æˆ·è¯†åˆ«èŠ‚ç‚¹"""
    
    logger.info("ğŸ‘¥ å¼€å§‹COSMICåŠŸèƒ½ç”¨æˆ·è¯†åˆ«...")
    
    start_time = time.time()
    
    try:
        # åˆ›å»ºCOSMICåŠŸèƒ½ç”¨æˆ·æ™ºèƒ½ä½“
        user_agent = COSMICFunctionalUserAgent()
        
        # æ‰§è¡ŒåŠŸèƒ½ç”¨æˆ·è¯†åˆ«
        functional_users = await user_agent.identify_functional_users(
            project_info=state["project_info"],
            requirement_analysis=state["requirement_analysis"],
            identified_processes=state["identified_processes"]
        )
        
        # åˆå§‹åŒ–COSMICç»“æœ
        if not state["cosmic_results"]:
            state["cosmic_results"] = {
                "functional_users": [],
                "boundary_analysis": None,
                "data_movements": [],
                "functional_processes": [],
                "total_cfp": 0,
                "cfp_breakdown": {},
                "estimation_confidence": 0.0,
                "analysis_issues": [],
                "calculation_metadata": {}
            }
        
        state["cosmic_results"]["functional_users"] = functional_users
        
        processing_time = time.time() - start_time
        
        # è®°å½•æ‰§è¡Œæ—¥å¿—
        state = update_execution_log(
            state,
            agent_id="cosmic_functional_user",
            action="identify_users",
            status="success",
            duration_ms=int(processing_time * 1000),
            details={
                "functional_users_count": len(functional_users),
                "user_names": [user.name for user in functional_users]
            }
        )
        
        logger.info(f"âœ… COSMICåŠŸèƒ½ç”¨æˆ·è¯†åˆ«å®Œæˆï¼Œè¯†åˆ«å‡º {len(functional_users)} ä¸ªåŠŸèƒ½ç”¨æˆ·")
        return state
        
    except Exception as e:
        logger.error(f"âŒ COSMICåŠŸèƒ½ç”¨æˆ·è¯†åˆ«å¤±è´¥: {str(e)}")
        state["current_error"] = str(e)
        return transition_state(state, WorkflowState.ERROR_ENCOUNTERED, str(e))


# COSMICè¾¹ç•Œåˆ†æèŠ‚ç‚¹
async def cosmic_analyze_boundary_node(state: WorkflowGraphState) -> WorkflowGraphState:
    """COSMICè¾¹ç•Œåˆ†æèŠ‚ç‚¹"""
    
    logger.info("ğŸ—ï¸ å¼€å§‹COSMICè¾¹ç•Œåˆ†æ...")
    
    start_time = time.time()
    
    try:
        # åˆ›å»ºCOSMICè¾¹ç•Œåˆ†ææ™ºèƒ½ä½“
        boundary_analyzer = COSMICBoundaryAnalyzerAgent()
        
        # æ‰§è¡Œè¾¹ç•Œåˆ†æ
        boundary_analysis = await boundary_analyzer.analyze_system_boundary(
            project_info=state["project_info"],
            functional_users=state["cosmic_results"]["functional_users"],
            requirement_analysis=state["requirement_analysis"]
        )
        
        state["cosmic_results"]["boundary_analysis"] = boundary_analysis
        
        processing_time = time.time() - start_time
        
        # è®°å½•æ‰§è¡Œæ—¥å¿—
        state = update_execution_log(
            state,
            agent_id="cosmic_boundary_analyzer",
            action="analyze_boundary",
            status="success",
            duration_ms=int(processing_time * 1000),
            details={
                "software_boundary": boundary_analysis.software_boundary,
                "storage_boundary": boundary_analysis.persistent_storage_boundary
            }
        )
        
        logger.info("âœ… COSMICè¾¹ç•Œåˆ†æå®Œæˆ")
        return state
        
    except Exception as e:
        logger.error(f"âŒ COSMICè¾¹ç•Œåˆ†æå¤±è´¥: {str(e)}")
        state["current_error"] = str(e)
        return transition_state(state, WorkflowState.ERROR_ENCOUNTERED, str(e))


# COSMICæ•°æ®ç§»åŠ¨åˆ†ç±»èŠ‚ç‚¹
async def cosmic_classify_movements_node(state: WorkflowGraphState) -> WorkflowGraphState:
    """COSMICæ•°æ®ç§»åŠ¨åˆ†ç±»èŠ‚ç‚¹"""
    
    logger.info("ğŸ”„ å¼€å§‹COSMICæ•°æ®ç§»åŠ¨åˆ†ç±»...")
    
    start_time = time.time()
    
    try:
        # åˆ›å»ºCOSMICæ•°æ®ç§»åŠ¨åˆ†ç±»æ™ºèƒ½ä½“
        movement_classifier = COSMICDataMovementClassifierAgent()
        
        # æ‰§è¡Œæ•°æ®ç§»åŠ¨åˆ†ç±»
        data_movements = await movement_classifier.classify_data_movements(
            identified_processes=state["identified_processes"],
            functional_users=state["cosmic_results"]["functional_users"],
            boundary_analysis=state["cosmic_results"]["boundary_analysis"]
        )
        
        state["cosmic_results"]["data_movements"] = data_movements
        
        processing_time = time.time() - start_time
        
        # è®°å½•æ‰§è¡Œæ—¥å¿—
        state = update_execution_log(
            state,
            agent_id="cosmic_movement_classifier",
            action="classify_movements",
            status="success",
            duration_ms=int(processing_time * 1000),
            details={
                "data_movements_count": len(data_movements),
                "movement_types": [dm.type for dm in data_movements]
            }
        )
        
        # è½¬æ¢çŠ¶æ€
        state = transition_state(
            state,
            WorkflowState.COSMIC_ANALYSIS_COMPLETED,
            f"COSMICæ•°æ®ç§»åŠ¨åˆ†ç±»å®Œæˆï¼Œè¯†åˆ«å‡º {len(data_movements)} ä¸ªæ•°æ®ç§»åŠ¨"
        )
        
        logger.info(f"âœ… COSMICæ•°æ®ç§»åŠ¨åˆ†ç±»å®Œæˆ")
        return state
        
    except Exception as e:
        logger.error(f"âŒ COSMICæ•°æ®ç§»åŠ¨åˆ†ç±»å¤±è´¥: {str(e)}")
        state["current_error"] = str(e)
        return transition_state(state, WorkflowState.ERROR_ENCOUNTERED, str(e))


# COSMIC CFPè®¡ç®—èŠ‚ç‚¹
async def cosmic_calculate_cfp_node(state: WorkflowGraphState) -> WorkflowGraphState:
    """COSMIC CFPè®¡ç®—èŠ‚ç‚¹"""
    
    logger.info("ğŸ§® å¼€å§‹COSMIC CFPè®¡ç®—...")
    
    start_time = time.time()
    
    try:
        # åˆ›å»ºCOSMIC CFPè®¡ç®—æ™ºèƒ½ä½“
        cfp_calculator = COSMICCFPCalculatorAgent()
        
        # æ‰§è¡ŒCFPè®¡ç®—
        cfp_result = await cfp_calculator.calculate_cosmic_function_points(
            data_movements=state["cosmic_results"]["data_movements"],
            functional_processes=state["identified_processes"],
            boundary_analysis=state["cosmic_results"]["boundary_analysis"]
        )
        
        # æ›´æ–°COSMICç»“æœ
        state["cosmic_results"]["total_cfp"] = cfp_result.total_cfp
        state["cosmic_results"]["cfp_breakdown"] = cfp_result.cfp_breakdown
        state["cosmic_results"]["estimation_confidence"] = cfp_result.confidence_score
        state["cosmic_results"]["functional_processes"] = cfp_result.functional_processes
        state["cosmic_results"]["calculation_metadata"] = cfp_result.calculation_details
        
        processing_time = time.time() - start_time
        
        # è®°å½•æ‰§è¡Œæ—¥å¿—
        state = update_execution_log(
            state,
            agent_id="cosmic_cfp_calculator",
            action="calculate_cfp",
            status="success",
            duration_ms=int(processing_time * 1000),
            details={
                "total_cfp": cfp_result.total_cfp,
                "confidence_score": cfp_result.confidence_score
            }
        )
        
        # è½¬æ¢çŠ¶æ€
        state = transition_state(
            state,
            WorkflowState.COSMIC_CALCULATION_COMPLETED,
            f"COSMIC CFPè®¡ç®—å®Œæˆ: {cfp_result.total_cfp} CFP"
        )
        
        logger.info(f"âœ… COSMIC CFPè®¡ç®—å®Œæˆ: {cfp_result.total_cfp} CFP")
        return state
        
    except Exception as e:
        logger.error(f"âŒ COSMIC CFPè®¡ç®—å¤±è´¥: {str(e)}")
        state["current_error"] = str(e)
        return transition_state(state, WorkflowState.ERROR_ENCOUNTERED, str(e))


# ç»“æœéªŒè¯èŠ‚ç‚¹
async def validate_results_node(state: WorkflowGraphState) -> WorkflowGraphState:
    """ç»“æœéªŒè¯èŠ‚ç‚¹"""
    
    logger.info("âœ… å¼€å§‹ç»“æœéªŒè¯...")
    
    start_time = time.time()
    
    try:
        # åˆ›å»ºéªŒè¯æ™ºèƒ½ä½“
        validator = ValidatorAgent()
        
        validation_results = {}
        
        # éªŒè¯NESMAç»“æœ
        if state["nesma_results"]:
            nesma_validation = await validator.validate_analysis_result(
                analysis_type="NESMA_estimation",
                analysis_result=state["nesma_results"],
                input_data=state["requirement_analysis"]
            )
            validation_results["nesma_validation"] = nesma_validation
        
        # éªŒè¯COSMICç»“æœ
        if state["cosmic_results"]:
            cosmic_validation = await validator.validate_analysis_result(
                analysis_type="COSMIC_estimation",
                analysis_result=state["cosmic_results"],
                input_data=state["requirement_analysis"]
            )
            validation_results["cosmic_validation"] = cosmic_validation
        
        # è®¡ç®—æ•´ä½“éªŒè¯åˆ†æ•°
        overall_validation = self._calculate_overall_validation(validation_results)
        validation_results["overall_validation"] = overall_validation
        
        state["validation_results"] = validation_results
        
        processing_time = time.time() - start_time
        
        # è®°å½•æ‰§è¡Œæ—¥å¿—
        state = update_execution_log(
            state,
            agent_id="validator",
            action="validate_results",
            status="success",
            duration_ms=int(processing_time * 1000),
            details={
                "overall_validation_score": overall_validation.confidence_score if overall_validation else 0.0
            }
        )
        
        # è½¬æ¢çŠ¶æ€
        state = transition_state(
            state,
            WorkflowState.VALIDATION_COMPLETED,
            "ç»“æœéªŒè¯å®Œæˆ"
        )
        
        logger.info("âœ… ç»“æœéªŒè¯å®Œæˆ")
        return state
        
    except Exception as e:
        logger.error(f"âŒ ç»“æœéªŒè¯å¤±è´¥: {str(e)}")
        state["current_error"] = str(e)
        return transition_state(state, WorkflowState.ERROR_ENCOUNTERED, str(e))


# å¯¹æ¯”åˆ†æèŠ‚ç‚¹
async def compare_standards_node(state: WorkflowGraphState) -> WorkflowGraphState:
    """è·¨æ ‡å‡†å¯¹æ¯”åˆ†æèŠ‚ç‚¹"""
    
    logger.info("ğŸ“Š å¼€å§‹è·¨æ ‡å‡†å¯¹æ¯”åˆ†æ...")
    
    start_time = time.time()
    
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸¤ç§æ ‡å‡†çš„ç»“æœ
        if not state["nesma_results"] or not state["cosmic_results"]:
            logger.warning("ç¼ºå°‘å®Œæ•´çš„ä¼°ç®—ç»“æœï¼Œè·³è¿‡å¯¹æ¯”åˆ†æ")
            return transition_state(
                state,
                WorkflowState.REPORT_GENERATION_PENDING,
                "è·³è¿‡å¯¹æ¯”åˆ†æï¼Œç¼ºå°‘å®Œæ•´ç»“æœ"
            )
        
        # åˆ›å»ºå¯¹æ¯”åˆ†ææ™ºèƒ½ä½“
        analyzer = ComparisonAnalyzerAgent()
        
        # æ‰§è¡Œå¯¹æ¯”åˆ†æ
        comparison_result = await analyzer.analyze_cross_standard_comparison(
            nesma_results=state["nesma_results"],
            cosmic_results=state["cosmic_results"],
            project_info=state["project_info"].__dict__
        )
        
        state["comparison_result"] = comparison_result
        
        processing_time = time.time() - start_time
        
        # è®°å½•æ‰§è¡Œæ—¥å¿—
        state = update_execution_log(
            state,
            agent_id="comparison_analyzer",
            action="compare_standards",
            status="success",
            duration_ms=int(processing_time * 1000),
            details={
                "difference_percentage": comparison_result.difference_percentage,
                "recommended_standard": comparison_result.recommendation.get("recommended_standard")
            }
        )
        
        # è½¬æ¢çŠ¶æ€
        state = transition_state(
            state,
            WorkflowState.COMPARISON_ANALYSIS_COMPLETED,
            "è·¨æ ‡å‡†å¯¹æ¯”åˆ†æå®Œæˆ"
        )
        
        logger.info("âœ… è·¨æ ‡å‡†å¯¹æ¯”åˆ†æå®Œæˆ")
        return state
        
    except Exception as e:
        logger.error(f"âŒ è·¨æ ‡å‡†å¯¹æ¯”åˆ†æå¤±è´¥: {str(e)}")
        state["current_error"] = str(e)
        return transition_state(state, WorkflowState.ERROR_ENCOUNTERED, str(e))


# æŠ¥å‘Šç”ŸæˆèŠ‚ç‚¹
async def generate_report_node(state: WorkflowGraphState) -> WorkflowGraphState:
    """æŠ¥å‘Šç”ŸæˆèŠ‚ç‚¹"""
    
    logger.info("ğŸ“„ å¼€å§‹ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
    
    start_time = time.time()
    
    try:
        # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆæ™ºèƒ½ä½“
        generator = ReportGeneratorAgent()
        
        # ç”ŸæˆæŠ¥å‘Š
        final_report = await generator.generate_comprehensive_report(
            project_info=state["project_info"],
            nesma_results=state["nesma_results"],
            cosmic_results=state["cosmic_results"],
            comparison_result=state["comparison_result"],
            validation_results=state["validation_results"],
            execution_log=state["execution_log"]
        )
        
        state["final_report"] = final_report
        
        processing_time = time.time() - start_time
        
        # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        state["performance_metrics"]["total_processing_time"] = (
            datetime.now() - state["workflow_start_time"]
        ).total_seconds()
        
        # è®°å½•æ‰§è¡Œæ—¥å¿—
        state = update_execution_log(
            state,
            agent_id="report_generator",
            action="generate_report",
            status="success",
            duration_ms=int(processing_time * 1000),
            details={
                "report_sections": len(final_report.get("sections", [])),
                "total_pages": final_report.get("metadata", {}).get("total_pages", 0)
            }
        )
        
        # è½¬æ¢çŠ¶æ€
        state = transition_state(
            state,
            WorkflowState.REPORT_COMPLETED,
            "æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ"
        )
        
        logger.info("âœ… æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        return state
        
    except Exception as e:
        logger.error(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
        state["current_error"] = str(e)
        return transition_state(state, WorkflowState.ERROR_ENCOUNTERED, str(e))


# å®ŒæˆèŠ‚ç‚¹
async def complete_workflow_node(state: WorkflowGraphState) -> WorkflowGraphState:
    """å·¥ä½œæµå®ŒæˆèŠ‚ç‚¹"""
    
    logger.info("ğŸ‰ å·¥ä½œæµæ‰§è¡Œå®Œæˆ")
    
    try:
        # è®¡ç®—æœ€ç»ˆè´¨é‡æŒ‡æ ‡
        state["quality_metrics"]["overall_confidence"] = self._calculate_overall_confidence(state)
        
        # è®°å½•å®Œæˆæ—¥å¿—
        state = update_execution_log(
            state,
            agent_id="workflow_manager",
            action="complete_workflow",
            status="success",
            details={
                "total_duration": state["performance_metrics"]["total_processing_time"],
                "overall_confidence": state["quality_metrics"]["overall_confidence"],
                "nesma_ufp": state["nesma_results"]["total_ufp"] if state["nesma_results"] else None,
                "cosmic_cfp": state["cosmic_results"]["total_cfp"] if state["cosmic_results"] else None
            }
        )
        
        # è½¬æ¢åˆ°æœ€ç»ˆçŠ¶æ€
        state = transition_state(
            state,
            WorkflowState.COMPLETED,
            "å·¥ä½œæµæ‰§è¡ŒæˆåŠŸå®Œæˆ"
        )
        
        logger.info("âœ… å·¥ä½œæµæ‰§è¡ŒæˆåŠŸå®Œæˆ")
        return state
        
    except Exception as e:
        logger.error(f"âŒ å·¥ä½œæµå®Œæˆå¤±è´¥: {str(e)}")
        state["current_error"] = str(e)
        return transition_state(state, WorkflowState.ERROR_ENCOUNTERED, str(e))


# é”™è¯¯å¤„ç†èŠ‚ç‚¹
async def handle_error_node(state: WorkflowGraphState) -> WorkflowGraphState:
    """é”™è¯¯å¤„ç†èŠ‚ç‚¹"""
    
    logger.error(f"âŒ å¤„ç†å·¥ä½œæµé”™è¯¯: {state['current_error']}")
    
    try:
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡è¯•
        if is_retry_needed(state):
            # å¢åŠ é‡è¯•æ¬¡æ•°
            state = increment_retry_attempt(
                state,
                retry_reason=state["current_error"],
                retry_strategy="simple"
            )
            
            logger.info(f"ğŸ”„ å‡†å¤‡é‡è¯•ï¼Œç¬¬ {state['retry_config']['current_attempt']} æ¬¡")
            
            # è½¬æ¢åˆ°é‡è¯•çŠ¶æ€
            return transition_state(
                state,
                WorkflowState.RETRY_PENDING,
                f"å‡†å¤‡é‡è¯•: {state['current_error']}"
            )
        else:
            # é‡è¯•æ¬¡æ•°å·²è¾¾ä¸Šé™ï¼Œç»ˆæ­¢å·¥ä½œæµ
            logger.error("âŒ é‡è¯•æ¬¡æ•°å·²è¾¾ä¸Šé™ï¼Œç»ˆæ­¢å·¥ä½œæµ")
            
            return transition_state(
                state,
                WorkflowState.TERMINATED,
                f"å·¥ä½œæµç»ˆæ­¢: {state['current_error']}"
            )
            
    except Exception as e:
        logger.error(f"âŒ é”™è¯¯å¤„ç†å¤±è´¥: {str(e)}")
        return transition_state(
            state,
            WorkflowState.TERMINATED,
            f"é”™è¯¯å¤„ç†å¤±è´¥: {str(e)}"
        )


# è¾…åŠ©å‡½æ•°
def _calculate_overall_validation(validation_results: Dict[str, Any]) -> Optional[Any]:
    """è®¡ç®—æ•´ä½“éªŒè¯ç»“æœ"""
    
    scores = []
    
    if "nesma_validation" in validation_results:
        scores.append(validation_results["nesma_validation"].confidence_score)
    
    if "cosmic_validation" in validation_results:
        scores.append(validation_results["cosmic_validation"].confidence_score)
    
    if not scores:
        return None
    
    # åˆ›å»ºè™šæ‹Ÿçš„æ•´ä½“éªŒè¯ç»“æœ
    from models.common_models import ValidationResult
    
    overall_score = sum(scores) / len(scores)
    
    return ValidationResult(
        is_valid=overall_score >= 0.5,
        confidence_score=overall_score,
        validation_details={"component_scores": scores},
        issues=[],
        suggestions=[]
    )


def _calculate_overall_confidence(state: WorkflowGraphState) -> float:
    """è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦"""
    
    confidence_scores = []
    
    # NESMAç½®ä¿¡åº¦
    if state["nesma_results"]:
        confidence_scores.append(state["nesma_results"]["estimation_confidence"])
    
    # COSMICç½®ä¿¡åº¦
    if state["cosmic_results"]:
        confidence_scores.append(state["cosmic_results"]["estimation_confidence"])
    
    # éªŒè¯ç½®ä¿¡åº¦
    if state["validation_results"] and state["validation_results"]["overall_validation"]:
        confidence_scores.append(state["validation_results"]["overall_validation"].confidence_score)
    
    if not confidence_scores:
        return 0.0
    
    return sum(confidence_scores) / len(confidence_scores) 