"""
é‡å­æ™ºèƒ½åŒ–åŠŸèƒ½ç‚¹ä¼°ç®—ç³»ç»Ÿ - éœ€æ±‚è§£ææ™ºèƒ½ä½“

ä»è‡ªç„¶è¯­è¨€éœ€æ±‚æè¿°ä¸­æå–ç»“æ„åŒ–çš„åŠŸèƒ½ä¿¡æ¯
"""

import asyncio
from typing import Dict, Any, Optional, List
import logging
from datetime import datetime
import re

from langchain_core.language_models import BaseLanguageModel
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

from agents.base.base_agent import SpecializedAgent
from models.project_models import ProjectInfo, ProcessDetails
from models.common_models import ConfidenceLevel
from config.settings import get_settings

logger = logging.getLogger(__name__)


class RequirementParserAgent(SpecializedAgent):
    """éœ€æ±‚è§£ææ™ºèƒ½ä½“"""
    
    def __init__(self, llm: Optional[BaseLanguageModel] = None):
        super().__init__(
            agent_id="requirement_parser",
            specialty="natural_language_processing",
            llm=llm
        )
        
        self.settings = get_settings()
        
        # è§£æå†å²å’Œæ¨¡å¼è¯†åˆ«
        self.parsing_history: List[Dict[str, Any]] = []
        self.common_patterns = self._load_common_patterns()
        
    def _load_common_patterns(self) -> Dict[str, List[str]]:
        """åŠ è½½å¸¸è§çš„éœ€æ±‚è¡¨è¾¾æ¨¡å¼"""
        return {
            "åŠŸèƒ½åŠ¨è¯": [
                "å¯ä»¥", "èƒ½å¤Ÿ", "å®ç°", "æä¾›", "æ”¯æŒ", "å…è®¸", "å¸®åŠ©",
                "ç®¡ç†", "ç»´æŠ¤", "å¤„ç†", "ç”Ÿæˆ", "åˆ›å»º", "æŸ¥è¯¢", "æ›´æ–°"
            ],
            "å®ä½“æ ‡è¯†": [
                "ç”¨æˆ·", "ç®¡ç†å‘˜", "ç³»ç»Ÿ", "æ•°æ®", "ä¿¡æ¯", "æŠ¥è¡¨", "æ–‡ä»¶",
                "è®¢å•", "äº§å“", "å®¢æˆ·", "å‘˜å·¥", "éƒ¨é—¨", "é¡¹ç›®"
            ],
            "æ“ä½œç±»å‹": [
                "å¢åŠ ", "åˆ é™¤", "ä¿®æ”¹", "æŸ¥è¯¢", "å¯¼å…¥", "å¯¼å‡º", "æ‰“å°",
                "å‘é€", "æ¥æ”¶", "å®¡æ ¸", "å®¡æ‰¹", "ç»Ÿè®¡", "åˆ†æ"
            ],
            "è¿æ¥è¯": [
                "é€šè¿‡", "åŸºäº", "æ ¹æ®", "æŒ‰ç…§", "åŒ…æ‹¬", "åŒ…å«", "æ¶‰åŠ",
                "å…³äº", "é’ˆå¯¹", "å¯¹äº", "ä»¥åŠ", "å’Œ", "æˆ–è€…"
            ]
        }
    
    def _get_capabilities(self) -> List[str]:
        """è·å–æ™ºèƒ½ä½“èƒ½åŠ›åˆ—è¡¨"""
        return [
            "è‡ªç„¶è¯­è¨€éœ€æ±‚è§£æ",
            "åŠŸèƒ½è¾¹ç•Œè¯†åˆ«",
            "å®ä½“å…³ç³»æå–",
            "ä¸šåŠ¡æµç¨‹æ¢³ç†",
            "éœ€æ±‚ç»“æ„åŒ–è½¬æ¢"
        ]
    
    async def _execute_task(self, task_name: str, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œéœ€æ±‚è§£æä»»åŠ¡"""
        if task_name == "parse_requirements":
            return await self.parse_requirements(inputs["requirement_text"])
        elif task_name == "extract_functional_entities":
            return await self.extract_functional_entities(inputs["requirement_text"])
        elif task_name == "identify_business_processes":
            return await self.identify_business_processes(inputs["requirement_text"])
        elif task_name == "validate_parsed_requirements":
            return await self.validate_parsed_requirements(
                inputs["parsed_requirements"],
                inputs["original_text"]
            )
        else:
            raise ValueError(f"æœªçŸ¥ä»»åŠ¡: {task_name}")
    
    async def parse_requirements(self, requirement_text: str) -> Dict[str, Any]:
        """è§£æéœ€æ±‚æ–‡æœ¬ï¼Œæå–ç»“æ„åŒ–ä¿¡æ¯"""
        
        # 1. é¢„å¤„ç†éœ€æ±‚æ–‡æœ¬
        processed_text = self._preprocess_text(requirement_text)
        
        # 2. è¯†åˆ«åŠŸèƒ½æ¨¡å—
        functional_modules = await self._identify_functional_modules(processed_text)
        
        # 3. æå–ä¸šåŠ¡å®ä½“
        business_entities = await self.extract_functional_entities(processed_text)
        
        # 4. è¯†åˆ«ä¸šåŠ¡æµç¨‹
        business_processes = await self.identify_business_processes(processed_text)
        
        # 5. æ„å»ºè§£æç»“æœ
        parsing_result = {
            "original_text": requirement_text,
            "processed_text": processed_text,
            "functional_modules": functional_modules,
            "business_entities": business_entities,
            "business_processes": business_processes,
            "parsing_confidence": self._calculate_parsing_confidence(
                functional_modules, business_entities, business_processes
            ),
            "parsing_timestamp": datetime.now()
        }
        
        # 6. è®°å½•è§£æå†å²
        self.parsing_history.append(parsing_result)
        
        return parsing_result
    
    async def extract_functional_entities(self, requirement_text: str) -> Dict[str, List[str]]:
        """æå–åŠŸèƒ½ç›¸å…³çš„å®ä½“"""
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯éœ€æ±‚åˆ†æä¸“å®¶ï¼Œéœ€è¦ä»éœ€æ±‚æè¿°ä¸­æå–å…³é”®çš„åŠŸèƒ½å®ä½“ã€‚

è¯·è¯†åˆ«ä»¥ä¸‹ç±»å‹çš„å®ä½“ï¼š
1. ç”¨æˆ·è§’è‰²ï¼šè°ä¼šä½¿ç”¨è¿™äº›åŠŸèƒ½
2. ä¸šåŠ¡å¯¹è±¡ï¼šç³»ç»Ÿå¤„ç†çš„ä¸»è¦æ•°æ®æˆ–ä¿¡æ¯
3. åŠŸèƒ½æ“ä½œï¼šç”¨æˆ·å¯ä»¥æ‰§è¡Œçš„æ“ä½œ
4. è¾“å…¥è¾“å‡ºï¼šæ•°æ®çš„æ¥æºå’Œå»å‘
5. ä¸šåŠ¡è§„åˆ™ï¼šçº¦æŸæ¡ä»¶å’Œä¸šåŠ¡é€»è¾‘

è¯·è¿”å›JSONæ ¼å¼çš„ç»“æœã€‚"""),
            ("human", """éœ€æ±‚æè¿°ï¼š
{requirement_text}

è¯·æå–åŠŸèƒ½ç›¸å…³çš„å®ä½“ï¼Œå¹¶æŒ‰ç±»å‹åˆ†ç»„ã€‚

è¿”å›æ ¼å¼ï¼š
{{
  "ç”¨æˆ·è§’è‰²": ["è§’è‰²1", "è§’è‰²2"],
  "ä¸šåŠ¡å¯¹è±¡": ["å¯¹è±¡1", "å¯¹è±¡2"], 
  "åŠŸèƒ½æ“ä½œ": ["æ“ä½œ1", "æ“ä½œ2"],
  "è¾“å…¥è¾“å‡º": ["è¾“å…¥1", "è¾“å‡º1"],
  "ä¸šåŠ¡è§„åˆ™": ["è§„åˆ™1", "è§„åˆ™2"]
}}""")
        ])
        
        response = await self.llm.ainvoke(
            prompt.format_messages(requirement_text=requirement_text)
        )
        
        # è§£æå®ä½“æå–ç»“æœ
        return await self._parse_entity_extraction(response.content)
    
    async def identify_business_processes(self, requirement_text: str) -> List[ProcessDetails]:
        """è¯†åˆ«ä¸šåŠ¡æµç¨‹"""
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸šåŠ¡æµç¨‹åˆ†æä¸“å®¶ï¼Œéœ€è¦ä»éœ€æ±‚æè¿°ä¸­è¯†åˆ«ç‹¬ç«‹çš„ä¸šåŠ¡æµç¨‹ã€‚

ä¸€ä¸ªä¸šåŠ¡æµç¨‹åº”è¯¥å…·å¤‡ï¼š
1. æ˜ç¡®çš„å¼€å§‹å’Œç»“æŸæ¡ä»¶
2. æ¸…æ™°çš„å¤„ç†æ­¥éª¤
3. æ¶‰åŠçš„æ•°æ®æˆ–å®ä½“
4. äº§ç”Ÿçš„è¾“å‡ºæˆ–ç»“æœ

è¯·è¯†åˆ«æ¯ä¸ªç‹¬ç«‹çš„ä¸šåŠ¡æµç¨‹ï¼Œå¹¶æè¿°å…¶ç‰¹å¾ã€‚"""),
            ("human", """éœ€æ±‚æè¿°ï¼š
{requirement_text}

è¯·è¯†åˆ«å…¶ä¸­çš„ä¸šåŠ¡æµç¨‹ï¼Œæ¯ä¸ªæµç¨‹åŒ…å«ï¼š
- æµç¨‹åç§°
- æµç¨‹æè¿°
- æ¶‰åŠçš„æ•°æ®ç»„
- ä¸»è¦æ­¥éª¤
- è¾“å…¥è¾“å‡º

è¿”å›JSONæ ¼å¼çš„æµç¨‹åˆ—è¡¨ã€‚""")
        ])
        
        response = await self.llm.ainvoke(
            prompt.format_messages(requirement_text=requirement_text)
        )
        
        # è§£æä¸šåŠ¡æµç¨‹
        return await self._parse_business_processes(response.content)
    
    async def validate_parsed_requirements(
        self, 
        parsed_requirements: Dict[str, Any], 
        original_text: str
    ) -> Dict[str, Any]:
        """éªŒè¯è§£æç»“æœçš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§"""
        
        validation_result = {
            "completeness_score": 0.0,
            "accuracy_score": 0.0,
            "consistency_score": 0.0,
            "overall_score": 0.0,
            "issues": [],
            "suggestions": []
        }
        
        # 1. å®Œæ•´æ€§æ£€æŸ¥
        completeness_issues = self._check_completeness(parsed_requirements, original_text)
        validation_result["completeness_score"] = 1.0 - len(completeness_issues) * 0.2
        validation_result["issues"].extend(completeness_issues)
        
        # 2. å‡†ç¡®æ€§æ£€æŸ¥
        accuracy_issues = self._check_accuracy(parsed_requirements, original_text)
        validation_result["accuracy_score"] = 1.0 - len(accuracy_issues) * 0.15
        validation_result["issues"].extend(accuracy_issues)
        
        # 3. ä¸€è‡´æ€§æ£€æŸ¥
        consistency_issues = self._check_consistency(parsed_requirements)
        validation_result["consistency_score"] = 1.0 - len(consistency_issues) * 0.1
        validation_result["issues"].extend(consistency_issues)
        
        # 4. è®¡ç®—æ€»ä½“è¯„åˆ†
        validation_result["overall_score"] = (
            validation_result["completeness_score"] * 0.4 +
            validation_result["accuracy_score"] * 0.4 +
            validation_result["consistency_score"] * 0.2
        )
        
        # 5. ç”Ÿæˆæ”¹è¿›å»ºè®®
        validation_result["suggestions"] = self._generate_improvement_suggestions(
            validation_result
        )
        
        return validation_result
    
    def _preprocess_text(self, text: str) -> str:
        """é¢„å¤„ç†éœ€æ±‚æ–‡æœ¬"""
        
        # å»é™¤å¤šä½™ç©ºç™½
        processed = re.sub(r'\s+', ' ', text.strip())
        
        # æ ‡å‡†åŒ–æ ‡ç‚¹ç¬¦å·
        processed = re.sub(r'[ï¼Œã€‚ï¼›ï¼šï¼ï¼Ÿ]', 'ã€‚', processed)
        
        # åˆ†å¥å¤„ç†
        sentences = processed.split('ã€‚')
        cleaned_sentences = [s.strip() for s in sentences if s.strip()]
        
        return 'ã€‚'.join(cleaned_sentences)
    
    async def _identify_functional_modules(self, text: str) -> List[Dict[str, Any]]:
        """è¯†åˆ«åŠŸèƒ½æ¨¡å—"""
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ç³»ç»Ÿæ¶æ„å¸ˆï¼Œéœ€è¦ä»éœ€æ±‚æè¿°ä¸­è¯†åˆ«åŠŸèƒ½æ¨¡å—ã€‚

åŠŸèƒ½æ¨¡å—æ˜¯ç›¸å¯¹ç‹¬ç«‹çš„åŠŸèƒ½é›†åˆï¼Œé€šå¸¸åŒ…å«ï¼š
- ç›¸å…³çš„ä¸šåŠ¡åŠŸèƒ½
- å…±åŒçš„æ•°æ®å¤„ç†
- ç‰¹å®šçš„ç”¨æˆ·ç¾¤ä½“
- æ˜ç¡®çš„ä¸šåŠ¡è¾¹ç•Œ

è¯·è¯†åˆ«ä¸»è¦çš„åŠŸèƒ½æ¨¡å—ã€‚"""),
            ("human", """éœ€æ±‚æè¿°ï¼š
{text}

è¯·è¯†åˆ«åŠŸèƒ½æ¨¡å—ï¼Œæ¯ä¸ªæ¨¡å—åŒ…å«ï¼š
- æ¨¡å—åç§°
- æ¨¡å—æè¿°
- ä¸»è¦åŠŸèƒ½
- æ¶‰åŠç”¨æˆ·
- ç›¸å…³æ•°æ®

è¿”å›JSONæ ¼å¼çš„æ¨¡å—åˆ—è¡¨ã€‚""")
        ])
        
        response = await self.llm.ainvoke(prompt.format_messages(text=text))
        
        try:
            import json
            if "```json" in response.content:
                json_start = response.content.find("```json") + 7
                json_end = response.content.find("```", json_start)
                json_content = response.content[json_start:json_end].strip()
            else:
                json_content = response.content
            
            modules = json.loads(json_content)
            return modules if isinstance(modules, list) else []
            
        except Exception as e:
            logger.warning(f"è§£æåŠŸèƒ½æ¨¡å—å¤±è´¥: {str(e)}")
            return []
    
    async def _parse_entity_extraction(self, response_content: str) -> Dict[str, List[str]]:
        """è§£æå®ä½“æå–ç»“æœ"""
        
        try:
            import json
            if "```json" in response_content:
                json_start = response_content.find("```json") + 7
                json_end = response_content.find("```", json_start)
                json_content = response_content[json_start:json_end].strip()
            else:
                json_content = response_content
            
            entities = json.loads(json_content)
            
            # ç¡®ä¿è¿”å›æ ‡å‡†æ ¼å¼
            standard_entities = {
                "ç”¨æˆ·è§’è‰²": entities.get("ç”¨æˆ·è§’è‰²", []),
                "ä¸šåŠ¡å¯¹è±¡": entities.get("ä¸šåŠ¡å¯¹è±¡", []),
                "åŠŸèƒ½æ“ä½œ": entities.get("åŠŸèƒ½æ“ä½œ", []),
                "è¾“å…¥è¾“å‡º": entities.get("è¾“å…¥è¾“å‡º", []),
                "ä¸šåŠ¡è§„åˆ™": entities.get("ä¸šåŠ¡è§„åˆ™", [])
            }
            
            return standard_entities
            
        except Exception as e:
            logger.warning(f"è§£æå®ä½“æå–ç»“æœå¤±è´¥: {str(e)}")
            return {
                "ç”¨æˆ·è§’è‰²": [],
                "ä¸šåŠ¡å¯¹è±¡": [],
                "åŠŸèƒ½æ“ä½œ": [],
                "è¾“å…¥è¾“å‡º": [],
                "ä¸šåŠ¡è§„åˆ™": []
            }
    
    async def _parse_business_processes(self, response_content: str) -> List[ProcessDetails]:
        """è§£æä¸šåŠ¡æµç¨‹"""
        
        try:
            import json
            if "```json" in response_content:
                json_start = response_content.find("```json") + 7
                json_end = response_content.find("```", json_start)
                json_content = response_content[json_start:json_end].strip()
            else:
                json_content = response_content
            
            processes_data = json.loads(json_content)
            
            processes = []
            for i, process_data in enumerate(processes_data):
                if isinstance(process_data, dict):
                    process = ProcessDetails(
                        id=f"process_{i+1}",
                        name=process_data.get("æµç¨‹åç§°", f"æµç¨‹{i+1}"),
                        description=process_data.get("æµç¨‹æè¿°", ""),
                        data_groups=process_data.get("æ¶‰åŠçš„æ•°æ®ç»„", []),
                        dependencies=process_data.get("ä¾èµ–å…³ç³»", [])
                    )
                    processes.append(process)
            
            return processes
            
        except Exception as e:
            logger.warning(f"è§£æä¸šåŠ¡æµç¨‹å¤±è´¥: {str(e)}")
            return []
    
    def _calculate_parsing_confidence(
        self, 
        functional_modules: List[Dict[str, Any]], 
        business_entities: Dict[str, List[str]], 
        business_processes: List[ProcessDetails]
    ) -> float:
        """è®¡ç®—è§£æç½®ä¿¡åº¦"""
        
        confidence_factors = []
        
        # åŠŸèƒ½æ¨¡å—æ•°é‡åˆç†æ€§
        module_count = len(functional_modules)
        if 1 <= module_count <= 10:
            confidence_factors.append(0.9)
        elif module_count == 0:
            confidence_factors.append(0.3)
        else:
            confidence_factors.append(0.7)
        
        # å®ä½“æå–å®Œæ•´æ€§
        entity_count = sum(len(entities) for entities in business_entities.values())
        if entity_count >= 5:
            confidence_factors.append(0.9)
        elif entity_count >= 2:
            confidence_factors.append(0.7)
        else:
            confidence_factors.append(0.5)
        
        # ä¸šåŠ¡æµç¨‹è¯†åˆ«
        process_count = len(business_processes)
        if process_count >= 1:
            confidence_factors.append(0.8)
        else:
            confidence_factors.append(0.4)
        
        return sum(confidence_factors) / len(confidence_factors) if confidence_factors else 0.5
    
    def _check_completeness(
        self, 
        parsed_requirements: Dict[str, Any], 
        original_text: str
    ) -> List[str]:
        """æ£€æŸ¥è§£æå®Œæ•´æ€§"""
        
        issues = []
        
        # æ£€æŸ¥å…³é”®å…ƒç´ æ˜¯å¦å­˜åœ¨
        if not parsed_requirements.get("functional_modules"):
            issues.append("æœªè¯†åˆ«åˆ°åŠŸèƒ½æ¨¡å—")
        
        if not parsed_requirements.get("business_entities", {}).get("ç”¨æˆ·è§’è‰²"):
            issues.append("æœªè¯†åˆ«åˆ°ç”¨æˆ·è§’è‰²")
        
        if not parsed_requirements.get("business_processes"):
            issues.append("æœªè¯†åˆ«åˆ°ä¸šåŠ¡æµç¨‹")
        
        # æ£€æŸ¥æ–‡æœ¬è¦†ç›–åº¦ï¼ˆç®€åŒ–å®ç°ï¼‰
        text_length = len(original_text)
        if text_length > 500:
            # å¯¹äºé•¿æ–‡æœ¬ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç»“æ„åŒ–ä¿¡æ¯
            total_extracted = (
                len(parsed_requirements.get("functional_modules", [])) +
                sum(len(entities) for entities in parsed_requirements.get("business_entities", {}).values()) +
                len(parsed_requirements.get("business_processes", []))
            )
            if total_extracted < text_length // 100:  # å¯å‘å¼è§„åˆ™
                issues.append("è§£æä¿¡æ¯ç›¸å¯¹äºæ–‡æœ¬é•¿åº¦åå°‘")
        
        return issues
    
    def _check_accuracy(
        self, 
        parsed_requirements: Dict[str, Any], 
        original_text: str
    ) -> List[str]:
        """æ£€æŸ¥è§£æå‡†ç¡®æ€§"""
        
        issues = []
        original_lower = original_text.lower()
        
        # æ£€æŸ¥æå–çš„å®ä½“æ˜¯å¦åœ¨åŸæ–‡ä¸­å­˜åœ¨
        business_entities = parsed_requirements.get("business_entities", {})
        
        for category, entities in business_entities.items():
            for entity in entities:
                if len(entity) > 2 and entity.lower() not in original_lower:
                    issues.append(f"å®ä½“'{entity}'åœ¨åŸæ–‡ä¸­æœªæ‰¾åˆ°")
        
        # æ£€æŸ¥åŠŸèƒ½æ¨¡å—åç§°åˆç†æ€§
        functional_modules = parsed_requirements.get("functional_modules", [])
        for module in functional_modules:
            module_name = module.get("æ¨¡å—åç§°", "")
            if module_name and len(module_name) < 2:
                issues.append(f"åŠŸèƒ½æ¨¡å—åç§°è¿‡çŸ­: {module_name}")
        
        return issues
    
    def _check_consistency(self, parsed_requirements: Dict[str, Any]) -> List[str]:
        """æ£€æŸ¥è§£æä¸€è‡´æ€§"""
        
        issues = []
        
        # æ£€æŸ¥ä¸šåŠ¡æµç¨‹ä¸åŠŸèƒ½æ¨¡å—çš„ä¸€è‡´æ€§
        functional_modules = parsed_requirements.get("functional_modules", [])
        business_processes = parsed_requirements.get("business_processes", [])
        
        module_names = {module.get("æ¨¡å—åç§°", "") for module in functional_modules}
        process_names = {process.name for process in business_processes}
        
        # ç®€åŒ–çš„ä¸€è‡´æ€§æ£€æŸ¥
        if len(module_names) > 0 and len(process_names) > 0:
            # æ£€æŸ¥æ˜¯å¦æœ‰å®Œå…¨é‡å¤çš„åç§°
            duplicates = module_names.intersection(process_names)
            if duplicates:
                issues.append(f"æ¨¡å—å’Œæµç¨‹åç§°é‡å¤: {list(duplicates)}")
        
        # æ£€æŸ¥ä¸šåŠ¡å®ä½“çš„åˆç†æ€§
        business_entities = parsed_requirements.get("business_entities", {})
        user_roles = business_entities.get("ç”¨æˆ·è§’è‰²", [])
        business_objects = business_entities.get("ä¸šåŠ¡å¯¹è±¡", [])
        
        if len(user_roles) == 0 and len(business_objects) > 0:
            issues.append("è¯†åˆ«äº†ä¸šåŠ¡å¯¹è±¡ä½†ç¼ºå°‘ç”¨æˆ·è§’è‰²")
        
        return issues
    
    def _generate_improvement_suggestions(self, validation_result: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        
        suggestions = []
        
        if validation_result["completeness_score"] < 0.7:
            suggestions.append("å»ºè®®è¡¥å……ç¼ºå¤±çš„åŠŸèƒ½æ¨¡å—ã€ç”¨æˆ·è§’è‰²æˆ–ä¸šåŠ¡æµç¨‹ä¿¡æ¯")
        
        if validation_result["accuracy_score"] < 0.7:
            suggestions.append("å»ºè®®æ£€æŸ¥æå–çš„å®ä½“æ˜¯å¦ä¸åŸæ–‡ä¸€è‡´")
        
        if validation_result["consistency_score"] < 0.7:
            suggestions.append("å»ºè®®æ£€æŸ¥å„ç»„ä»¶ä¹‹é—´çš„é€»è¾‘ä¸€è‡´æ€§")
        
        if validation_result["overall_score"] > 0.8:
            suggestions.append("è§£æè´¨é‡è‰¯å¥½ï¼Œå¯ä»¥è¿›è¡Œä¸‹ä¸€æ­¥å¤„ç†")
        
        return suggestions
    
    def get_parsing_history(self) -> List[Dict[str, Any]]:
        """è·å–è§£æå†å²"""
        return self.parsing_history.copy()
    
    def get_parsing_statistics(self) -> Dict[str, Any]:
        """è·å–è§£æç»Ÿè®¡"""
        if not self.parsing_history:
            return {"total": 0}
        
        confidence_scores = [result["parsing_confidence"] for result in self.parsing_history]
        
        return {
            "total_parsed": len(self.parsing_history),
            "average_confidence": sum(confidence_scores) / len(confidence_scores),
            "min_confidence": min(confidence_scores),
            "max_confidence": max(confidence_scores),
            "recent_parsing": self.parsing_history[-5:]  # æœ€è¿‘5æ¬¡è§£æ
        }


# å·¥å‚å‡½æ•°
async def create_requirement_parser(llm: Optional[BaseLanguageModel] = None) -> RequirementParserAgent:
    """åˆ›å»ºéœ€æ±‚è§£ææ™ºèƒ½ä½“"""
    parser = RequirementParserAgent(llm=llm)
    await parser.initialize()
    return parser


if __name__ == "__main__":
    async def main():
        # æµ‹è¯•éœ€æ±‚è§£æå™¨
        parser = await create_requirement_parser()
        
        # æµ‹è¯•éœ€æ±‚æ–‡æœ¬
        test_requirement = """
        ç”µå•†å¹³å°ç”¨æˆ·ç®¡ç†ç³»ç»Ÿéœ€è¦æ”¯æŒä»¥ä¸‹åŠŸèƒ½ï¼š
        1. ç”¨æˆ·æ³¨å†Œï¼šæ–°ç”¨æˆ·å¯ä»¥é€šè¿‡æ‰‹æœºå·æˆ–é‚®ç®±æ³¨å†Œè´¦å·ï¼Œéœ€è¦éªŒè¯èº«ä»½
        2. ç”¨æˆ·ç™»å½•ï¼šæ”¯æŒå¤šç§ç™»å½•æ–¹å¼ï¼ŒåŒ…æ‹¬å¯†ç ã€çŸ­ä¿¡éªŒè¯ç ã€ç¬¬ä¸‰æ–¹ç™»å½•
        3. ä¸ªäººä¿¡æ¯ç®¡ç†ï¼šç”¨æˆ·å¯ä»¥æŸ¥çœ‹å’Œä¿®æ”¹ä¸ªäººåŸºæœ¬ä¿¡æ¯ï¼ŒåŒ…æ‹¬å¤´åƒã€æ˜µç§°ã€è”ç³»æ–¹å¼
        4. è®¢å•ç®¡ç†ï¼šç”¨æˆ·å¯ä»¥æŸ¥çœ‹å†å²è®¢å•ã€è®¢å•è¯¦æƒ…ï¼Œæ”¯æŒè®¢å•æœç´¢å’Œç­›é€‰
        5. åœ°å€ç®¡ç†ï¼šç”¨æˆ·å¯ä»¥æ·»åŠ ã€ç¼–è¾‘ã€åˆ é™¤æ”¶è´§åœ°å€ï¼Œè®¾ç½®é»˜è®¤åœ°å€
        6. ç³»ç»Ÿç®¡ç†å‘˜å¯ä»¥æŸ¥çœ‹ç”¨æˆ·ç»Ÿè®¡æŠ¥è¡¨ï¼ŒåŒ…æ‹¬æ³¨å†Œé‡ã€æ´»è·ƒåº¦ç­‰æŒ‡æ ‡
        """
        
        print("ğŸ“‹ éœ€æ±‚è§£ææµ‹è¯•:")
        parsing_result = await parser.execute(
            "parse_requirements",
            {"requirement_text": test_requirement}
        )
        
        print(f"\nåŠŸèƒ½æ¨¡å—æ•°é‡: {len(parsing_result['functional_modules'])}")
        print(f"ä¸šåŠ¡æµç¨‹æ•°é‡: {len(parsing_result['business_processes'])}")
        print(f"è§£æç½®ä¿¡åº¦: {parsing_result['parsing_confidence']:.2f}")
        
        print(f"\nè¯†åˆ«çš„ç”¨æˆ·è§’è‰²: {parsing_result['business_entities']['ç”¨æˆ·è§’è‰²']}")
        print(f"è¯†åˆ«çš„ä¸šåŠ¡å¯¹è±¡: {parsing_result['business_entities']['ä¸šåŠ¡å¯¹è±¡']}")
        
        # éªŒè¯è§£æç»“æœ
        validation = await parser.execute(
            "validate_parsed_requirements",
            {
                "parsed_requirements": parsing_result,
                "original_text": test_requirement
            }
        )
        
        print(f"\néªŒè¯ç»“æœ:")
        print(f"æ€»ä½“è¯„åˆ†: {validation['overall_score']:.2f}")
        print(f"é—®é¢˜: {validation['issues']}")
        print(f"å»ºè®®: {validation['suggestions']}")
    
    asyncio.run(main()) 