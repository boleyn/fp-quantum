"""
é‡å­æ™ºèƒ½åŒ–åŠŸèƒ½ç‚¹ä¼°ç®—ç³»ç»Ÿ - éœ€æ±‚è§£ææ™ºèƒ½ä½“

ä»è‡ªç„¶è¯­è¨€éœ€æ±‚æè¿°ä¸­æå–ç»“æ„åŒ–çš„åŠŸèƒ½ä¿¡æ¯
"""

import asyncio
from typing import Dict, Any, Optional, List
import logging
from datetime import datetime
import re

from langchain_core.language_models import BaseLanguageModel
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool
from pydantic import BaseModel, Field

from agents.base.base_agent import SpecializedAgent
from models.project_models import ProjectInfo, ProcessDetails
from models.common_models import ConfidenceLevel, BaseEntity

# ä¸šåŠ¡å®ä½“æ¨¡å‹
class BusinessEntity(BaseEntity):
    """ä¸šåŠ¡å®ä½“æ¨¡å‹"""
    name: str = Field(..., description="å®ä½“åç§°")
    entity_type: str = Field(..., description="å®ä½“ç±»å‹")
    description: str = Field(..., description="å®ä½“æè¿°")
    attributes: List[str] = Field(default_factory=list, description="å±æ€§åˆ—è¡¨")
from config.settings import get_settings
import logging

logger = logging.getLogger(__name__)

# ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹
class EntityExtractionResult(BaseModel):
    """å®ä½“æå–ç»“æœæ¨¡å‹"""
    entities: List[Dict[str, Any]] = Field(description="æå–çš„ä¸šåŠ¡å®ä½“åˆ—è¡¨")
    relationships: List[Dict[str, str]] = Field(description="å®ä½“å…³ç³»åˆ—è¡¨")

class ProcessExtractionResult(BaseModel):
    """æµç¨‹æå–ç»“æœæ¨¡å‹"""
    processes: List[Dict[str, Any]] = Field(description="è¯†åˆ«çš„ä¸šåŠ¡æµç¨‹åˆ—è¡¨")

class RequirementParserAgent(SpecializedAgent):
    """éœ€æ±‚è§£ææ™ºèƒ½ä½“"""
    
    def __init__(self, llm: Optional[BaseLanguageModel] = None):
        super().__init__(
            agent_id="requirement_parser",
            specialty="natural_language_processing",
            llm=llm
        )
        
        self.settings = get_settings()
        
        # è§£æå†å²å’Œæ¨¡å¼è¯†åˆ«
        self.parsing_history: List[Dict[str, Any]] = []
        self.common_patterns = self._load_common_patterns()
        
    def _load_common_patterns(self) -> Dict[str, List[str]]:
        """åŠ è½½å¸¸è§çš„éœ€æ±‚è¡¨è¾¾æ¨¡å¼"""
        return {
            "åŠŸèƒ½åŠ¨è¯": [
                "å¯ä»¥", "èƒ½å¤Ÿ", "å®ç°", "æä¾›", "æ”¯æŒ", "å…è®¸", "å¸®åŠ©",
                "ç®¡ç†", "ç»´æŠ¤", "å¤„ç†", "ç”Ÿæˆ", "åˆ›å»º", "æŸ¥è¯¢", "æ›´æ–°"
            ],
            "å®ä½“æ ‡è¯†": [
                "ç”¨æˆ·", "ç®¡ç†å‘˜", "ç³»ç»Ÿ", "æ•°æ®", "ä¿¡æ¯", "æŠ¥è¡¨", "æ–‡ä»¶",
                "è®¢å•", "äº§å“", "å®¢æˆ·", "å‘˜å·¥", "éƒ¨é—¨", "é¡¹ç›®"
            ],
            "æ“ä½œç±»å‹": [
                "å¢åŠ ", "åˆ é™¤", "ä¿®æ”¹", "æŸ¥è¯¢", "å¯¼å…¥", "å¯¼å‡º", "æ‰“å°",
                "å‘é€", "æ¥æ”¶", "å®¡æ ¸", "å®¡æ‰¹", "ç»Ÿè®¡", "åˆ†æ"
            ],
            "è¿æ¥è¯": [
                "é€šè¿‡", "åŸºäº", "æ ¹æ®", "æŒ‰ç…§", "åŒ…æ‹¬", "åŒ…å«", "æ¶‰åŠ",
                "å…³äº", "é’ˆå¯¹", "å¯¹äº", "ä»¥åŠ", "å’Œ", "æˆ–è€…"
            ]
        }
    
    def _get_capabilities(self) -> List[str]:
        """è·å–æ™ºèƒ½ä½“èƒ½åŠ›åˆ—è¡¨"""
        return [
            "è‡ªç„¶è¯­è¨€éœ€æ±‚è§£æ",
            "åŠŸèƒ½è¾¹ç•Œè¯†åˆ«",
            "å®ä½“å…³ç³»æå–",
            "ä¸šåŠ¡æµç¨‹æ¢³ç†",
            "éœ€æ±‚ç»“æ„åŒ–è½¬æ¢"
        ]
    
    async def _execute_task(self, task_name: str, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œéœ€æ±‚è§£æä»»åŠ¡"""
        if task_name == "parse_requirements":
            return await self.parse_requirements(inputs["requirement_text"])
        elif task_name == "extract_functional_entities":
            return await self.extract_functional_entities(inputs["requirement_text"])
        elif task_name == "identify_business_processes":
            return await self.identify_business_processes(inputs["requirement_text"])
        elif task_name == "validate_parsed_requirements":
            return await self.validate_parsed_requirements(
                inputs["parsed_requirements"],
                inputs["original_text"]
            )
        else:
            raise ValueError(f"æœªçŸ¥ä»»åŠ¡: {task_name}")
    
    async def parse_requirements(self, requirement_text: str) -> Dict[str, Any]:
        """è§£æéœ€æ±‚æ–‡æœ¬ï¼Œæå–ç»“æ„åŒ–ä¿¡æ¯"""
        
        # 1. é¢„å¤„ç†éœ€æ±‚æ–‡æœ¬
        processed_text = self._preprocess_text(requirement_text)
        
        # 2. è¯†åˆ«åŠŸèƒ½æ¨¡å—
        functional_modules = await self._identify_functional_modules(processed_text)
        
        # 3. æå–ä¸šåŠ¡å®ä½“
        business_entities = await self.extract_functional_entities(processed_text)
        
        # 4. è¯†åˆ«ä¸šåŠ¡æµç¨‹
        business_processes = await self.identify_business_processes(processed_text)
        
        # 5. æ„å»ºè§£æç»“æœ
        parsing_result = {
            "original_text": requirement_text,
            "processed_text": processed_text,
            "functional_modules": functional_modules,
            "business_entities": business_entities,
            "business_processes": business_processes,
            "parsing_confidence": self._calculate_parsing_confidence(
                functional_modules, business_entities, business_processes
            ),
            "parsing_timestamp": datetime.now()
        }
        
        # 6. è®°å½•è§£æå†å²
        self.parsing_history.append(parsing_result)
        
        return parsing_result
    
    async def extract_functional_entities(self, requirement_text: str) -> Dict[str, List[str]]:
        """æå–åŠŸèƒ½ç›¸å…³çš„å®ä½“"""
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯éœ€æ±‚åˆ†æä¸“å®¶ï¼Œéœ€è¦ä»éœ€æ±‚æè¿°ä¸­æå–å…³é”®çš„åŠŸèƒ½å®ä½“ã€‚

è¯·è¯†åˆ«ä»¥ä¸‹ç±»å‹çš„å®ä½“ï¼š
1. ç”¨æˆ·è§’è‰²ï¼šè°ä¼šä½¿ç”¨è¿™äº›åŠŸèƒ½
2. ä¸šåŠ¡å¯¹è±¡ï¼šç³»ç»Ÿå¤„ç†çš„ä¸»è¦æ•°æ®æˆ–ä¿¡æ¯
3. åŠŸèƒ½æ“ä½œï¼šç”¨æˆ·å¯ä»¥æ‰§è¡Œçš„æ“ä½œ
4. è¾“å…¥è¾“å‡ºï¼šæ•°æ®çš„æ¥æºå’Œå»å‘
5. ä¸šåŠ¡è§„åˆ™ï¼šçº¦æŸæ¡ä»¶å’Œä¸šåŠ¡é€»è¾‘

è¯·è¿”å›JSONæ ¼å¼çš„ç»“æœã€‚"""),
            ("human", """éœ€æ±‚æè¿°ï¼š
{requirement_text}

è¯·æå–åŠŸèƒ½ç›¸å…³çš„å®ä½“ï¼Œå¹¶æŒ‰ç±»å‹åˆ†ç»„ã€‚

è¿”å›æ ¼å¼ï¼š
{{
  "ç”¨æˆ·è§’è‰²": ["è§’è‰²1", "è§’è‰²2"],
  "ä¸šåŠ¡å¯¹è±¡": ["å¯¹è±¡1", "å¯¹è±¡2"], 
  "åŠŸèƒ½æ“ä½œ": ["æ“ä½œ1", "æ“ä½œ2"],
  "è¾“å…¥è¾“å‡º": ["è¾“å…¥1", "è¾“å‡º1"],
  "ä¸šåŠ¡è§„åˆ™": ["è§„åˆ™1", "è§„åˆ™2"]
}}""")
        ])
        
        response = await self.llm.ainvoke(
            prompt.format_messages(requirement_text=requirement_text)
        )
        
        # è§£æå®ä½“æå–ç»“æœ
        return await self._parse_entity_extraction(response.content)
    
    async def identify_business_processes(self, requirement_text: str) -> List[ProcessDetails]:
        """è¯†åˆ«ä¸šåŠ¡æµç¨‹"""
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸šåŠ¡æµç¨‹åˆ†æä¸“å®¶ï¼Œéœ€è¦ä»éœ€æ±‚æè¿°ä¸­è¯†åˆ«ç‹¬ç«‹çš„ä¸šåŠ¡æµç¨‹ã€‚

ä¸€ä¸ªä¸šåŠ¡æµç¨‹åº”è¯¥å…·å¤‡ï¼š
1. æ˜ç¡®çš„å¼€å§‹å’Œç»“æŸæ¡ä»¶
2. æ¸…æ™°çš„å¤„ç†æ­¥éª¤
3. æ¶‰åŠçš„æ•°æ®æˆ–å®ä½“
4. äº§ç”Ÿçš„è¾“å‡ºæˆ–ç»“æœ

è¯·è¯†åˆ«æ¯ä¸ªç‹¬ç«‹çš„ä¸šåŠ¡æµç¨‹ï¼Œå¹¶æè¿°å…¶ç‰¹å¾ã€‚"""),
            ("human", """éœ€æ±‚æè¿°ï¼š
{requirement_text}

è¯·è¯†åˆ«å…¶ä¸­çš„ä¸šåŠ¡æµç¨‹ï¼Œæ¯ä¸ªæµç¨‹åŒ…å«ï¼š
- æµç¨‹åç§°
- æµç¨‹æè¿°
- æ¶‰åŠçš„æ•°æ®ç»„
- ä¸»è¦æ­¥éª¤
- è¾“å…¥è¾“å‡º

è¿”å›JSONæ ¼å¼çš„æµç¨‹åˆ—è¡¨ã€‚""")
        ])
        
        response = await self.llm.ainvoke(
            prompt.format_messages(requirement_text=requirement_text)
        )
        
        # è§£æä¸šåŠ¡æµç¨‹
        return await self._parse_business_processes(response.content)
    
    async def validate_parsed_requirements(
        self, 
        parsed_requirements: Dict[str, Any], 
        original_text: str
    ) -> Dict[str, Any]:
        """éªŒè¯è§£æç»“æœçš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§"""
        
        validation_result = {
            "completeness_score": 0.0,
            "accuracy_score": 0.0,
            "consistency_score": 0.0,
            "overall_score": 0.0,
            "issues": [],
            "suggestions": []
        }
        
        # 1. å®Œæ•´æ€§æ£€æŸ¥
        completeness_issues = self._check_completeness(parsed_requirements, original_text)
        validation_result["completeness_score"] = 1.0 - len(completeness_issues) * 0.2
        validation_result["issues"].extend(completeness_issues)
        
        # 2. å‡†ç¡®æ€§æ£€æŸ¥
        accuracy_issues = self._check_accuracy(parsed_requirements, original_text)
        validation_result["accuracy_score"] = 1.0 - len(accuracy_issues) * 0.15
        validation_result["issues"].extend(accuracy_issues)
        
        # 3. ä¸€è‡´æ€§æ£€æŸ¥
        consistency_issues = self._check_consistency(parsed_requirements)
        validation_result["consistency_score"] = 1.0 - len(consistency_issues) * 0.1
        validation_result["issues"].extend(consistency_issues)
        
        # 4. è®¡ç®—æ€»ä½“è¯„åˆ†
        validation_result["overall_score"] = (
            validation_result["completeness_score"] * 0.4 +
            validation_result["accuracy_score"] * 0.4 +
            validation_result["consistency_score"] * 0.2
        )
        
        # 5. ç”Ÿæˆæ”¹è¿›å»ºè®®
        validation_result["suggestions"] = self._generate_improvement_suggestions(
            validation_result
        )
        
        return validation_result
    
    def _preprocess_text(self, text: str) -> str:
        """é¢„å¤„ç†éœ€æ±‚æ–‡æœ¬"""
        
        # å»é™¤å¤šä½™ç©ºç™½
        processed = re.sub(r'\s+', ' ', text.strip())
        
        # æ ‡å‡†åŒ–æ ‡ç‚¹ç¬¦å·
        processed = re.sub(r'[ï¼Œã€‚ï¼›ï¼šï¼ï¼Ÿ]', 'ã€‚', processed)
        
        # åˆ†å¥å¤„ç†
        sentences = processed.split('ã€‚')
        cleaned_sentences = [s.strip() for s in sentences if s.strip()]
        
        return 'ã€‚'.join(cleaned_sentences)
    
    async def _identify_functional_modules(self, text: str) -> List[Dict[str, Any]]:
        """è¯†åˆ«åŠŸèƒ½æ¨¡å—"""
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ç³»ç»Ÿæ¶æ„å¸ˆï¼Œéœ€è¦ä»éœ€æ±‚æè¿°ä¸­è¯†åˆ«åŠŸèƒ½æ¨¡å—ã€‚

åŠŸèƒ½æ¨¡å—æ˜¯ç›¸å¯¹ç‹¬ç«‹çš„åŠŸèƒ½é›†åˆï¼Œé€šå¸¸åŒ…å«ï¼š
- ç›¸å…³çš„ä¸šåŠ¡åŠŸèƒ½
- å…±åŒçš„æ•°æ®å¤„ç†
- ç‰¹å®šçš„ç”¨æˆ·ç¾¤ä½“
- æ˜ç¡®çš„ä¸šåŠ¡è¾¹ç•Œ

è¯·è¯†åˆ«ä¸»è¦çš„åŠŸèƒ½æ¨¡å—ã€‚"""),
            ("human", """éœ€æ±‚æè¿°ï¼š
{text}

è¯·è¯†åˆ«åŠŸèƒ½æ¨¡å—ï¼Œæ¯ä¸ªæ¨¡å—åŒ…å«ï¼š
- æ¨¡å—åç§°
- æ¨¡å—æè¿°
- ä¸»è¦åŠŸèƒ½
- æ¶‰åŠç”¨æˆ·
- ç›¸å…³æ•°æ®

è¿”å›JSONæ ¼å¼çš„æ¨¡å—åˆ—è¡¨ã€‚""")
        ])
        
        response = await self.llm.ainvoke(prompt.format_messages(text=text))
        
        try:
            import json
            if "```json" in response.content:
                json_start = response.content.find("```json") + 7
                json_end = response.content.find("```", json_start)
                json_content = response.content[json_start:json_end].strip()
            else:
                json_content = response.content
            
            modules = json.loads(json_content)
            return modules if isinstance(modules, list) else []
            
        except Exception as e:
            logger.warning(f"è§£æåŠŸèƒ½æ¨¡å—å¤±è´¥: {str(e)}")
            return []
    
    async def _parse_entity_extraction(self, response_content: str) -> Dict[str, List[str]]:
        """è§£æå®ä½“æå–ç»“æœ"""
        
        try:
            import json
            if "```json" in response_content:
                json_start = response_content.find("```json") + 7
                json_end = response_content.find("```", json_start)
                json_content = response_content[json_start:json_end].strip()
            else:
                json_content = response_content
            
            entities = json.loads(json_content)
            
            # ç¡®ä¿è¿”å›æ ‡å‡†æ ¼å¼
            standard_entities = {
                "ç”¨æˆ·è§’è‰²": entities.get("ç”¨æˆ·è§’è‰²", []),
                "ä¸šåŠ¡å¯¹è±¡": entities.get("ä¸šåŠ¡å¯¹è±¡", []),
                "åŠŸèƒ½æ“ä½œ": entities.get("åŠŸèƒ½æ“ä½œ", []),
                "è¾“å…¥è¾“å‡º": entities.get("è¾“å…¥è¾“å‡º", []),
                "ä¸šåŠ¡è§„åˆ™": entities.get("ä¸šåŠ¡è§„åˆ™", [])
            }
            
            return standard_entities
            
        except Exception as e:
            logger.warning(f"è§£æå®ä½“æå–ç»“æœå¤±è´¥: {str(e)}")
            return {
                "ç”¨æˆ·è§’è‰²": [],
                "ä¸šåŠ¡å¯¹è±¡": [],
                "åŠŸèƒ½æ“ä½œ": [],
                "è¾“å…¥è¾“å‡º": [],
                "ä¸šåŠ¡è§„åˆ™": []
            }
    
    async def _parse_business_processes(self, response_content: str) -> List[ProcessDetails]:
        """è§£æä¸šåŠ¡æµç¨‹"""
        
        try:
            import json
            if "```json" in response_content:
                json_start = response_content.find("```json") + 7
                json_end = response_content.find("```", json_start)
                json_content = response_content[json_start:json_end].strip()
            else:
                json_content = response_content
            
            processes_data = json.loads(json_content)
            
            processes = []
            for i, process_data in enumerate(processes_data):
                if isinstance(process_data, dict):
                    process = ProcessDetails(
                        id=f"process_{i+1}",
                        name=process_data.get("æµç¨‹åç§°", f"æµç¨‹{i+1}"),
                        description=process_data.get("æµç¨‹æè¿°", ""),
                        data_groups=process_data.get("æ¶‰åŠçš„æ•°æ®ç»„", []),
                        dependencies=process_data.get("ä¾èµ–å…³ç³»", []),
                        inputs=process_data.get("inputs", []),
                        outputs=process_data.get("outputs", []),
                        business_rules=process_data.get("business_rules", []),
                        complexity_indicators=process_data.get("complexity_indicators", {}),
                        metadata=process_data
                    )
                    processes.append(process)
            
            return processes
            
        except Exception as e:
            logger.warning(f"è§£æä¸šåŠ¡æµç¨‹å¤±è´¥: {str(e)}")
            return []
    
    def _calculate_parsing_confidence(
        self, 
        functional_modules: List[Dict[str, Any]], 
        business_entities: Dict[str, List[str]], 
        business_processes: List[ProcessDetails]
    ) -> float:
        """è®¡ç®—è§£æç½®ä¿¡åº¦"""
        
        confidence_factors = []
        
        # åŠŸèƒ½æ¨¡å—æ•°é‡åˆç†æ€§
        module_count = len(functional_modules)
        if 1 <= module_count <= 10:
            confidence_factors.append(0.9)
        elif module_count == 0:
            confidence_factors.append(0.3)
        else:
            confidence_factors.append(0.7)
        
        # ğŸ”¥ ä¿®å¤å®ä½“æå–å®Œæ•´æ€§è®¡ç®— - å¢åŠ ç±»å‹æ£€æŸ¥
        try:
            if isinstance(business_entities, dict):
                entity_count = sum(len(entities) for entities in business_entities.values())
            elif isinstance(business_entities, list):
                # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œè®¡ç®—åˆ—è¡¨é•¿åº¦
                entity_count = len(business_entities)
            else:
                # å…¶ä»–æƒ…å†µï¼Œè®¾ä¸º0
                entity_count = 0
            
            if entity_count >= 5:
                confidence_factors.append(0.9)
            elif entity_count >= 2:
                confidence_factors.append(0.7)
            else:
                confidence_factors.append(0.5)
        except Exception as e:
            logger.warning(f"è®¡ç®—å®ä½“æ•°é‡æ—¶å‡ºé”™: {e}, business_entitiesç±»å‹: {type(business_entities)}")
            confidence_factors.append(0.5)  # é»˜è®¤å€¼
        
        # ä¸šåŠ¡æµç¨‹è¯†åˆ«
        try:
            if isinstance(business_processes, list):
                process_count = len(business_processes)
            else:
                process_count = 0
            
            if process_count >= 1:
                confidence_factors.append(0.8)
            else:
                confidence_factors.append(0.4)
        except Exception as e:
            logger.warning(f"è®¡ç®—æµç¨‹æ•°é‡æ—¶å‡ºé”™: {e}, business_processesç±»å‹: {type(business_processes)}")
            confidence_factors.append(0.4)  # é»˜è®¤å€¼
        
        return sum(confidence_factors) / len(confidence_factors) if confidence_factors else 0.5
    
    def _check_completeness(
        self, 
        parsed_requirements: Dict[str, Any], 
        original_text: str
    ) -> List[str]:
        """æ£€æŸ¥è§£æå®Œæ•´æ€§"""
        
        issues = []
        
        # æ£€æŸ¥å…³é”®å…ƒç´ æ˜¯å¦å­˜åœ¨
        if not parsed_requirements.get("functional_modules"):
            issues.append("æœªè¯†åˆ«åˆ°åŠŸèƒ½æ¨¡å—")
        
        if not parsed_requirements.get("business_entities", {}).get("ç”¨æˆ·è§’è‰²"):
            issues.append("æœªè¯†åˆ«åˆ°ç”¨æˆ·è§’è‰²")
        
        if not parsed_requirements.get("business_processes"):
            issues.append("æœªè¯†åˆ«åˆ°ä¸šåŠ¡æµç¨‹")
        
        # æ£€æŸ¥æ–‡æœ¬è¦†ç›–åº¦ï¼ˆç®€åŒ–å®ç°ï¼‰
        text_length = len(original_text)
        if text_length > 500:
            # å¯¹äºé•¿æ–‡æœ¬ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç»“æ„åŒ–ä¿¡æ¯
            total_extracted = (
                len(parsed_requirements.get("functional_modules", [])) +
                sum(len(entities) for entities in parsed_requirements.get("business_entities", {}).values()) +
                len(parsed_requirements.get("business_processes", []))
            )
            if total_extracted < text_length // 100:  # å¯å‘å¼è§„åˆ™
                issues.append("è§£æä¿¡æ¯ç›¸å¯¹äºæ–‡æœ¬é•¿åº¦åå°‘")
        
        return issues
    
    def _check_accuracy(
        self, 
        parsed_requirements: Dict[str, Any], 
        original_text: str
    ) -> List[str]:
        """æ£€æŸ¥è§£æå‡†ç¡®æ€§"""
        
        issues = []
        original_lower = original_text.lower()
        
        # æ£€æŸ¥æå–çš„å®ä½“æ˜¯å¦åœ¨åŸæ–‡ä¸­å­˜åœ¨
        business_entities = parsed_requirements.get("business_entities", {})
        
        for category, entities in business_entities.items():
            for entity in entities:
                if len(entity) > 2 and entity.lower() not in original_lower:
                    issues.append(f"å®ä½“'{entity}'åœ¨åŸæ–‡ä¸­æœªæ‰¾åˆ°")
        
        # æ£€æŸ¥åŠŸèƒ½æ¨¡å—åç§°åˆç†æ€§
        functional_modules = parsed_requirements.get("functional_modules", [])
        for module in functional_modules:
            module_name = module.get("æ¨¡å—åç§°", "")
            if module_name and len(module_name) < 2:
                issues.append(f"åŠŸèƒ½æ¨¡å—åç§°è¿‡çŸ­: {module_name}")
        
        return issues
    
    def _check_consistency(self, parsed_requirements: Dict[str, Any]) -> List[str]:
        """æ£€æŸ¥è§£æä¸€è‡´æ€§"""
        
        issues = []
        
        # æ£€æŸ¥ä¸šåŠ¡æµç¨‹ä¸åŠŸèƒ½æ¨¡å—çš„ä¸€è‡´æ€§
        functional_modules = parsed_requirements.get("functional_modules", [])
        business_processes = parsed_requirements.get("business_processes", [])
        
        module_names = {module.get("æ¨¡å—åç§°", "") for module in functional_modules}
        process_names = {process.name for process in business_processes}
        
        # ç®€åŒ–çš„ä¸€è‡´æ€§æ£€æŸ¥
        if len(module_names) > 0 and len(process_names) > 0:
            # æ£€æŸ¥æ˜¯å¦æœ‰å®Œå…¨é‡å¤çš„åç§°
            duplicates = module_names.intersection(process_names)
            if duplicates:
                issues.append(f"æ¨¡å—å’Œæµç¨‹åç§°é‡å¤: {list(duplicates)}")
        
        # æ£€æŸ¥ä¸šåŠ¡å®ä½“çš„åˆç†æ€§
        business_entities = parsed_requirements.get("business_entities", {})
        user_roles = business_entities.get("ç”¨æˆ·è§’è‰²", [])
        business_objects = business_entities.get("ä¸šåŠ¡å¯¹è±¡", [])
        
        if len(user_roles) == 0 and len(business_objects) > 0:
            issues.append("è¯†åˆ«äº†ä¸šåŠ¡å¯¹è±¡ä½†ç¼ºå°‘ç”¨æˆ·è§’è‰²")
        
        return issues
    
    def _generate_improvement_suggestions(self, validation_result: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        
        suggestions = []
        
        if validation_result["completeness_score"] < 0.7:
            suggestions.append("å»ºè®®è¡¥å……ç¼ºå¤±çš„åŠŸèƒ½æ¨¡å—ã€ç”¨æˆ·è§’è‰²æˆ–ä¸šåŠ¡æµç¨‹ä¿¡æ¯")
        
        if validation_result["accuracy_score"] < 0.7:
            suggestions.append("å»ºè®®æ£€æŸ¥æå–çš„å®ä½“æ˜¯å¦ä¸åŸæ–‡ä¸€è‡´")
        
        if validation_result["consistency_score"] < 0.7:
            suggestions.append("å»ºè®®æ£€æŸ¥å„ç»„ä»¶ä¹‹é—´çš„é€»è¾‘ä¸€è‡´æ€§")
        
        if validation_result["overall_score"] > 0.8:
            suggestions.append("è§£æè´¨é‡è‰¯å¥½ï¼Œå¯ä»¥è¿›è¡Œä¸‹ä¸€æ­¥å¤„ç†")
        
        return suggestions
    
    def get_parsing_history(self) -> List[Dict[str, Any]]:
        """è·å–è§£æå†å²"""
        return self.parsing_history.copy()
    
    def get_parsing_statistics(self) -> Dict[str, Any]:
        """è·å–è§£æç»Ÿè®¡"""
        if not self.parsing_history:
            return {"total": 0}
        
        confidence_scores = [result["parsing_confidence"] for result in self.parsing_history]
        
        return {
            "total_parsed": len(self.parsing_history),
            "average_confidence": sum(confidence_scores) / len(confidence_scores),
            "min_confidence": min(confidence_scores),
            "max_confidence": max(confidence_scores),
            "recent_parsing": self.parsing_history[-5:]  # æœ€è¿‘5æ¬¡è§£æ
        }

    async def extract_business_entities(
        self,
        requirement_text: str,
        context: Optional[Dict[str, Any]] = None
    ) -> List[BusinessEntity]:
        """ä»éœ€æ±‚æ–‡æœ¬ä¸­æå–ä¸šåŠ¡å®ä½“"""
        
        # å®šä¹‰å®ä½“æå–å·¥å…·
        @tool
        def extract_entities(
            entities: List[Dict[str, Any]],
            relationships: List[Dict[str, str]]
        ) -> dict:
            """æå–ä¸šåŠ¡å®ä½“å’Œå…³ç³»
            
            Args:
                entities: ä¸šåŠ¡å®ä½“åˆ—è¡¨ï¼Œæ¯ä¸ªå®ä½“åŒ…å«name, type, description, attributes
                relationships: å®ä½“å…³ç³»åˆ—è¡¨ï¼Œæ¯ä¸ªå…³ç³»åŒ…å«source, target, type
            """
            return {
                "entities": entities,
                "relationships": relationships
            }
        
        # åˆ›å»ºå¸¦å·¥å…·çš„LLM
        llm_with_tools = self.llm.bind_tools([extract_entities])
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸šåŠ¡éœ€æ±‚åˆ†æä¸“å®¶ï¼Œä¸“é—¨ä»éœ€æ±‚æ–‡æ¡£ä¸­æå–ä¸šåŠ¡å®ä½“ã€‚

ä¸šåŠ¡å®ä½“ç±»å‹åŒ…æ‹¬ï¼š
- æ•°æ®å®ä½“ï¼šå®¢æˆ·ã€è®¢å•ã€äº§å“ç­‰
- ä¸šåŠ¡å¯¹è±¡ï¼šåˆåŒã€å‘ç¥¨ã€æŠ¥å‘Šç­‰  
- ç”¨æˆ·è§’è‰²ï¼šç®¡ç†å‘˜ã€æ“ä½œå‘˜ã€å®¢æˆ·ç­‰
- ç³»ç»Ÿç»„ä»¶ï¼šæ¨¡å—ã€æ¥å£ã€æœåŠ¡ç­‰

è¯·ä½¿ç”¨extract_entitieså·¥å…·è¿”å›æå–ç»“æœã€‚"""),
            ("human", """éœ€æ±‚æ–‡æœ¬ï¼š
{requirement_text}

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š{context}

è¯·æå–å…¶ä¸­çš„ä¸šåŠ¡å®ä½“å’Œå…³ç³»ã€‚""")
        ])
        
        try:
            response = await llm_with_tools.ainvoke(
                prompt.format_messages(
                    requirement_text=requirement_text,
                    context=str(context) if context else "æ— "
                )
            )
            
            # è§£æå·¥å…·è°ƒç”¨ç»“æœ
            if response.tool_calls:
                tool_call = response.tool_calls[0]
                result_data = tool_call["args"]
                
                # è½¬æ¢ä¸ºBusinessEntityå¯¹è±¡
                entities = []
                for entity_data in result_data.get("entities", []):
                    entity = BusinessEntity(
                        name=entity_data.get("name", ""),
                        entity_type=entity_data.get("type", "unknown"),
                        description=entity_data.get("description", ""),
                        attributes=entity_data.get("attributes", [])
                    )
                    entities.append(entity)
                
                logger.info(f"âœ… æå–äº† {len(entities)} ä¸ªä¸šåŠ¡å®ä½“")
                return entities
            else:
                logger.warning("LLMæœªä½¿ç”¨å·¥å…·è°ƒç”¨ï¼Œè¿”å›ç©ºåˆ—è¡¨")
                return []
                
        except Exception as e:
            logger.error(f"âŒ ä¸šåŠ¡å®ä½“æå–å¤±è´¥: {str(e)}")
            return []

    async def identify_business_processes_with_tools(
        self,
        requirement_text: str,
        entities: Optional[List[BusinessEntity]] = None
    ) -> List[ProcessDetails]:
        """ä½¿ç”¨å·¥å…·è°ƒç”¨æ–¹å¼è¯†åˆ«ä¸šåŠ¡æµç¨‹"""
        
        # å®šä¹‰æµç¨‹è¯†åˆ«å·¥å…·
        @tool
        def identify_processes(
            processes: List[Dict[str, Any]]
        ) -> dict:
            """è¯†åˆ«ä¸šåŠ¡æµç¨‹
            
            Args:
                processes: ä¸šåŠ¡æµç¨‹åˆ—è¡¨ï¼Œæ¯ä¸ªæµç¨‹åŒ…å«name, description, data_groups, steps, inputs, outputs
            """
            return {"processes": processes}
        
        # åˆ›å»ºå¸¦å·¥å…·çš„LLM
        llm_with_tools = self.llm.bind_tools([identify_processes])
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸šåŠ¡åˆ†æä¸“å®¶ï¼Œä¸“é—¨è¯†åˆ«å’Œåˆ†æä¸šåŠ¡æµç¨‹ã€‚

ä¸šåŠ¡æµç¨‹ç‰¹å¾ï¼š
- æœ‰æ˜ç¡®çš„è§¦å‘æ¡ä»¶å’Œç»“æŸæ¡ä»¶
- åŒ…å«ä¸€ç³»åˆ—è¿ç»­çš„ä¸šåŠ¡æ´»åŠ¨
- æ¶‰åŠç‰¹å®šçš„æ•°æ®è¾“å…¥å’Œè¾“å‡º
- äº§ç”Ÿæ˜ç¡®çš„ä¸šåŠ¡ä»·å€¼

è¯·è¯†åˆ«ç‹¬ç«‹çš„ä¸šåŠ¡æµç¨‹ã€‚"""),
            ("human", """éœ€æ±‚æ–‡æ¡£ï¼š
{requirement_text}

{entities_context}

è¯·ä½¿ç”¨identify_processeså·¥å…·æå–ä¸šåŠ¡æµç¨‹ä¿¡æ¯ã€‚""")
        ])
        
        entities_context = ""
        if entities:
            entities_context = f"å·²è¯†åˆ«çš„ä¸šåŠ¡å®ä½“ï¼š{[e.name for e in entities]}"
        
        response = await llm_with_tools.ainvoke(
            prompt.format_messages(
                requirement_text=requirement_text,
                entities_context=entities_context
            )
        )
        
        # å¤„ç†å·¥å…·è°ƒç”¨å“åº”
        if hasattr(response, 'tool_calls') and response.tool_calls:
            processes_data = response.tool_calls[0]['args']['processes']
            return [
                ProcessDetails(
                    id=f"process_{i+1:03d}",
                    name=p.get('name', f'ä¸šåŠ¡æµç¨‹{i+1}'),
                    description=p.get('description', ''),
                    data_groups=p.get('data_groups', []),
                    dependencies=p.get('dependencies', []),
                    inputs=p.get('inputs', []),
                    outputs=p.get('outputs', []),
                    business_rules=p.get('business_rules', []),
                    complexity_indicators=p.get('complexity_indicators', {}),
                    metadata={
                        'steps': p.get('steps', []),
                        'inputs': p.get('inputs', []),
                        'outputs': p.get('outputs', []),
                        'source': 'tool_extraction'
                    }
                )
                for i, p in enumerate(processes_data)
            ]
        else:
            # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œå°è¯•è§£ææ–‡æœ¬å“åº”
            return await self._parse_business_processes(response.content)


# å·¥å‚å‡½æ•°
async def create_requirement_parser(llm: Optional[BaseLanguageModel] = None) -> RequirementParserAgent:
    """åˆ›å»ºéœ€æ±‚è§£ææ™ºèƒ½ä½“"""
    parser = RequirementParserAgent(llm=llm)
    await parser.initialize()
    return parser


if __name__ == "__main__":
    async def main():
        # æµ‹è¯•éœ€æ±‚è§£æå™¨
        parser = await create_requirement_parser()
        
        # æµ‹è¯•éœ€æ±‚æ–‡æœ¬
        test_requirement = """
        ç”µå•†å¹³å°ç”¨æˆ·ç®¡ç†ç³»ç»Ÿéœ€è¦æ”¯æŒä»¥ä¸‹åŠŸèƒ½ï¼š
        1. ç”¨æˆ·æ³¨å†Œï¼šæ–°ç”¨æˆ·å¯ä»¥é€šè¿‡æ‰‹æœºå·æˆ–é‚®ç®±æ³¨å†Œè´¦å·ï¼Œéœ€è¦éªŒè¯èº«ä»½
        2. ç”¨æˆ·ç™»å½•ï¼šæ”¯æŒå¤šç§ç™»å½•æ–¹å¼ï¼ŒåŒ…æ‹¬å¯†ç ã€çŸ­ä¿¡éªŒè¯ç ã€ç¬¬ä¸‰æ–¹ç™»å½•
        3. ä¸ªäººä¿¡æ¯ç®¡ç†ï¼šç”¨æˆ·å¯ä»¥æŸ¥çœ‹å’Œä¿®æ”¹ä¸ªäººåŸºæœ¬ä¿¡æ¯ï¼ŒåŒ…æ‹¬å¤´åƒã€æ˜µç§°ã€è”ç³»æ–¹å¼
        4. è®¢å•ç®¡ç†ï¼šç”¨æˆ·å¯ä»¥æŸ¥çœ‹å†å²è®¢å•ã€è®¢å•è¯¦æƒ…ï¼Œæ”¯æŒè®¢å•æœç´¢å’Œç­›é€‰
        5. åœ°å€ç®¡ç†ï¼šç”¨æˆ·å¯ä»¥æ·»åŠ ã€ç¼–è¾‘ã€åˆ é™¤æ”¶è´§åœ°å€ï¼Œè®¾ç½®é»˜è®¤åœ°å€
        6. ç³»ç»Ÿç®¡ç†å‘˜å¯ä»¥æŸ¥çœ‹ç”¨æˆ·ç»Ÿè®¡æŠ¥è¡¨ï¼ŒåŒ…æ‹¬æ³¨å†Œé‡ã€æ´»è·ƒåº¦ç­‰æŒ‡æ ‡
        """
        
        print("ğŸ“‹ éœ€æ±‚è§£ææµ‹è¯•:")
        parsing_result = await parser.execute(
            "parse_requirements",
            {"requirement_text": test_requirement}
        )
        
        print(f"\nåŠŸèƒ½æ¨¡å—æ•°é‡: {len(parsing_result['functional_modules'])}")
        print(f"ä¸šåŠ¡æµç¨‹æ•°é‡: {len(parsing_result['business_processes'])}")
        print(f"è§£æç½®ä¿¡åº¦: {parsing_result['parsing_confidence']:.2f}")
        
        print(f"\nè¯†åˆ«çš„ç”¨æˆ·è§’è‰²: {parsing_result['business_entities']['ç”¨æˆ·è§’è‰²']}")
        print(f"è¯†åˆ«çš„ä¸šåŠ¡å¯¹è±¡: {parsing_result['business_entities']['ä¸šåŠ¡å¯¹è±¡']}")
        
        # éªŒè¯è§£æç»“æœ
        validation = await parser.execute(
            "validate_parsed_requirements",
            {
                "parsed_requirements": parsing_result,
                "original_text": test_requirement
            }
        )
        
        print(f"\néªŒè¯ç»“æœ:")
        print(f"æ€»ä½“è¯„åˆ†: {validation['overall_score']:.2f}")
        print(f"é—®é¢˜: {validation['issues']}")
        print(f"å»ºè®®: {validation['suggestions']}")
    
    asyncio.run(main()) 