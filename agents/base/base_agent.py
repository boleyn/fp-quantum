"""
é‡å­æ™ºèƒ½åŒ–åŠŸèƒ½ç‚¹ä¼°ç®—ç³»ç»Ÿ - åŸºç¡€æ™ºèƒ½ä½“ç±»

æä¾›æ‰€æœ‰æ™ºèƒ½ä½“çš„é€šç”¨åŠŸèƒ½å’Œæ¥å£å®šä¹‰
"""

import asyncio
import time
import uuid
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, List
import logging
from datetime import datetime

from langchain_core.language_models import BaseLanguageModel
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field

from config.settings import get_settings
from models.common_models import ProcessingStatus, ExecutionLog, ErrorInfo

logger = logging.getLogger(__name__)


class AgentConfig(BaseModel):
    """æ™ºèƒ½ä½“é…ç½®"""
    agent_id: str = Field(..., description="æ™ºèƒ½ä½“ID")
    name: str = Field(..., description="æ™ºèƒ½ä½“åç§°")
    description: str = Field(default="", description="æ™ºèƒ½ä½“æè¿°")
    max_retries: int = Field(default=3, description="æœ€å¤§é‡è¯•æ¬¡æ•°")
    timeout_seconds: int = Field(default=300, description="è¶…æ—¶æ—¶é—´(ç§’)")
    enable_logging: bool = Field(default=True, description="æ˜¯å¦å¯ç”¨æ—¥å¿—")
    enable_cache: bool = Field(default=True, description="æ˜¯å¦å¯ç”¨ç¼“å­˜")


class BaseAgent(ABC):
    """åŸºç¡€æ™ºèƒ½ä½“ç±»"""
    
    def __init__(
        self,
        agent_id: str,
        llm: Optional[BaseLanguageModel] = None,
        config: Optional[AgentConfig] = None
    ):
        self.agent_id = agent_id
        self.session_id = str(uuid.uuid4())
        self.settings = get_settings()
        
        # é…ç½®
        self.config = config or AgentConfig(
            agent_id=agent_id,
            name=agent_id.replace("_", " ").title()
        )
        
        # LLMé…ç½®
        if llm:
            self.llm = llm
        else:
            self.llm = self._create_default_llm()
        
        # æ‰§è¡ŒçŠ¶æ€
        self.status = ProcessingStatus.READY
        self.execution_logs: List[ExecutionLog] = []
        self.error_info: Optional[ErrorInfo] = None
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_executions = 0
        self.successful_executions = 0
        self.total_execution_time = 0.0
        
        # ç¼“å­˜
        self.cache: Dict[str, Any] = {} if self.config.enable_cache else None
        
        logger.info(f"ğŸ¤– æ™ºèƒ½ä½“ {self.agent_id} åˆå§‹åŒ–å®Œæˆ")
    
    def _create_default_llm(self) -> BaseLanguageModel:
        """åˆ›å»ºé»˜è®¤LLM"""
        return ChatOpenAI(
            model=self.settings.llm.worker_model,
            api_key=self.settings.llm.deepseek_api_key,
            base_url=self.settings.llm.deepseek_api_base,
            temperature=0.1,
            max_tokens=4000,
            timeout=self.config.timeout_seconds
        )
    
    async def initialize(self):
        """åˆå§‹åŒ–æ™ºèƒ½ä½“ï¼ˆå­ç±»å¯é‡å†™ï¼‰"""
        self.status = ProcessingStatus.READY
        self._log_execution("INITIALIZE", {"status": "completed"})
        logger.info(f"âœ… æ™ºèƒ½ä½“ {self.agent_id} åˆå§‹åŒ–å®Œæˆ")
    
    async def execute(
        self,
        task_name: str,
        inputs: Dict[str, Any],
        use_cache: bool = True
    ) -> Dict[str, Any]:
        """æ‰§è¡Œä»»åŠ¡çš„é€šç”¨åŒ…è£…å™¨"""
        start_time = time.time()
        self.total_executions += 1
        
        try:
            # æ£€æŸ¥ç¼“å­˜
            if use_cache and self.cache is not None:
                cache_key = self._generate_cache_key(task_name, inputs)
                if cache_key in self.cache:
                    logger.info(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜ç»“æœ: {task_name}")
                    self._log_execution(task_name, {"cache_hit": True})
                    return self.cache[cache_key]
            
            # è®¾ç½®çŠ¶æ€
            self.status = ProcessingStatus.PROCESSING
            
            # æ‰§è¡Œå…·ä½“ä»»åŠ¡
            result = await self._execute_task(task_name, inputs)
            
            # ç¼“å­˜ç»“æœ
            if use_cache and self.cache is not None and result:
                cache_key = self._generate_cache_key(task_name, inputs)
                self.cache[cache_key] = result
            
            # æ›´æ–°ç»Ÿè®¡
            execution_time = time.time() - start_time
            self.total_execution_time += execution_time
            self.successful_executions += 1
            self.status = ProcessingStatus.COMPLETED
            
            # è®°å½•æ‰§è¡Œæ—¥å¿—
            self._log_execution(task_name, {
                "status": "success",
                "execution_time": execution_time,
                "result_size": len(str(result))
            })
            
            return result
            
        except Exception as e:
            # é”™è¯¯å¤„ç†
            execution_time = time.time() - start_time
            self.total_execution_time += execution_time
            self.status = ProcessingStatus.ERROR
            
            error_info = ErrorInfo(
                error_type=type(e).__name__,
                error_message=str(e),
                occurred_at=datetime.now()
            )
            self.error_info = error_info
            
            self._log_execution(task_name, {
                "status": "error",
                "execution_time": execution_time,
                "error": str(e)
            })
            
            logger.error(f"âŒ æ™ºèƒ½ä½“ {self.agent_id} æ‰§è¡Œä»»åŠ¡ {task_name} å¤±è´¥: {str(e)}")
            raise
    
    @abstractmethod
    async def _execute_task(self, task_name: str, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå…·ä½“ä»»åŠ¡ï¼ˆå­ç±»å¿…é¡»å®ç°ï¼‰"""
        pass
    
    def _generate_cache_key(self, task_name: str, inputs: Dict[str, Any]) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        import hashlib
        input_str = str(sorted(inputs.items()))
        hash_obj = hashlib.md5(f"{task_name}_{input_str}".encode())
        return hash_obj.hexdigest()
    
    def _log_execution(self, step_name: str, details: Dict[str, Any]):
        """è®°å½•æ‰§è¡Œæ—¥å¿—"""
        if not self.config.enable_logging:
            return
        
        log_entry = ExecutionLog(
            step_name=step_name,
            agent_id=self.agent_id,
            session_id=self.session_id,
            timestamp=datetime.now(),
            details=details
        )
        
        self.execution_logs.append(log_entry)
        
        # é™åˆ¶æ—¥å¿—æ•°é‡
        if len(self.execution_logs) > 1000:
            self.execution_logs = self.execution_logs[-500:]
    
    async def retry_with_backoff(
        self,
        func,
        max_retries: Optional[int] = None,
        backoff_factor: float = 2.0,
        *args,
        **kwargs
    ):
        """å¸¦é€€é¿çš„é‡è¯•æœºåˆ¶"""
        max_retries = max_retries or self.config.max_retries
        
        for attempt in range(max_retries + 1):
            try:
                return await func(*args, **kwargs)
            except Exception as e:
                if attempt == max_retries:
                    logger.error(f"âŒ é‡è¯• {max_retries} æ¬¡åä»å¤±è´¥: {str(e)}")
                    raise
                
                wait_time = backoff_factor ** attempt
                logger.warning(f"âš ï¸ å°è¯• {attempt + 1} å¤±è´¥ï¼Œ{wait_time}ç§’åé‡è¯•: {str(e)}")
                await asyncio.sleep(wait_time)
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯"""
        success_rate = (
            self.successful_executions / self.total_executions 
            if self.total_executions > 0 else 0.0
        )
        
        avg_execution_time = (
            self.total_execution_time / self.total_executions 
            if self.total_executions > 0 else 0.0
        )
        
        return {
            "agent_id": self.agent_id,
            "session_id": self.session_id,
            "status": self.status.value,
            "total_executions": self.total_executions,
            "successful_executions": self.successful_executions,
            "success_rate": success_rate,
            "total_execution_time": self.total_execution_time,
            "average_execution_time": avg_execution_time,
            "cache_size": len(self.cache) if self.cache else 0,
            "log_entries": len(self.execution_logs),
            "last_error": self.error_info.model_dump() if self.error_info else None
        }
    
    def clear_cache(self):
        """æ¸…é™¤ç¼“å­˜"""
        if self.cache:
            self.cache.clear()
            logger.info(f"ğŸ—‘ï¸ {self.agent_id} ç¼“å­˜å·²æ¸…é™¤")
    
    def export_logs(self) -> List[Dict[str, Any]]:
        """å¯¼å‡ºæ‰§è¡Œæ—¥å¿—"""
        return [log.model_dump() for log in self.execution_logs]
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        try:
            # æµ‹è¯•LLMè¿æ¥
            test_response = await self.llm.ainvoke("æµ‹è¯•è¿æ¥")
            llm_healthy = bool(test_response.content)
        except Exception as e:
            llm_healthy = False
            logger.warning(f"âš ï¸ LLMå¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}")
        
        stats = self.get_statistics()
        
        return {
            "agent_id": self.agent_id,
            "status": self.status.value,
            "llm_healthy": llm_healthy,
            "cache_enabled": self.cache is not None,
            "uptime_seconds": sum(log.details.get("execution_time", 0) for log in self.execution_logs),
            "last_activity": (
                self.execution_logs[-1].timestamp.isoformat() 
                if self.execution_logs else None
            ),
            "performance": {
                "success_rate": stats["success_rate"],
                "average_execution_time": stats["average_execution_time"]
            }
        }
    
    def __repr__(self) -> str:
        return f"{self.__class__.__name__}(agent_id='{self.agent_id}', status='{self.status.value}')"


class SpecializedAgent(BaseAgent):
    """ä¸“ä¸šåŒ–æ™ºèƒ½ä½“åŸºç±»"""
    
    def __init__(
        self,
        agent_id: str,
        specialty: str,
        llm: Optional[BaseLanguageModel] = None,
        config: Optional[AgentConfig] = None
    ):
        super().__init__(agent_id, llm, config)
        self.specialty = specialty
        self.expertise_areas: List[str] = []
        self.knowledge_sources: List[str] = []
    
    def add_expertise_area(self, area: str):
        """æ·»åŠ ä¸“ä¸šé¢†åŸŸ"""
        if area not in self.expertise_areas:
            self.expertise_areas.append(area)
    
    def add_knowledge_source(self, source: str):
        """æ·»åŠ çŸ¥è¯†æº"""
        if source not in self.knowledge_sources:
            self.knowledge_sources.append(source)
    
    def get_expertise_info(self) -> Dict[str, Any]:
        """è·å–ä¸“ä¸šä¿¡æ¯"""
        return {
            "specialty": self.specialty,
            "expertise_areas": self.expertise_areas,
            "knowledge_sources": self.knowledge_sources,
            "capabilities": self._get_capabilities()
        }
    
    @abstractmethod
    def _get_capabilities(self) -> List[str]:
        """è·å–èƒ½åŠ›åˆ—è¡¨ï¼ˆå­ç±»å®ç°ï¼‰"""
        pass


if __name__ == "__main__":
    # æµ‹è¯•åŸºç¡€æ™ºèƒ½ä½“
    class TestAgent(BaseAgent):
        async def _execute_task(self, task_name: str, inputs: Dict[str, Any]) -> Dict[str, Any]:
            # æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œ
            await asyncio.sleep(0.1)
            return {"result": f"Processed {task_name} with {len(inputs)} inputs"}
        
        def _get_capabilities(self) -> List[str]:
            return ["æµ‹è¯•åŠŸèƒ½", "æ¼”ç¤ºåŠŸèƒ½"]
    
    async def main():
        # åˆ›å»ºæµ‹è¯•æ™ºèƒ½ä½“
        agent = TestAgent("test_agent")
        await agent.initialize()
        
        # æ‰§è¡Œæµ‹è¯•ä»»åŠ¡
        result = await agent.execute("test_task", {"input": "test_data"})
        print(f"æ‰§è¡Œç»“æœ: {result}")
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = agent.get_statistics()
        print(f"ç»Ÿè®¡ä¿¡æ¯: {stats}")
        
        # å¥åº·æ£€æŸ¥
        health = await agent.health_check()
        print(f"å¥åº·çŠ¶æ€: {health}")
    
    asyncio.run(main())