"""
é‡å­æ™ºèƒ½åŒ–åŠŸèƒ½ç‚¹ä¼°ç®—ç³»ç»Ÿ - æ€§èƒ½ä¼˜åŒ–å™¨

æä¾›ç¼“å­˜ã€æ‰¹å¤„ç†ã€å¹¶å‘ç­‰æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½
"""

import asyncio
import time
from typing import Dict, Any, List, Optional, Callable, TypeVar, Union
from functools import wraps
from concurrent.futures import ThreadPoolExecutor, as_completed
import hashlib
import json
import logging
from dataclasses import dataclass
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)

T = TypeVar('T')


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""
    operation_name: str
    start_time: datetime
    end_time: datetime
    duration_seconds: float
    cache_hit: bool = False
    batch_size: Optional[int] = None
    concurrent_tasks: Optional[int] = None
    memory_usage_mb: Optional[float] = None


class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, max_size: int = 1000, ttl_seconds: int = 3600):
        self.cache: Dict[str, Dict[str, Any]] = {}
        self.max_size = max_size
        self.ttl_seconds = ttl_seconds
        self.access_times: Dict[str, datetime] = {}
        
    def get_cache_key(self, func_name: str, args: tuple, kwargs: dict) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_data = {
            "function": func_name,
            "args": str(args),
            "kwargs": str(sorted(kwargs.items()))
        }
        return hashlib.md5(json.dumps(key_data).encode()).hexdigest()
    
    def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜"""
        if key not in self.cache:
            return None
            
        # æ£€æŸ¥TTL
        if self._is_expired(key):
            self.delete(key)
            return None
            
        # æ›´æ–°è®¿é—®æ—¶é—´
        self.access_times[key] = datetime.now()
        return self.cache[key]["value"]
    
    def set(self, key: str, value: Any) -> None:
        """è®¾ç½®ç¼“å­˜"""
        # å¦‚æœç¼“å­˜å·²æ»¡ï¼Œæ¸…ç†è¿‡æœŸå’Œæœ€å°‘ä½¿ç”¨çš„æ¡ç›®
        if len(self.cache) >= self.max_size:
            self._evict_cache()
            
        self.cache[key] = {
            "value": value,
            "created_at": datetime.now()
        }
        self.access_times[key] = datetime.now()
        
    def delete(self, key: str) -> None:
        """åˆ é™¤ç¼“å­˜"""
        if key in self.cache:
            del self.cache[key]
        if key in self.access_times:
            del self.access_times[key]
            
    def clear(self) -> None:
        """æ¸…ç©ºç¼“å­˜"""
        self.cache.clear()
        self.access_times.clear()
        
    def _is_expired(self, key: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿‡æœŸ"""
        if key not in self.cache:
            return True
            
        created_at = self.cache[key]["created_at"]
        return datetime.now() - created_at > timedelta(seconds=self.ttl_seconds)
    
    def _evict_cache(self) -> None:
        """æ¸…ç†ç¼“å­˜"""
        # é¦–å…ˆæ¸…ç†è¿‡æœŸçš„
        expired_keys = [key for key in self.cache.keys() if self._is_expired(key)]
        for key in expired_keys:
            self.delete(key)
            
        # å¦‚æœè¿˜æ˜¯å¤ªå¤šï¼Œæ¸…ç†æœ€å°‘ä½¿ç”¨çš„
        if len(self.cache) >= self.max_size:
            # æŒ‰è®¿é—®æ—¶é—´æ’åºï¼Œåˆ é™¤æœ€æ—§çš„
            sorted_keys = sorted(
                self.access_times.keys(),
                key=lambda k: self.access_times[k]
            )
            
            # åˆ é™¤æœ€æ—§çš„25%
            to_delete = sorted_keys[:max(1, len(sorted_keys) // 4)]
            for key in to_delete:
                self.delete(key)
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        return {
            "size": len(self.cache),
            "max_size": self.max_size,
            "hit_ratio": getattr(self, "_hit_count", 0) / max(getattr(self, "_access_count", 1), 1),
            "expired_entries": len([k for k in self.cache.keys() if self._is_expired(k)])
        }


class BatchProcessor:
    """æ‰¹å¤„ç†å™¨"""
    
    def __init__(self, batch_size: int = 10, max_wait_time: float = 1.0):
        self.batch_size = batch_size
        self.max_wait_time = max_wait_time
        self.pending_tasks: List[Dict[str, Any]] = []
        self.last_batch_time = time.time()
        
    async def add_task(
        self, 
        func: Callable, 
        args: tuple = (), 
        kwargs: dict = None
    ) -> Any:
        """æ·»åŠ ä»»åŠ¡åˆ°æ‰¹æ¬¡"""
        if kwargs is None:
            kwargs = {}
            
        task = {
            "func": func,
            "args": args,
            "kwargs": kwargs,
            "future": asyncio.Future()
        }
        
        self.pending_tasks.append(task)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰§è¡Œæ‰¹æ¬¡
        if (len(self.pending_tasks) >= self.batch_size or 
            time.time() - self.last_batch_time > self.max_wait_time):
            await self._execute_batch()
            
        return await task["future"]
    
    async def _execute_batch(self) -> None:
        """æ‰§è¡Œæ‰¹æ¬¡"""
        if not self.pending_tasks:
            return
            
        batch = self.pending_tasks.copy()
        self.pending_tasks.clear()
        self.last_batch_time = time.time()
        
        # æŒ‰å‡½æ•°åˆ†ç»„
        function_groups: Dict[str, List[Dict[str, Any]]] = {}
        for task in batch:
            func_name = task["func"].__name__
            if func_name not in function_groups:
                function_groups[func_name] = []
            function_groups[func_name].append(task)
        
        # å¹¶è¡Œæ‰§è¡Œæ¯ä¸ªå‡½æ•°ç»„
        for func_name, tasks in function_groups.items():
            asyncio.create_task(self._execute_function_batch(tasks))
    
    async def _execute_function_batch(self, tasks: List[Dict[str, Any]]) -> None:
        """æ‰§è¡ŒåŒä¸€å‡½æ•°çš„æ‰¹æ¬¡"""
        try:
            # å¦‚æœå‡½æ•°æ”¯æŒæ‰¹å¤„ç†ï¼Œå°è¯•æ‰¹é‡æ‰§è¡Œ
            first_task = tasks[0]
            func = first_task["func"]
            
            if hasattr(func, "_supports_batch"):
                # æ‰¹é‡æ‰§è¡Œ
                all_args = [task["args"] for task in tasks]
                all_kwargs = [task["kwargs"] for task in tasks]
                
                results = await func(all_args, all_kwargs)
                
                # åˆ†å‘ç»“æœ
                for task, result in zip(tasks, results):
                    if not task["future"].done():
                        task["future"].set_result(result)
            else:
                # å•ç‹¬æ‰§è¡Œ
                for task in tasks:
                    try:
                        if asyncio.iscoroutinefunction(task["func"]):
                            result = await task["func"](*task["args"], **task["kwargs"])
                        else:
                            result = task["func"](*task["args"], **task["kwargs"])
                        
                        if not task["future"].done():
                            task["future"].set_result(result)
                    except Exception as e:
                        if not task["future"].done():
                            task["future"].set_exception(e)
                            
        except Exception as e:
            # å¦‚æœæ‰¹å¤„ç†å¤±è´¥ï¼Œè®¾ç½®æ‰€æœ‰ä»»åŠ¡çš„å¼‚å¸¸
            for task in tasks:
                if not task["future"].done():
                    task["future"].set_exception(e)


class ConcurrencyManager:
    """å¹¶å‘ç®¡ç†å™¨"""
    
    def __init__(self, max_concurrent_tasks: int = 10):
        self.max_concurrent_tasks = max_concurrent_tasks
        self.semaphore = asyncio.Semaphore(max_concurrent_tasks)
        self.active_tasks: Dict[str, asyncio.Task] = {}
        
    async def execute_concurrent(
        self, 
        tasks: List[Callable], 
        task_args: List[tuple] = None,
        task_kwargs: List[dict] = None
    ) -> List[Any]:
        """å¹¶å‘æ‰§è¡Œä»»åŠ¡åˆ—è¡¨"""
        
        if task_args is None:
            task_args = [() for _ in tasks]
        if task_kwargs is None:
            task_kwargs = [{} for _ in tasks]
            
        async def limited_task(func, args, kwargs):
            async with self.semaphore:
                if asyncio.iscoroutinefunction(func):
                    return await func(*args, **kwargs)
                else:
                    return func(*args, **kwargs)
        
        # åˆ›å»ºä»»åŠ¡
        concurrent_tasks = [
            asyncio.create_task(limited_task(func, args, kwargs))
            for func, args, kwargs in zip(tasks, task_args, task_kwargs)
        ]
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*concurrent_tasks, return_exceptions=True)
        
        return results
    
    async def execute_with_timeout(
        self, 
        func: Callable, 
        timeout: float,
        *args, 
        **kwargs
    ) -> Any:
        """æ‰§è¡Œå¸¦è¶…æ—¶çš„ä»»åŠ¡"""
        
        async def task():
            async with self.semaphore:
                if asyncio.iscoroutinefunction(func):
                    return await func(*args, **kwargs)
                else:
                    return func(*args, **kwargs)
        
        try:
            return await asyncio.wait_for(task(), timeout=timeout)
        except asyncio.TimeoutError:
            logger.warning(f"ä»»åŠ¡ {func.__name__} æ‰§è¡Œè¶…æ—¶ ({timeout}ç§’)")
            raise


class PerformanceOptimizer:
    """æ€§èƒ½ä¼˜åŒ–å™¨"""
    
    def __init__(
        self,
        cache_size: int = 1000,
        cache_ttl: int = 3600,
        batch_size: int = 10,
        max_concurrent: int = 10
    ):
        self.cache_manager = CacheManager(cache_size, cache_ttl)
        self.batch_processor = BatchProcessor(batch_size)
        self.concurrency_manager = ConcurrencyManager(max_concurrent)
        self.metrics: List[PerformanceMetrics] = []
        
    def cached(self, ttl: Optional[int] = None):
        """ç¼“å­˜è£…é¥°å™¨"""
        def decorator(func):
            @wraps(func)
            async def wrapper(*args, **kwargs):
                # ç”Ÿæˆç¼“å­˜é”®
                cache_key = self.cache_manager.get_cache_key(
                    func.__name__, args, kwargs
                )
                
                # å°è¯•ä»ç¼“å­˜è·å–
                cached_result = self.cache_manager.get(cache_key)
                if cached_result is not None:
                    logger.debug(f"ç¼“å­˜å‘½ä¸­: {func.__name__}")
                    return cached_result
                
                # æ‰§è¡Œå‡½æ•°
                start_time = datetime.now()
                if asyncio.iscoroutinefunction(func):
                    result = await func(*args, **kwargs)
                else:
                    result = func(*args, **kwargs)
                
                # å­˜å‚¨åˆ°ç¼“å­˜
                self.cache_manager.set(cache_key, result)
                
                # è®°å½•æŒ‡æ ‡
                end_time = datetime.now()
                metrics = PerformanceMetrics(
                    operation_name=func.__name__,
                    start_time=start_time,
                    end_time=end_time,
                    duration_seconds=(end_time - start_time).total_seconds(),
                    cache_hit=False
                )
                self.metrics.append(metrics)
                
                return result
            
            return wrapper
        return decorator
    
    def batched(self, batch_size: Optional[int] = None):
        """æ‰¹å¤„ç†è£…é¥°å™¨"""
        def decorator(func):
            @wraps(func)
            async def wrapper(*args, **kwargs):
                processor = BatchProcessor(
                    batch_size or self.batch_processor.batch_size
                )
                return await processor.add_task(func, args, kwargs)
            
            return wrapper
        return decorator
    
    def timed(self, func):
        """è®¡æ—¶è£…é¥°å™¨"""
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = datetime.now()
            
            try:
                if asyncio.iscoroutinefunction(func):
                    result = await func(*args, **kwargs)
                else:
                    result = func(*args, **kwargs)
                
                return result
                
            finally:
                end_time = datetime.now()
                metrics = PerformanceMetrics(
                    operation_name=func.__name__,
                    start_time=start_time,
                    end_time=end_time,
                    duration_seconds=(end_time - start_time).total_seconds()
                )
                self.metrics.append(metrics)
                logger.info(
                    f"å‡½æ•° {func.__name__} æ‰§è¡Œæ—¶é—´: "
                    f"{metrics.duration_seconds:.3f}ç§’"
                )
        
        return wrapper
    
    async def optimize_large_dataset_processing(
        self,
        data: List[Any],
        processor_func: Callable,
        chunk_size: int = 100
    ) -> List[Any]:
        """ä¼˜åŒ–å¤§æ•°æ®é›†å¤„ç†"""
        
        if len(data) <= chunk_size:
            # å°æ•°æ®é›†ç›´æ¥å¤„ç†
            return await processor_func(data)
        
        # åˆ†å—å¤„ç†
        chunks = [
            data[i:i + chunk_size] 
            for i in range(0, len(data), chunk_size)
        ]
        
        # å¹¶å‘å¤„ç†å—
        tasks = [processor_func(chunk) for chunk in chunks]
        chunk_results = await self.concurrency_manager.execute_concurrent(tasks)
        
        # åˆå¹¶ç»“æœ
        results = []
        for chunk_result in chunk_results:
            if isinstance(chunk_result, list):
                results.extend(chunk_result)
            else:
                results.append(chunk_result)
        
        return results
    
    def get_performance_report(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        if not self.metrics:
            return {"message": "æš‚æ— æ€§èƒ½æ•°æ®"}
        
        # æŒ‰æ“ä½œåˆ†ç»„
        operation_stats: Dict[str, List[float]] = {}
        for metric in self.metrics:
            if metric.operation_name not in operation_stats:
                operation_stats[metric.operation_name] = []
            operation_stats[metric.operation_name].append(metric.duration_seconds)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        report = {
            "æ€»æ“ä½œæ•°": len(self.metrics),
            "æ“ä½œç»Ÿè®¡": {},
            "ç¼“å­˜ç»Ÿè®¡": self.cache_manager.get_stats(),
            "æœ€æ…¢æ“ä½œ": self._get_slowest_operations(),
            "æ€§èƒ½å»ºè®®": self._get_performance_recommendations()
        }
        
        for op_name, durations in operation_stats.items():
            report["æ“ä½œç»Ÿè®¡"][op_name] = {
                "è°ƒç”¨æ¬¡æ•°": len(durations),
                "å¹³å‡è€—æ—¶": sum(durations) / len(durations),
                "æœ€å¤§è€—æ—¶": max(durations),
                "æœ€å°è€—æ—¶": min(durations)
            }
        
        return report
    
    def _get_slowest_operations(self, top_n: int = 5) -> List[Dict[str, Any]]:
        """è·å–æœ€æ…¢çš„æ“ä½œ"""
        sorted_metrics = sorted(
            self.metrics,
            key=lambda m: m.duration_seconds,
            reverse=True
        )
        
        return [
            {
                "æ“ä½œå": metric.operation_name,
                "è€—æ—¶": f"{metric.duration_seconds:.3f}ç§’",
                "æ—¶é—´": metric.start_time.strftime("%Y-%m-%d %H:%M:%S")
            }
            for metric in sorted_metrics[:top_n]
        ]
    
    def _get_performance_recommendations(self) -> List[str]:
        """è·å–æ€§èƒ½å»ºè®®"""
        recommendations = []
        
        if not self.metrics:
            return recommendations
        
        # åˆ†æç¼“å­˜å‘½ä¸­ç‡
        cache_stats = self.cache_manager.get_stats()
        if cache_stats["hit_ratio"] < 0.5:
            recommendations.append("è€ƒè™‘å¢åŠ ç¼“å­˜å¤§å°æˆ–ä¼˜åŒ–ç¼“å­˜ç­–ç•¥")
        
        # åˆ†ææ…¢æ“ä½œ
        slow_operations = [
            m for m in self.metrics 
            if m.duration_seconds > 5.0
        ]
        if slow_operations:
            recommendations.append(
                f"å‘ç° {len(slow_operations)} ä¸ªæ…¢æ“ä½œï¼Œå»ºè®®ä¼˜åŒ–æˆ–ä½¿ç”¨å¼‚æ­¥å¤„ç†"
            )
        
        # åˆ†æå¹¶å‘åº¦
        concurrent_operations = len([
            m for m in self.metrics
            if m.concurrent_tasks and m.concurrent_tasks > 1
        ])
        if concurrent_operations < len(self.metrics) * 0.3:
            recommendations.append("è€ƒè™‘å¢åŠ å¹¶å‘å¤„ç†ä»¥æé«˜æ€§èƒ½")
        
        return recommendations or ["å½“å‰æ€§èƒ½è¡¨ç°è‰¯å¥½"]
    
    def clear_metrics(self) -> None:
        """æ¸…ç©ºæ€§èƒ½æŒ‡æ ‡"""
        self.metrics.clear()
    
    def clear_cache(self) -> None:
        """æ¸…ç©ºç¼“å­˜"""
        self.cache_manager.clear()


# å…¨å±€æ€§èƒ½ä¼˜åŒ–å™¨å®ä¾‹
global_optimizer = PerformanceOptimizer()


def optimize_agent_performance(agent_class):
    """æ™ºèƒ½ä½“æ€§èƒ½ä¼˜åŒ–è£…é¥°å™¨"""
    
    class OptimizedAgent(agent_class):
        def __init__(self, *args, **kwargs):
            super().__init__(*args, **kwargs)
            self.optimizer = PerformanceOptimizer()
        
        async def execute_task(self, task_name: str, inputs: Dict[str, Any]) -> Dict[str, Any]:
            """ä¼˜åŒ–çš„ä»»åŠ¡æ‰§è¡Œ"""
            
            # ä½¿ç”¨ç¼“å­˜å’Œè®¡æ—¶
            @self.optimizer.cached()
            @self.optimizer.timed
            async def cached_execute():
                return await super(OptimizedAgent, self).execute_task(task_name, inputs)
            
            return await cached_execute()
        
        def get_performance_stats(self) -> Dict[str, Any]:
            """è·å–æ€§èƒ½ç»Ÿè®¡"""
            return self.optimizer.get_performance_report()
    
    return OptimizedAgent


if __name__ == "__main__":
    async def test_performance_optimizer():
        """æµ‹è¯•æ€§èƒ½ä¼˜åŒ–å™¨"""
        
        optimizer = PerformanceOptimizer()
        
        # æµ‹è¯•ç¼“å­˜
        @optimizer.cached()
        async def expensive_operation(x: int) -> int:
            await asyncio.sleep(1)  # æ¨¡æ‹Ÿè€—æ—¶æ“ä½œ
            return x * x
        
        # æµ‹è¯•è®¡æ—¶
        @optimizer.timed
        async def timed_operation(x: int) -> int:
            await asyncio.sleep(0.5)
            return x + 1
        
        print("ğŸš€ æµ‹è¯•æ€§èƒ½ä¼˜åŒ–å™¨...")
        
        # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼ˆæ— ç¼“å­˜ï¼‰
        result1 = await expensive_operation(5)
        print(f"ç¬¬ä¸€æ¬¡è°ƒç”¨ç»“æœ: {result1}")
        
        # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼ˆæœ‰ç¼“å­˜ï¼‰
        result2 = await expensive_operation(5)
        print(f"ç¬¬äºŒæ¬¡è°ƒç”¨ç»“æœ: {result2}")
        
        # æµ‹è¯•è®¡æ—¶
        result3 = await timed_operation(10)
        print(f"è®¡æ—¶æ“ä½œç»“æœ: {result3}")
        
        # æ‰“å°æ€§èƒ½æŠ¥å‘Š
        report = optimizer.get_performance_report()
        print("\nğŸ“Š æ€§èƒ½æŠ¥å‘Š:")
        for key, value in report.items():
            print(f"{key}: {value}")
    
    asyncio.run(test_performance_optimizer()) 