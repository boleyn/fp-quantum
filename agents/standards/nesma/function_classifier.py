"""
é‡å­æ™ºèƒ½åŒ–åŠŸèƒ½ç‚¹ä¼°ç®—ç³»ç»Ÿ - NESMAåŠŸèƒ½åˆ†ç±»å™¨æ™ºèƒ½ä½“

åŸºäºNESMA v2.3+æ ‡å‡†è¿›è¡ŒåŠŸèƒ½ç±»å‹æ™ºèƒ½åˆ†ç±»
"""

import asyncio
from typing import Dict, Any, Optional, List
import logging
from datetime import datetime
from pathlib import Path

from langchain_core.language_models import BaseLanguageModel
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool
from langchain_core.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field

from agents.base.base_agent import SpecializedAgent
from agents.knowledge.rule_retriever import RuleRetrieverAgent
from models.nesma_models import (
    NESMAFunctionType, NESMAFunctionClassification
)
from models.project_models import ProcessDetails
from models.common_models import ConfidenceLevel, ValidationResult
from config.settings import get_settings
import logging

logger = logging.getLogger(__name__)

# ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹
class FunctionClassificationResult(BaseModel):
    """åŠŸèƒ½åˆ†ç±»ç»“æœçš„ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹"""
    function_type: str = Field(description="åŠŸèƒ½ç±»å‹ï¼šILFã€EIFã€EIã€EOã€EQä¹‹ä¸€")
    confidence_score: float = Field(description="ç½®ä¿¡åº¦åˆ†æ•°ï¼Œ0.0-1.0ä¹‹é—´", ge=0.0, le=1.0)
    justification: str = Field(description="è¯¦ç»†çš„åˆ†ç±»ç†ç”±")
    key_indicators: List[str] = Field(description="å…³é”®æŒ‡æ ‡åˆ—è¡¨")
    rules_applied: List[str] = Field(description="åº”ç”¨çš„è§„åˆ™åˆ—è¡¨")


class NESMAFunctionClassifierAgent(SpecializedAgent):
    """NESMAåŠŸèƒ½åˆ†ç±»å™¨æ™ºèƒ½ä½“"""
    
    def __init__(
        self,
        rule_retriever: Optional[RuleRetrieverAgent] = None,
        llm: Optional[BaseLanguageModel] = None
    ):
        super().__init__(
            agent_id="nesma_function_classifier",
            specialty="nesma_function_classification",
            llm=llm
        )
        
        self.rule_retriever = rule_retriever
        self.settings = get_settings()
        
        # NESMAåˆ†ç±»è§„åˆ™æ•°æ®åº“
        self.classification_rules = self._load_classification_rules()
        self.classification_history: List[NESMAFunctionClassification] = []
        
    def _load_classification_rules(self) -> Dict[str, Any]:
        """åŠ è½½NESMAåˆ†ç±»è§„åˆ™"""
        return {
            "ILF": {
                "å®šä¹‰": "å†…éƒ¨é€»è¾‘æ–‡ä»¶ï¼šåº”ç”¨å†…ç»´æŠ¤çš„ä¸€ç»„é€»è¾‘ç›¸å…³çš„æ•°æ®",
                "å…³é”®ç‰¹å¾": [
                    "ç”±åº”ç”¨å†…éƒ¨ç»´æŠ¤",
                    "é€šè¿‡å¤–éƒ¨è¾“å…¥è¿›è¡Œæ›´æ–°",
                    "åŒ…å«å¤šä¸ªæ•°æ®å…ƒç´ ",
                    "æœ‰ä¸»é”®æ ‡è¯†"
                ],
                "è¯†åˆ«è¯æ±‡": [
                    "å­˜å‚¨", "ç»´æŠ¤", "ç®¡ç†", "è¡¨", "æ•°æ®åº“", "è®°å½•",
                    "ä¸»æ•°æ®", "åŸºç¡€æ•°æ®", "é…ç½®æ•°æ®", "ç”¨æˆ·ä¿¡æ¯"
                ],
                "æ’é™¤æ¡ä»¶": [
                    "ä»…ä¾›æŸ¥è¯¢ä¸èƒ½æ›´æ–°",
                    "æ¥è‡ªå¤–éƒ¨ç³»ç»Ÿ", 
                    "ä¸´æ—¶æ–‡ä»¶",
                    "æ—¥å¿—æ–‡ä»¶"
                ]
            },
            "EIF": {
                "å®šä¹‰": "å¤–éƒ¨æ¥å£æ–‡ä»¶ï¼šè¢«å¦ä¸€ä¸ªåº”ç”¨ç»´æŠ¤çš„ä¸€ç»„é€»è¾‘ç›¸å…³çš„æ•°æ®",
                "å…³é”®ç‰¹å¾": [
                    "ç”±å¤–éƒ¨åº”ç”¨ç»´æŠ¤",
                    "ä»…ä¾›æœ¬åº”ç”¨å¼•ç”¨",
                    "ä¸èƒ½ç”±æœ¬åº”ç”¨æ›´æ–°",
                    "è·¨ç³»ç»Ÿæ•°æ®"
                ],
                "è¯†åˆ«è¯æ±‡": [
                    "å¤–éƒ¨", "æ¥å£", "å¼•ç”¨", "æŸ¥è¯¢", "ç¬¬ä¸‰æ–¹",
                    "å…¶ä»–ç³»ç»Ÿ", "å…±äº«æ•°æ®", "åŒæ­¥æ•°æ®"
                ],
                "æ’é™¤æ¡ä»¶": [
                    "å¯ä»¥æ›´æ–°",
                    "åº”ç”¨å†…éƒ¨æ•°æ®",
                    "ä¸´æ—¶æ¥å£"
                ]
            },
            "EI": {
                "å®šä¹‰": "å¤–éƒ¨è¾“å…¥ï¼šä»åº”ç”¨è¾¹ç•Œå¤–å¤„ç†æ•°æ®æˆ–æ§åˆ¶ä¿¡æ¯çš„åŠŸèƒ½",
                "å…³é”®ç‰¹å¾": [
                    "æ•°æ®ä»å¤–éƒ¨è¿›å…¥",
                    "æ›´æ–°ILF",
                    "ç»´æŠ¤æ•°æ®å®Œæ•´æ€§",
                    "åŒ…å«ä¸šåŠ¡é€»è¾‘"
                ],
                "è¯†åˆ«è¯æ±‡": [
                    "è¾“å…¥", "æ–°å¢", "æ·»åŠ ", "åˆ›å»º", "å½•å…¥", "å¯¼å…¥",
                    "æ›´æ–°", "ä¿®æ”¹", "ç¼–è¾‘", "ç»´æŠ¤", "ä¿å­˜"
                ],
                "æ’é™¤æ¡ä»¶": [
                    "ä»…æŸ¥è¯¢åŠŸèƒ½",
                    "ä»…è¾“å‡ºåŠŸèƒ½",
                    "é‡å¤æ•°æ®å¤„ç†"
                ]
            },
            "EO": {
                "å®šä¹‰": "å¤–éƒ¨è¾“å‡ºï¼šå‘åº”ç”¨è¾¹ç•Œå¤–å‘é€æ•°æ®æˆ–æ§åˆ¶ä¿¡æ¯çš„åŠŸèƒ½",
                "å…³é”®ç‰¹å¾": [
                    "åŒ…å«æ´¾ç”Ÿæ•°æ®",
                    "æœ‰è®¡ç®—é€»è¾‘",
                    "åˆ›å»ºæ•°æ®ä¾›å¤–éƒ¨ä½¿ç”¨",
                    "å«æœ‰å¤„ç†é€»è¾‘"
                ],
                "è¯†åˆ«è¯æ±‡": [
                    "æŠ¥è¡¨", "ç»Ÿè®¡", "åˆ†æ", "è®¡ç®—", "æ±‡æ€»", "ç”Ÿæˆ",
                    "å¯¼å‡º", "æ‰“å°", "å‘é€", "ä¼ è¾“"
                ],
                "æ’é™¤æ¡ä»¶": [
                    "ä»…æ£€ç´¢åŠŸèƒ½",
                    "æ— è®¡ç®—é€»è¾‘",
                    "é‡å¤æŸ¥è¯¢"
                ]
            },
            "EQ": {
                "å®šä¹‰": "å¤–éƒ¨æŸ¥è¯¢ï¼šä»åº”ç”¨è¾¹ç•Œå¤–æ£€ç´¢æ•°æ®çš„åŠŸèƒ½",
                "å…³é”®ç‰¹å¾": [
                    "æ£€ç´¢æ•°æ®å±•ç¤º",
                    "ä¸æ›´æ–°ILF",
                    "è¾“å…¥è¾“å‡ºç»“åˆ",
                    "ç®€å•æ£€ç´¢é€»è¾‘"
                ],
                "è¯†åˆ«è¯æ±‡": [
                    "æŸ¥è¯¢", "æ£€ç´¢", "æœç´¢", "æŸ¥æ‰¾", "æµè§ˆ", "æ˜¾ç¤º",
                    "åˆ—è¡¨", "è¯¦æƒ…", "ä¿¡æ¯", "çŠ¶æ€"
                ],
                "æ’é™¤æ¡ä»¶": [
                    "æ›´æ–°åŠŸèƒ½",
                    "å¤æ‚è®¡ç®—",
                    "æ´¾ç”Ÿæ•°æ®"
                ]
            }
        }
    
    def _get_capabilities(self) -> List[str]:
        """è·å–æ™ºèƒ½ä½“èƒ½åŠ›åˆ—è¡¨"""
        return [
            "NESMAåŠŸèƒ½ç±»å‹è¯†åˆ«",
            "åˆ†ç±»è§„åˆ™åŒ¹é…",
            "ç½®ä¿¡åº¦è¯„ä¼°",
            "åˆ†ç±»ç†ç”±ç”Ÿæˆ",
            "æ‰¹é‡åŠŸèƒ½åˆ†ç±»"
        ]
    
    async def _execute_task(self, task_name: str, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒNESMAåˆ†ç±»ä»»åŠ¡"""
        if task_name == "classify_function":
            return await self.classify_function(
                inputs["function_description"],
                inputs.get("process_details", None)
            )
        elif task_name == "classify_batch_functions":
            return await self.classify_batch_functions(inputs["functions"])
        elif task_name == "validate_classification":
            return await self.validate_classification(
                inputs["classification"],
                inputs["function_description"]
            )
        elif task_name == "explain_classification":
            return await self.explain_classification(
                inputs["function_type"],
                inputs["function_description"]
            )
        else:
            raise ValueError(f"æœªçŸ¥ä»»åŠ¡: {task_name}")
    
    async def classify_function(
        self,
        function_description: str,
        process_details: Optional[ProcessDetails] = None
    ) -> NESMAFunctionClassification:
        """å¯¹å•ä¸ªåŠŸèƒ½è¿›è¡ŒNESMAåˆ†ç±»"""
        
        # 1. è·å–ç›¸å…³NESMAè§„åˆ™
        nesma_rules = await self._retrieve_nesma_rules(function_description)
        
        # 2. ä½¿ç”¨LLMè¿›è¡Œåˆ†ç±»
        classification = await self._llm_classify_function(
            function_description, 
            process_details, 
            nesma_rules
        )
        
        # 3. éªŒè¯åˆ†ç±»ç»“æœ
        validated_classification = await self._validate_classification_result(
            classification, 
            function_description
        )
        
        # 4. è®°å½•åˆ†ç±»å†å²
        self.classification_history.append(validated_classification)
        
        return validated_classification
    
    async def classify_batch_functions(
        self, 
        functions: List[Dict[str, Any]]
    ) -> List[NESMAFunctionClassification]:
        """æ‰¹é‡åŠŸèƒ½åˆ†ç±»"""
        
        classifications = []
        
        for func_info in functions:
            try:
                classification = await self.classify_function(
                    func_info["description"],
                    func_info.get("process_details", None)
                )
                classifications.append(classification)
            except Exception as e:
                logger.error(f"åŠŸèƒ½åˆ†ç±»å¤±è´¥: {func_info.get('id', 'unknown')}, é”™è¯¯: {str(e)}")
                # åˆ›å»ºå¤±è´¥çš„åˆ†ç±»è®°å½•
                failed_classification = NESMAFunctionClassification(
                    function_id=func_info.get("id", "unknown"),
                    function_name=func_info.get("name", "æœªçŸ¥åŠŸèƒ½"),  # æ·»åŠ function_name
                    function_description=func_info.get("description", ""),  # æ·»åŠ function_description
                    function_type=NESMAFunctionType.EI,  # é»˜è®¤ç±»å‹
                    confidence_score=0.0,
                    justification=f"åˆ†ç±»å¤±è´¥: {str(e)}",
                    rules_applied=[]
                )
                classifications.append(failed_classification)
        
        return classifications
    
    async def validate_classification(
        self,
        classification: NESMAFunctionClassification,
        function_description: str
    ) -> Dict[str, Any]:
        """éªŒè¯åˆ†ç±»ç»“æœçš„åˆç†æ€§"""
        
        # è·å–è§„åˆ™åŒ¹é…åº¦
        rule_match = self._check_rule_match(
            classification.function_type, 
            function_description
        )
        
        # æ£€æŸ¥å¸¸è§é”™è¯¯
        potential_errors = self._check_common_errors(
            classification.function_type,
            function_description
        )
        
        # è®¡ç®—æ€»ä½“éªŒè¯åˆ†æ•°
        validation_score = self._calculate_validation_score(
            classification.confidence_score,
            rule_match["score"],
            len(potential_errors)
        )
        
        return {
            "is_valid": validation_score > 0.7,
            "validation_score": validation_score,
            "rule_match": rule_match,
            "potential_errors": potential_errors,
            "suggestions": self._generate_validation_suggestions(
                classification, 
                potential_errors
            )
        }
    
    async def explain_classification(
        self,
        function_type: NESMAFunctionType,
        function_description: str
    ) -> Dict[str, Any]:
        """è§£é‡Šåˆ†ç±»åŸå› å’Œä¾æ®"""
        
        rules = self.classification_rules[function_type.value]
        
        # åˆ†æåŠŸèƒ½æè¿°ä¸­çš„å…³é”®è¯åŒ¹é…
        keyword_matches = self._analyze_keyword_matches(
            function_description, 
            rules["è¯†åˆ«è¯æ±‡"]
        )
        
        # æ£€æŸ¥æ’é™¤æ¡ä»¶
        exclusion_checks = self._check_exclusion_conditions(
            function_description,
            rules["æ’é™¤æ¡ä»¶"]
        )
        
        return {
            "function_type": function_type.value,
            "definition": rules["å®šä¹‰"],
            "key_characteristics": rules["å…³é”®ç‰¹å¾"],
            "keyword_matches": keyword_matches,
            "exclusion_checks": exclusion_checks,
            "classification_confidence": self._calculate_explanation_confidence(
                keyword_matches, 
                exclusion_checks
            )
        }
    
    async def _retrieve_nesma_rules(self, function_description: str) -> List[str]:
        """æ£€ç´¢ç›¸å…³çš„NESMAåˆ†ç±»è§„åˆ™"""
        if not self.rule_retriever:
            return []
        
        try:
            # æ„å»ºæŸ¥è¯¢
            query = f"NESMA åŠŸèƒ½åˆ†ç±» {function_description[:100]}"
            
            result = await self.rule_retriever.retrieve_rules(
                query=query,
                standard="NESMA",
                min_chunks=3
            )
            
            if result and result.retrieved_chunks:
                # å¤„ç†ä¸åŒç±»å‹çš„chunkæ ¼å¼ï¼ˆå­—å…¸æˆ–å¯¹è±¡ï¼‰
                def get_chunk_content(chunk):
                    if isinstance(chunk, dict):
                        return chunk.get('content', '')
                    else:
                        return getattr(chunk, 'content', '')
                
                return [get_chunk_content(chunk) for chunk in result.retrieved_chunks]
            
        except Exception as e:
            logger.warning(f"NESMAè§„åˆ™æ£€ç´¢å¤±è´¥: {str(e)}")
        
        return []
    
    async def _llm_classify_function(
        self,
        function_description: str,
        process_details: Optional[ProcessDetails],
        nesma_rules: List[str]
    ) -> NESMAFunctionClassification:
        """ä½¿ç”¨LLMè¿›è¡ŒåŠŸèƒ½åˆ†ç±»"""
        
        # å®šä¹‰åˆ†ç±»å·¥å…·
        @tool
        def classify_nesma_function(
            function_type: str,
            confidence_score: float,
            justification: str,
            key_indicators: List[str],
            rules_applied: List[str]
        ) -> dict:
            """å¯¹åŠŸèƒ½è¿›è¡ŒNESMAåˆ†ç±»
            
            Args:
                function_type: åŠŸèƒ½ç±»å‹ï¼Œå¿…é¡»æ˜¯ILFã€EIFã€EIã€EOã€EQä¹‹ä¸€
                confidence_score: ç½®ä¿¡åº¦åˆ†æ•°ï¼Œ0.0-1.0ä¹‹é—´
                justification: è¯¦ç»†çš„åˆ†ç±»ç†ç”±
                key_indicators: å…³é”®æŒ‡æ ‡åˆ—è¡¨
                rules_applied: åº”ç”¨çš„è§„åˆ™åˆ—è¡¨
            """
            return {
                "function_type": function_type,
                "confidence_score": confidence_score,
                "justification": justification,
                "key_indicators": key_indicators,
                "rules_applied": rules_applied
            }
        
        # åˆ›å»ºå¸¦å·¥å…·çš„LLM
        llm_with_tools = self.llm.bind_tools([classify_nesma_function])
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯NESMAåŠŸèƒ½ç‚¹åˆ†ç±»ä¸“å®¶ï¼Œéœ€è¦å°†åŠŸèƒ½åˆ†ç±»ä¸ºä»¥ä¸‹äº”ç§ç±»å‹ä¹‹ä¸€ï¼š

ILF (Internal Logical File): å†…éƒ¨é€»è¾‘æ–‡ä»¶ - åº”ç”¨å†…ç»´æŠ¤çš„æ•°æ®
EIF (External Interface File): å¤–éƒ¨æ¥å£æ–‡ä»¶ - å¤–éƒ¨åº”ç”¨ç»´æŠ¤çš„æ•°æ®  
EI (External Input): å¤–éƒ¨è¾“å…¥ - å¤„ç†è¾“å…¥æ•°æ®å¹¶æ›´æ–°å†…éƒ¨æ–‡ä»¶
EO (External Output): å¤–éƒ¨è¾“å‡º - å‘å¤–éƒ¨å‘é€å¤„ç†åçš„æ•°æ®
EQ (External Query): å¤–éƒ¨æŸ¥è¯¢ - æ£€ç´¢æ•°æ®è¿›è¡Œå±•ç¤º

åˆ†ç±»åŸåˆ™ï¼š
1. å…³æ³¨æ•°æ®çš„æ¥æºå’Œå»å‘
2. åˆ¤æ–­æ˜¯å¦åŒ…å«ä¸šåŠ¡é€»è¾‘å¤„ç†
3. åŒºåˆ†æ•°æ®ç»´æŠ¤å’Œæ•°æ®æ£€ç´¢
4. è€ƒè™‘è·¨åº”ç”¨è¾¹ç•Œçš„ç‰¹å¾

è¯·ä½¿ç”¨classify_nesma_functionå·¥å…·è¿”å›åˆ†ç±»ç»“æœã€‚"""),
            ("human", """åŠŸèƒ½æè¿°ï¼š{function_description}

æµç¨‹ä¸Šä¸‹æ–‡ï¼š{process_context}

NESMAè§„åˆ™å‚è€ƒï¼š
{nesma_rules}

è¯·å¯¹æ­¤åŠŸèƒ½è¿›è¡ŒNESMAåˆ†ç±»ã€‚""")
        ])
        
        process_context = ""
        if process_details:
            process_context = f"æµç¨‹åç§°: {process_details.name}\næµç¨‹æè¿°: {process_details.description}\næ•°æ®ç»„: {process_details.data_groups}"
        
        response = await llm_with_tools.ainvoke(
            prompt.format_messages(
                function_description=function_description,
                process_context=process_context,
                nesma_rules="\n".join(nesma_rules[:5])  # é™åˆ¶è§„åˆ™æ•°é‡
            )
        )
        
        # è§£æå·¥å…·è°ƒç”¨ç»“æœ
        if response.tool_calls:
            tool_call = response.tool_calls[0]
            result_data = tool_call["args"]
            
            # éªŒè¯åŠŸèƒ½ç±»å‹
            function_type_str = result_data.get("function_type", "EI")
            try:
                function_type = NESMAFunctionType(function_type_str)
            except ValueError:
                logger.warning(f"æ— æ•ˆçš„åŠŸèƒ½ç±»å‹: {function_type_str}ï¼Œä½¿ç”¨é»˜è®¤å€¼EI")
                function_type = NESMAFunctionType.EI
            
            return NESMAFunctionClassification(
                function_id="auto_generated",
                function_name=f"{function_type.value}åŠŸèƒ½",
                function_description=function_description,
                function_type=function_type,
                confidence_score=result_data.get("confidence_score", 0.7),
                justification=result_data.get("justification", "LLMå·¥å…·è°ƒç”¨åˆ†ç±»"),
                rules_applied=result_data.get("rules_applied", ["NESMAåŸºç¡€è§„åˆ™"]),
                classification_confidence=result_data.get("confidence_score", 0.7)
            )
        else:
            # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œä½¿ç”¨ä¿å®ˆåˆ†ç±»
            logger.warning("LLMæœªä½¿ç”¨å·¥å…·è°ƒç”¨ï¼Œä½¿ç”¨ä¿å®ˆåˆ†ç±»")
            return await self._conservative_classify(function_description)
    
    async def _validate_classification_result(
        self,
        classification: NESMAFunctionClassification,
        function_description: str
    ) -> NESMAFunctionClassification:
        """éªŒè¯å¹¶å¯èƒ½è°ƒæ•´åˆ†ç±»ç»“æœ"""
        
        # æ£€æŸ¥åˆ†ç±»åˆç†æ€§
        validation = await self.validate_classification(
            classification, 
            function_description
        )
        
        # å¦‚æœéªŒè¯å¤±è´¥ä¸”ç½®ä¿¡åº¦è¾ƒä½ï¼Œå°è¯•é‡æ–°åˆ†ç±»
        if not validation["is_valid"] and classification.confidence_score < 0.7:
            logger.warning(f"åˆ†ç±»éªŒè¯å¤±è´¥ï¼Œå°è¯•é‡æ–°åˆ†ç±»: {function_description[:50]}...")
            
            # ä½¿ç”¨æ›´ä¿å®ˆçš„åˆ†ç±»ç­–ç•¥
            adjusted_classification = await self._conservative_classify(
                function_description
            )
            return adjusted_classification
        
        return classification
    
    async def _conservative_classify(
        self, 
        function_description: str
    ) -> NESMAFunctionClassification:
        """ä¿å®ˆçš„åˆ†ç±»ç­–ç•¥ï¼ˆå½“ä¸»è¦åˆ†ç±»å¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
        
        description_lower = function_description.lower()
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        if any(keyword in description_lower for keyword in ["æ–°å¢", "æ·»åŠ ", "åˆ›å»º", "å½•å…¥", "è¾“å…¥"]):
            function_type = NESMAFunctionType.EI
            justification = "åŸºäºå…³é”®è¯åŒ¹é…ï¼Œè¯†åˆ«ä¸ºå¤–éƒ¨è¾“å…¥åŠŸèƒ½"
        elif any(keyword in description_lower for keyword in ["æŸ¥è¯¢", "æ£€ç´¢", "æœç´¢", "æ˜¾ç¤º", "åˆ—è¡¨"]):
            function_type = NESMAFunctionType.EQ
            justification = "åŸºäºå…³é”®è¯åŒ¹é…ï¼Œè¯†åˆ«ä¸ºå¤–éƒ¨æŸ¥è¯¢åŠŸèƒ½"
        elif any(keyword in description_lower for keyword in ["æŠ¥è¡¨", "ç»Ÿè®¡", "å¯¼å‡º", "è®¡ç®—"]):
            function_type = NESMAFunctionType.EO
            justification = "åŸºäºå…³é”®è¯åŒ¹é…ï¼Œè¯†åˆ«ä¸ºå¤–éƒ¨è¾“å‡ºåŠŸèƒ½"
        elif any(keyword in description_lower for keyword in ["å­˜å‚¨", "ç»´æŠ¤", "ç®¡ç†", "æ•°æ®"]):
            function_type = NESMAFunctionType.ILF
            justification = "åŸºäºå…³é”®è¯åŒ¹é…ï¼Œè¯†åˆ«ä¸ºå†…éƒ¨é€»è¾‘æ–‡ä»¶"
        else:
            function_type = NESMAFunctionType.EI  # é»˜è®¤åˆ†ç±»
            justification = "æ— æ³•æ˜ç¡®è¯†åˆ«ï¼Œé»˜è®¤åˆ†ç±»ä¸ºå¤–éƒ¨è¾“å…¥"
        
        return NESMAFunctionClassification(
            function_id="auto_generated",
            function_name=f"{function_type.value}åŠŸèƒ½",
            function_description=function_description,
            function_type=function_type,
            confidence_score=0.6,  # ä¿å®ˆçš„ç½®ä¿¡åº¦
            justification=justification,
            rules_applied=["ä¿å®ˆåˆ†ç±»ç­–ç•¥"]
        )
    
    def _check_rule_match(
        self, 
        function_type: NESMAFunctionType, 
        function_description: str
    ) -> Dict[str, Any]:
        """æ£€æŸ¥è§„åˆ™åŒ¹é…æƒ…å†µ"""
        
        rules = self.classification_rules[function_type.value]
        description_lower = function_description.lower()
        
        # æ£€æŸ¥è¯†åˆ«è¯æ±‡åŒ¹é…
        matched_keywords = [
            keyword for keyword in rules["è¯†åˆ«è¯æ±‡"] 
            if keyword in description_lower
        ]
        
        # æ£€æŸ¥æ’é™¤æ¡ä»¶
        exclusion_violations = [
            condition for condition in rules["æ’é™¤æ¡ä»¶"]
            if any(word in description_lower for word in condition.split())
        ]
        
        # è®¡ç®—åŒ¹é…åˆ†æ•°
        keyword_score = len(matched_keywords) / len(rules["è¯†åˆ«è¯æ±‡"])
        exclusion_penalty = len(exclusion_violations) * 0.2
        rule_score = max(0.0, keyword_score - exclusion_penalty)
        
        return {
            "score": rule_score,
            "matched_keywords": matched_keywords,
            "exclusion_violations": exclusion_violations,
            "keyword_match_rate": keyword_score
        }
    
    def _check_common_errors(
        self, 
        function_type: NESMAFunctionType, 
        function_description: str
    ) -> List[str]:
        """æ£€æŸ¥å¸¸è§åˆ†ç±»é”™è¯¯"""
        
        errors = []
        description_lower = function_description.lower()
        
        # ILFå¸¸è§é”™è¯¯
        if function_type == NESMAFunctionType.ILF:
            if any(word in description_lower for word in ["æŸ¥è¯¢", "æ˜¾ç¤º", "åˆ—è¡¨"]):
                errors.append("ILFä¸åº”åŒ…å«æŸ¥è¯¢å±•ç¤ºåŠŸèƒ½")
            if "å¤–éƒ¨" in description_lower:
                errors.append("ILFåº”ä¸ºå†…éƒ¨æ•°æ®ï¼Œä¸åº”æ¶‰åŠå¤–éƒ¨")
        
        # EIFå¸¸è§é”™è¯¯
        elif function_type == NESMAFunctionType.EIF:
            if any(word in description_lower for word in ["æ›´æ–°", "ä¿®æ”¹", "ç»´æŠ¤"]):
                errors.append("EIFä¸èƒ½è¢«æœ¬åº”ç”¨æ›´æ–°")
            if "å†…éƒ¨" in description_lower:
                errors.append("EIFåº”ä¸ºå¤–éƒ¨æ•°æ®")
        
        # EIå¸¸è§é”™è¯¯  
        elif function_type == NESMAFunctionType.EI:
            if "æŸ¥è¯¢" in description_lower and "è¾“å…¥" not in description_lower:
                errors.append("çº¯æŸ¥è¯¢åŠŸèƒ½åº”åˆ†ç±»ä¸ºEQ")
            if "æŠ¥è¡¨" in description_lower or "ç»Ÿè®¡" in description_lower:
                errors.append("æŠ¥è¡¨ç»Ÿè®¡åŠŸèƒ½åº”åˆ†ç±»ä¸ºEO")
        
        # EOå¸¸è§é”™è¯¯
        elif function_type == NESMAFunctionType.EO:
            if "æŸ¥è¯¢" in description_lower and "è®¡ç®—" not in description_lower:
                errors.append("ç®€å•æŸ¥è¯¢åº”åˆ†ç±»ä¸ºEQ")
            if "è¾“å…¥" in description_lower:
                errors.append("è¾“å…¥åŠŸèƒ½åº”åˆ†ç±»ä¸ºEI")
        
        # EQå¸¸è§é”™è¯¯
        elif function_type == NESMAFunctionType.EQ:
            if any(word in description_lower for word in ["æ›´æ–°", "æ–°å¢", "ä¿®æ”¹"]):
                errors.append("æ›´æ–°åŠŸèƒ½åº”åˆ†ç±»ä¸ºEI")
            if any(word in description_lower for word in ["è®¡ç®—", "ç»Ÿè®¡", "æŠ¥è¡¨"]):
                errors.append("è®¡ç®—åŠŸèƒ½åº”åˆ†ç±»ä¸ºEO")
        
        return errors
    
    def _calculate_validation_score(
        self, 
        confidence_score: float, 
        rule_match_score: float, 
        error_count: int
    ) -> float:
        """è®¡ç®—éªŒè¯åˆ†æ•°"""
        
        base_score = (confidence_score + rule_match_score) / 2
        error_penalty = error_count * 0.15
        
        return max(0.0, min(1.0, base_score - error_penalty))
    
    def _generate_validation_suggestions(
        self,
        classification: NESMAFunctionClassification,
        potential_errors: List[str]
    ) -> List[str]:
        """ç”ŸæˆéªŒè¯å»ºè®®"""
        
        suggestions = []
        
        if classification.confidence_score < 0.7:
            suggestions.append("ç½®ä¿¡åº¦è¾ƒä½ï¼Œå»ºè®®äººå·¥å¤æ ¸")
        
        if potential_errors:
            suggestions.append("å­˜åœ¨æ½œåœ¨åˆ†ç±»é”™è¯¯ï¼Œå»ºè®®æ£€æŸ¥ï¼š" + "; ".join(potential_errors))
        
        if not classification.rules_applied:
            suggestions.append("æœªæ˜ç¡®åº”ç”¨åˆ†ç±»è§„åˆ™ï¼Œå»ºè®®è¡¥å……è§„åˆ™ä¾æ®")
        
        if not suggestions:
            suggestions.append("åˆ†ç±»ç»“æœçœ‹èµ·æ¥åˆç†")
        
        return suggestions
    
    def _analyze_keyword_matches(
        self, 
        function_description: str, 
        keywords: List[str]
    ) -> Dict[str, Any]:
        """åˆ†æå…³é”®è¯åŒ¹é…æƒ…å†µ"""
        
        description_lower = function_description.lower()
        matched = []
        
        for keyword in keywords:
            if keyword in description_lower:
                matched.append(keyword)
        
        return {
            "matched_keywords": matched,
            "match_count": len(matched),
            "match_rate": len(matched) / len(keywords) if keywords else 0
        }
    
    def _check_exclusion_conditions(
        self, 
        function_description: str, 
        exclusions: List[str]
    ) -> Dict[str, Any]:
        """æ£€æŸ¥æ’é™¤æ¡ä»¶"""
        
        description_lower = function_description.lower()
        violated = []
        
        for exclusion in exclusions:
            if any(word in description_lower for word in exclusion.split()):
                violated.append(exclusion)
        
        return {
            "violated_conditions": violated,
            "violation_count": len(violated),
            "is_valid": len(violated) == 0
        }
    
    def _calculate_explanation_confidence(
        self, 
        keyword_matches: Dict[str, Any], 
        exclusion_checks: Dict[str, Any]
    ) -> float:
        """è®¡ç®—è§£é‡Šç½®ä¿¡åº¦"""
        
        match_score = keyword_matches["match_rate"]
        exclusion_penalty = exclusion_checks["violation_count"] * 0.3
        
        return max(0.0, min(1.0, match_score - exclusion_penalty))
    
    async def _parse_classification_response(
        self, 
        response_content: str, 
        function_description: str
    ) -> NESMAFunctionClassification:
        """è§£æåˆ†ç±»å“åº” - å·²åºŸå¼ƒï¼Œä¿ç•™ç”¨äºå…¼å®¹æ€§"""
        logger.warning("ä½¿ç”¨å·²åºŸå¼ƒçš„JSONè§£ææ–¹æ³•ï¼Œå»ºè®®ä½¿ç”¨å·¥å…·è°ƒç”¨")
        return await self._conservative_classify(function_description)
    
    def get_classification_history(self) -> List[NESMAFunctionClassification]:
        """è·å–åˆ†ç±»å†å²"""
        return self.classification_history.copy()
    
    def get_classification_statistics(self) -> Dict[str, Any]:
        """è·å–åˆ†ç±»ç»Ÿè®¡"""
        if not self.classification_history:
            return {"total": 0}
        
        type_counts = {}
        confidence_scores = []
        
        for classification in self.classification_history:
            func_type = classification.function_type.value
            type_counts[func_type] = type_counts.get(func_type, 0) + 1
            confidence_scores.append(classification.confidence_score)
        
        return {
            "total": len(self.classification_history),
            "type_distribution": type_counts,
            "average_confidence": sum(confidence_scores) / len(confidence_scores),
            "min_confidence": min(confidence_scores),
            "max_confidence": max(confidence_scores)
        }


# å·¥å‚å‡½æ•°
async def create_nesma_function_classifier(
    rule_retriever: Optional[RuleRetrieverAgent] = None,
    llm: Optional[BaseLanguageModel] = None
) -> NESMAFunctionClassifierAgent:
    """åˆ›å»ºNESMAåŠŸèƒ½åˆ†ç±»å™¨æ™ºèƒ½ä½“"""
    classifier = NESMAFunctionClassifierAgent(rule_retriever=rule_retriever, llm=llm)
    await classifier.initialize()
    return classifier


if __name__ == "__main__":
    async def main():
        # æµ‹è¯•NESMAåŠŸèƒ½åˆ†ç±»å™¨
        classifier = await create_nesma_function_classifier()
        
        # æµ‹è¯•åŠŸèƒ½æè¿°
        test_functions = [
            "ç”¨æˆ·å¯ä»¥å½•å…¥ä¸ªäººåŸºæœ¬ä¿¡æ¯ï¼ŒåŒ…æ‹¬å§“åã€èº«ä»½è¯å·ã€è”ç³»æ–¹å¼ç­‰",
            "ç³»ç»Ÿæ˜¾ç¤ºç”¨æˆ·ä¿¡æ¯åˆ—è¡¨ï¼Œæ”¯æŒæŒ‰å§“åå’Œéƒ¨é—¨æŸ¥è¯¢",
            "ç”Ÿæˆæœˆåº¦é”€å”®ç»Ÿè®¡æŠ¥è¡¨ï¼ŒåŒ…å«å„äº§å“çº¿çš„é”€å”®é¢å’Œå¢é•¿ç‡",
            "ç»´æŠ¤äº§å“åŸºç¡€ä¿¡æ¯ï¼ŒåŒ…æ‹¬äº§å“ç¼–ç ã€åç§°ã€ä»·æ ¼ã€åº“å­˜ç­‰",
            "æŸ¥è¯¢å¤–éƒ¨ä¾›åº”å•†çš„äº§å“ä»·æ ¼ä¿¡æ¯"
        ]
        
        print("ğŸ” NESMAåŠŸèƒ½åˆ†ç±»æµ‹è¯•:")
        for func_desc in test_functions:
            classification = await classifier.execute(
                "classify_function",
                {"function_description": func_desc}
            )
            print(f"\nåŠŸèƒ½: {func_desc[:50]}...")
            print(f"åˆ†ç±»: {classification.function_type.value}")
            print(f"ç½®ä¿¡åº¦: {classification.confidence_score:.2f}")
            print(f"ç†ç”±: {classification.justification}")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = classifier.get_classification_statistics()
        print(f"\nğŸ“Š åˆ†ç±»ç»Ÿè®¡: {stats}")
    
    asyncio.run(main()) 